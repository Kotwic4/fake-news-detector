{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../fakenewsnet_dataset/dataset'\n",
    "DATASET_NAME = 'politifact'\n",
    "DATASET_PATH = '{}/{}'.format(DATA_PATH, DATASET_NAME)\n",
    "REAL_DATA_PATH = '{}_real.csv'.format(DATASET_PATH)\n",
    "FAKE_DATA_PATH = '{}_fake.csv'.format(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_arts = pd.read_csv(FAKE_DATA_PATH, na_values=['nan'], keep_default_na=False)\n",
    "real_arts = pd.read_csv(REAL_DATA_PATH, na_values=['nan'], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_art_data_frame(df):\n",
    "    return [{'id': id, 'url': url, 'title': title} for id, url, title, tweets in df.values]\n",
    "    \n",
    "fake_arts_with_content = parse_art_data_frame(fake_arts)\n",
    "real_arts_with_content = parse_art_data_frame(real_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = [(art, 'fake') for art in fake_arts_with_content]\n",
    "real_data = [(art, 'real') for art in real_arts_with_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(fake_data)\n",
    "# np.random.shuffle(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fake_data[0:int(len(fake_data)*0.8)] + real_data[0:int(len(real_data)*0.8)]\n",
    "test_data = fake_data[int(len(fake_data)*0.8):] + real_data[int(len(real_data)*0.8):]\n",
    "# np.random.shuffle(train_data)\n",
    "# np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844\n",
      "212\n",
      "1056\n",
      "1056\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(train_data) + len(test_data))\n",
    "print(len(fake_data) + len(real_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def predict(self, text):\n",
    "        text = clear_text(text)\n",
    "        sentence = Sentence(text)\n",
    "        self.classifier.predict(sentence)\n",
    "        return sentence.labels[0]\n",
    "\n",
    "def transform_data(data):\n",
    "    return [{'label': label, 'text': clear_text(x)} for x, label in data]\n",
    "\n",
    "def save_data(data, data_folder = '.'):\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    data = transform_data(data)\n",
    "    frame_data = pd.DataFrame(data)\n",
    "    train_path = '{}/train.csv'.format(data_folder)\n",
    "    test_path = '{}/test.csv'.format(data_folder)\n",
    "    dev_path = '{}/dev.csv'.format(data_folder)\n",
    "    frame_data.iloc[0:int(len(data)*0.8)].to_csv(train_path, sep='\\t', index = False, header = False)\n",
    "    frame_data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv(test_path, sep='\\t', index = False, header = False)\n",
    "    frame_data.iloc[int(len(data)*0.9):].to_csv(dev_path, sep='\\t', index = False, header = False)\n",
    "\n",
    "def load_corpus(data_folder = '.'):\n",
    "    column_name_map = {1: \"text\", 0: \"label\"}\n",
    "    return CSVClassificationCorpus(data_folder,\n",
    "                                     column_name_map,\n",
    "                                     delimiter='\\t',\n",
    "                                  test_file='test.csv',\n",
    "                                  dev_file='dev.csv',\n",
    "                                  train_file='train.csv')\n",
    "    \n",
    "def train_classifier(corpus, model_folder = '.', max_epochs = 1):\n",
    "    label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "    word_embeddings = [\n",
    "        WordEmbeddings('glove'),\n",
    "        FlairEmbeddings('news-forward-fast'),\n",
    "        FlairEmbeddings('news-backward-fast')\n",
    "    ]\n",
    "\n",
    "    document_embeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                hidden_size=512,\n",
    "                                                reproject_words=True,\n",
    "                                                reproject_words_dimension=256)\n",
    "\n",
    "    classifier = TextClassifier(document_embeddings,\n",
    "                                label_dictionary=label_dict)\n",
    "\n",
    "    trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "    trainer.train(model_folder, max_epochs=max_epochs)\n",
    "    \n",
    "    return TextClassifier.load('{}/best-model.pt'.format(model_folder))\n",
    "    \n",
    "def train_model(train_data,\n",
    "               data_folder = '.',\n",
    "               model_folder = '.',\n",
    "               max_epochs=1\n",
    "               ):\n",
    "    save_data(train_data, data_folder)\n",
    "    corpus = load_corpus(data_folder)\n",
    "    classifier = train_classifier(corpus, model_folder, max_epochs)\n",
    "    return Classifier(classifier)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, pos_label = 'fake'):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=pos_label)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=pos_label)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "def validate_model(test_data, classifier):\n",
    "    y_true = [label for x, label in test_data]\n",
    "    y_pred = [classifier.predict(x).value for x, label in test_data]\n",
    "    acc, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
    "    print(\"acc: \", acc)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1: \", f1)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "def make_test(train_data, test_data, data_folder, model_folder, max_epochs):\n",
    "    classifier = train_model(train_data, data_folder, model_folder, max_epochs)\n",
    "    validate_model(test_data, classifier)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content = [(x, label) for x, label in train_data] \n",
    "test_content = [(x, label) for x, label in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "844\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "train_title = [(x['title'], label) for x, label in train_content] \n",
    "test_title = [(x['title'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_title if x == '']))\n",
    "print(len([x for x, label in test_title if x == '']))\n",
    "train_title = [(x, label) for x, label in train_title if x != ''] \n",
    "test_title = [(x, label) for x, label in test_title if x != '']\n",
    "print(len(train_title))\n",
    "print(len(test_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:33:23,010 Reading data from test_csv/title1\n",
      "2019-11-27 11:33:23,011 Train: test_csv/title1/train.csv\n",
      "2019-11-27 11:33:23,012 Dev: test_csv/title1/dev.csv\n",
      "2019-11-27 11:33:23,012 Test: test_csv/title1/test.csv\n",
      "2019-11-27 11:33:23,016 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:00<00:00, 4950.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:33:23,222 [b'fake', b'real']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:33:24,606 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:24,607 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-27 11:33:24,607 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:24,608 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
      "2019-11-27 11:33:24,608 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:24,609 Parameters:\n",
      "2019-11-27 11:33:24,610  - learning_rate: \"0.1\"\n",
      "2019-11-27 11:33:24,612  - mini_batch_size: \"32\"\n",
      "2019-11-27 11:33:24,612  - patience: \"3\"\n",
      "2019-11-27 11:33:24,614  - anneal_factor: \"0.5\"\n",
      "2019-11-27 11:33:24,614  - max_epochs: \"1\"\n",
      "2019-11-27 11:33:24,615  - shuffle: \"True\"\n",
      "2019-11-27 11:33:24,616  - train_with_dev: \"False\"\n",
      "2019-11-27 11:33:24,617  - batch_growth_annealing: \"False\"\n",
      "2019-11-27 11:33:24,618 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:24,618 Model training base path: \"test_csv/title1\"\n",
      "2019-11-27 11:33:24,619 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:24,621 Device: cpu\n",
      "2019-11-27 11:33:24,621 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:24,622 Embeddings storage mode: cpu\n",
      "2019-11-27 11:33:24,623 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:25,689 epoch 1 - iter 0/22 - loss 0.68916136 - samples/sec: 67.65\n",
      "2019-11-27 11:33:27,675 epoch 1 - iter 2/22 - loss 0.71861239 - samples/sec: 32.52\n",
      "2019-11-27 11:33:29,963 epoch 1 - iter 4/22 - loss 0.66550626 - samples/sec: 28.28\n",
      "2019-11-27 11:33:32,379 epoch 1 - iter 6/22 - loss 0.67501398 - samples/sec: 26.62\n",
      "2019-11-27 11:33:34,873 epoch 1 - iter 8/22 - loss 0.65738410 - samples/sec: 25.84\n",
      "2019-11-27 11:33:36,939 epoch 1 - iter 10/22 - loss 0.63565629 - samples/sec: 31.44\n",
      "2019-11-27 11:33:40,306 epoch 1 - iter 12/22 - loss 0.62578197 - samples/sec: 19.07\n",
      "2019-11-27 11:33:42,469 epoch 1 - iter 14/22 - loss 0.62217228 - samples/sec: 29.79\n",
      "2019-11-27 11:33:45,660 epoch 1 - iter 16/22 - loss 0.63071660 - samples/sec: 21.35\n",
      "2019-11-27 11:33:48,023 epoch 1 - iter 18/22 - loss 0.65871892 - samples/sec: 27.23\n",
      "2019-11-27 11:33:50,830 epoch 1 - iter 20/22 - loss 0.65680557 - samples/sec: 22.90\n",
      "2019-11-27 11:33:51,221 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:33:51,221 EPOCH 1 done: loss 0.6644 - lr 0.1000\n",
      "2019-11-27 11:33:54,554 DEV : loss 1.0087348222732544 - score 0.1294\n",
      "2019-11-27 11:33:54,594 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:34:00,771 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:00,775 Testing using best model ...\n",
      "2019-11-27 11:34:00,777 loading file test_csv/title1/best-model.pt\n",
      "2019-11-27 11:34:05,279 0.1905\t0.1905\t0.1905\n",
      "2019-11-27 11:34:05,280 \n",
      "MICRO_AVG: acc 0.1053 - f1-score 0.1905\n",
      "MACRO_AVG: acc 0.0953 - f1-score 0.16\n",
      "fake       tp: 0 - fp: 68 - fn: 0 - tn: 16 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "real       tp: 16 - fp: 0 - fn: 68 - tn: 0 - precision: 1.0000 - recall: 0.1905 - accuracy: 0.1905 - f1-score: 0.3200\n",
      "2019-11-27 11:34:05,282 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:05,284 loading file ./test_csv/title1/best-model.pt\n",
      "acc:  0.5094339622641509\n",
      "precision:  0.45549738219895286\n",
      "recall:  1.0\n",
      "f1:  0.6258992805755396\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/title1'\n",
    "make_test(train_title, test_title, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:34:38,105 Reading data from test_csv/title10\n",
      "2019-11-27 11:34:38,106 Train: test_csv/title10/train.csv\n",
      "2019-11-27 11:34:38,107 Dev: test_csv/title10/dev.csv\n",
      "2019-11-27 11:34:38,108 Test: test_csv/title10/test.csv\n",
      "2019-11-27 11:34:38,111 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:00<00:00, 3098.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:34:38,470 [b'fake', b'real']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:34:39,927 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:39,928 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-27 11:34:39,929 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:39,929 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
      "2019-11-27 11:34:39,929 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:39,930 Parameters:\n",
      "2019-11-27 11:34:39,930  - learning_rate: \"0.1\"\n",
      "2019-11-27 11:34:39,931  - mini_batch_size: \"32\"\n",
      "2019-11-27 11:34:39,932  - patience: \"3\"\n",
      "2019-11-27 11:34:39,933  - anneal_factor: \"0.5\"\n",
      "2019-11-27 11:34:39,934  - max_epochs: \"10\"\n",
      "2019-11-27 11:34:39,934  - shuffle: \"True\"\n",
      "2019-11-27 11:34:39,935  - train_with_dev: \"False\"\n",
      "2019-11-27 11:34:39,936  - batch_growth_annealing: \"False\"\n",
      "2019-11-27 11:34:39,936 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:39,957 Model training base path: \"test_csv/title10\"\n",
      "2019-11-27 11:34:39,957 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:39,959 Device: cpu\n",
      "2019-11-27 11:34:39,960 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:39,960 Embeddings storage mode: cpu\n",
      "2019-11-27 11:34:39,962 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:34:41,262 epoch 1 - iter 0/22 - loss 0.73002851 - samples/sec: 55.57\n",
      "2019-11-27 11:34:43,461 epoch 1 - iter 2/22 - loss 0.70463985 - samples/sec: 29.36\n",
      "2019-11-27 11:34:45,474 epoch 1 - iter 4/22 - loss 0.69936606 - samples/sec: 32.19\n",
      "2019-11-27 11:34:48,071 epoch 1 - iter 6/22 - loss 0.68790513 - samples/sec: 25.05\n",
      "2019-11-27 11:34:50,388 epoch 1 - iter 8/22 - loss 0.68477023 - samples/sec: 27.82\n",
      "2019-11-27 11:34:52,848 epoch 1 - iter 10/22 - loss 0.67726776 - samples/sec: 26.17\n",
      "2019-11-27 11:34:55,376 epoch 1 - iter 12/22 - loss 0.66921083 - samples/sec: 25.72\n",
      "2019-11-27 11:34:57,459 epoch 1 - iter 14/22 - loss 0.65883099 - samples/sec: 30.93\n",
      "2019-11-27 11:34:59,822 epoch 1 - iter 16/22 - loss 0.64964344 - samples/sec: 27.27\n",
      "2019-11-27 11:35:02,641 epoch 1 - iter 18/22 - loss 0.63892033 - samples/sec: 22.95\n",
      "2019-11-27 11:35:04,349 epoch 1 - iter 20/22 - loss 0.63375245 - samples/sec: 37.80\n",
      "2019-11-27 11:35:04,892 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:35:04,893 EPOCH 1 done: loss 0.6246 - lr 0.1000\n",
      "2019-11-27 11:35:08,048 DEV : loss 0.38570666313171387 - score 0.9176\n",
      "2019-11-27 11:35:08,088 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:35:11,117 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:35:12,488 epoch 2 - iter 0/22 - loss 0.56040251 - samples/sec: 53.97\n",
      "2019-11-27 11:35:14,145 epoch 2 - iter 2/22 - loss 0.52227975 - samples/sec: 39.04\n",
      "2019-11-27 11:35:16,060 epoch 2 - iter 4/22 - loss 0.49964541 - samples/sec: 34.24\n",
      "2019-11-27 11:35:18,717 epoch 2 - iter 6/22 - loss 0.48989876 - samples/sec: 24.22\n",
      "2019-11-27 11:35:21,777 epoch 2 - iter 8/22 - loss 0.49891116 - samples/sec: 21.03\n",
      "2019-11-27 11:35:24,361 epoch 2 - iter 10/22 - loss 0.49492020 - samples/sec: 24.96\n",
      "2019-11-27 11:35:26,303 epoch 2 - iter 12/22 - loss 0.49768907 - samples/sec: 33.25\n",
      "2019-11-27 11:35:28,908 epoch 2 - iter 14/22 - loss 0.49331783 - samples/sec: 24.74\n",
      "2019-11-27 11:35:31,439 epoch 2 - iter 16/22 - loss 0.49326972 - samples/sec: 25.54\n",
      "2019-11-27 11:35:34,183 epoch 2 - iter 18/22 - loss 0.48789199 - samples/sec: 23.44\n",
      "2019-11-27 11:35:36,643 epoch 2 - iter 20/22 - loss 0.49058883 - samples/sec: 26.20\n",
      "2019-11-27 11:35:37,099 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:35:37,100 EPOCH 2 done: loss 0.4935 - lr 0.1000\n",
      "2019-11-27 11:35:39,983 DEV : loss 1.9648493528366089 - score 0.0706\n",
      "2019-11-27 11:35:40,017 BAD EPOCHS (no improvement): 1\n",
      "2019-11-27 11:35:40,018 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:35:41,872 epoch 3 - iter 0/22 - loss 0.85481095 - samples/sec: 38.46\n",
      "2019-11-27 11:35:43,850 epoch 3 - iter 2/22 - loss 0.63612582 - samples/sec: 32.59\n",
      "2019-11-27 11:35:45,863 epoch 3 - iter 4/22 - loss 0.56866466 - samples/sec: 32.04\n",
      "2019-11-27 11:35:49,678 epoch 3 - iter 6/22 - loss 0.54080626 - samples/sec: 16.91\n",
      "2019-11-27 11:35:52,573 epoch 3 - iter 8/22 - loss 0.52440411 - samples/sec: 22.23\n",
      "2019-11-27 11:35:54,995 epoch 3 - iter 10/22 - loss 0.51271065 - samples/sec: 26.64\n",
      "2019-11-27 11:35:58,123 epoch 3 - iter 12/22 - loss 0.51211123 - samples/sec: 20.64\n",
      "2019-11-27 11:36:00,666 epoch 3 - iter 14/22 - loss 0.51401355 - samples/sec: 25.32\n",
      "2019-11-27 11:36:03,932 epoch 3 - iter 16/22 - loss 0.51052295 - samples/sec: 19.78\n",
      "2019-11-27 11:36:05,932 epoch 3 - iter 18/22 - loss 0.49460102 - samples/sec: 32.24\n",
      "2019-11-27 11:36:08,161 epoch 3 - iter 20/22 - loss 0.49541380 - samples/sec: 28.93\n",
      "2019-11-27 11:36:08,697 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:36:08,698 EPOCH 3 done: loss 0.5111 - lr 0.1000\n",
      "2019-11-27 11:36:11,530 DEV : loss 1.515805721282959 - score 0.2588\n",
      "2019-11-27 11:36:11,564 BAD EPOCHS (no improvement): 2\n",
      "2019-11-27 11:36:11,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:36:13,441 epoch 4 - iter 0/22 - loss 0.76389235 - samples/sec: 38.38\n",
      "2019-11-27 11:36:15,558 epoch 4 - iter 2/22 - loss 0.59143364 - samples/sec: 30.47\n",
      "2019-11-27 11:36:18,248 epoch 4 - iter 4/22 - loss 0.53473089 - samples/sec: 24.00\n",
      "2019-11-27 11:36:20,420 epoch 4 - iter 6/22 - loss 0.50151672 - samples/sec: 29.74\n",
      "2019-11-27 11:36:22,790 epoch 4 - iter 8/22 - loss 0.47037445 - samples/sec: 27.19\n",
      "2019-11-27 11:36:25,024 epoch 4 - iter 10/22 - loss 0.47095238 - samples/sec: 28.91\n",
      "2019-11-27 11:36:26,840 epoch 4 - iter 12/22 - loss 0.46649755 - samples/sec: 35.60\n",
      "2019-11-27 11:36:29,440 epoch 4 - iter 14/22 - loss 0.45792700 - samples/sec: 24.77\n",
      "2019-11-27 11:36:31,867 epoch 4 - iter 16/22 - loss 0.48006471 - samples/sec: 26.67\n",
      "2019-11-27 11:36:33,846 epoch 4 - iter 18/22 - loss 0.47357180 - samples/sec: 32.63\n",
      "2019-11-27 11:36:36,290 epoch 4 - iter 20/22 - loss 0.46777101 - samples/sec: 26.35\n",
      "2019-11-27 11:36:36,765 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:36:36,766 EPOCH 4 done: loss 0.5325 - lr 0.1000\n",
      "2019-11-27 11:36:39,822 DEV : loss 1.0936050415039062 - score 0.4118\n",
      "2019-11-27 11:36:39,857 BAD EPOCHS (no improvement): 3\n",
      "2019-11-27 11:36:39,857 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:36:41,994 epoch 5 - iter 0/22 - loss 0.54822528 - samples/sec: 33.67\n",
      "2019-11-27 11:36:45,364 epoch 5 - iter 2/22 - loss 0.40774146 - samples/sec: 19.19\n",
      "2019-11-27 11:36:48,399 epoch 5 - iter 4/22 - loss 0.38882354 - samples/sec: 21.25\n",
      "2019-11-27 11:36:51,286 epoch 5 - iter 6/22 - loss 0.38891332 - samples/sec: 22.30\n",
      "2019-11-27 11:36:54,521 epoch 5 - iter 8/22 - loss 0.39174438 - samples/sec: 19.92\n",
      "2019-11-27 11:36:57,106 epoch 5 - iter 10/22 - loss 0.40190487 - samples/sec: 25.00\n",
      "2019-11-27 11:36:59,279 epoch 5 - iter 12/22 - loss 0.42462082 - samples/sec: 29.62\n",
      "2019-11-27 11:37:01,507 epoch 5 - iter 14/22 - loss 0.42426930 - samples/sec: 29.09\n",
      "2019-11-27 11:37:03,474 epoch 5 - iter 16/22 - loss 0.42156408 - samples/sec: 32.80\n",
      "2019-11-27 11:37:05,380 epoch 5 - iter 18/22 - loss 0.43530451 - samples/sec: 33.81\n",
      "2019-11-27 11:37:07,290 epoch 5 - iter 20/22 - loss 0.43234491 - samples/sec: 33.81\n",
      "2019-11-27 11:37:07,970 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:37:07,971 EPOCH 5 done: loss 0.4312 - lr 0.1000\n",
      "2019-11-27 11:37:10,989 DEV : loss 1.7237738370895386 - score 0.2118\n",
      "Epoch     4: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-11-27 11:37:11,031 BAD EPOCHS (no improvement): 4\n",
      "2019-11-27 11:37:11,032 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:37:13,035 epoch 6 - iter 0/22 - loss 0.73525000 - samples/sec: 36.69\n",
      "2019-11-27 11:37:15,489 epoch 6 - iter 2/22 - loss 0.51243466 - samples/sec: 26.43\n",
      "2019-11-27 11:37:17,886 epoch 6 - iter 4/22 - loss 0.46698039 - samples/sec: 26.89\n",
      "2019-11-27 11:37:20,885 epoch 6 - iter 6/22 - loss 0.46576811 - samples/sec: 21.54\n",
      "2019-11-27 11:37:22,658 epoch 6 - iter 8/22 - loss 0.43364820 - samples/sec: 36.34\n",
      "2019-11-27 11:37:24,562 epoch 6 - iter 10/22 - loss 0.42817354 - samples/sec: 33.82\n",
      "2019-11-27 11:37:27,151 epoch 6 - iter 12/22 - loss 0.41383364 - samples/sec: 24.92\n",
      "2019-11-27 11:37:29,732 epoch 6 - iter 14/22 - loss 0.40144135 - samples/sec: 24.94\n",
      "2019-11-27 11:37:31,658 epoch 6 - iter 16/22 - loss 0.39603863 - samples/sec: 33.46\n",
      "2019-11-27 11:37:34,208 epoch 6 - iter 18/22 - loss 0.39530748 - samples/sec: 25.27\n",
      "2019-11-27 11:37:36,408 epoch 6 - iter 20/22 - loss 0.39723188 - samples/sec: 29.26\n",
      "2019-11-27 11:37:36,991 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:37:36,991 EPOCH 6 done: loss 0.3889 - lr 0.0500\n",
      "2019-11-27 11:37:40,012 DEV : loss 0.18344277143478394 - score 0.9412\n",
      "2019-11-27 11:37:40,042 BAD EPOCHS (no improvement): 0\n",
      "2019-11-27 11:37:43,012 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:37:44,459 epoch 7 - iter 0/22 - loss 0.30908889 - samples/sec: 55.11\n",
      "2019-11-27 11:37:46,746 epoch 7 - iter 2/22 - loss 0.28083676 - samples/sec: 28.26\n",
      "2019-11-27 11:37:48,643 epoch 7 - iter 4/22 - loss 0.32699643 - samples/sec: 33.94\n",
      "2019-11-27 11:37:51,233 epoch 7 - iter 6/22 - loss 0.31150108 - samples/sec: 24.84\n",
      "2019-11-27 11:37:53,747 epoch 7 - iter 8/22 - loss 0.32356370 - samples/sec: 25.74\n",
      "2019-11-27 11:37:55,414 epoch 7 - iter 10/22 - loss 0.33991634 - samples/sec: 38.65\n",
      "2019-11-27 11:37:57,975 epoch 7 - iter 12/22 - loss 0.33525559 - samples/sec: 25.11\n",
      "2019-11-27 11:38:00,370 epoch 7 - iter 14/22 - loss 0.33165658 - samples/sec: 26.94\n",
      "2019-11-27 11:38:02,936 epoch 7 - iter 16/22 - loss 0.32405920 - samples/sec: 25.08\n",
      "2019-11-27 11:38:05,332 epoch 7 - iter 18/22 - loss 0.33755073 - samples/sec: 26.83\n",
      "2019-11-27 11:38:08,167 epoch 7 - iter 20/22 - loss 0.34449767 - samples/sec: 22.71\n",
      "2019-11-27 11:38:08,801 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:38:08,801 EPOCH 7 done: loss 0.3559 - lr 0.0500\n",
      "2019-11-27 11:38:11,895 DEV : loss 0.10605574399232864 - score 0.9882\n",
      "2019-11-27 11:38:11,922 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:38:14,768 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:38:17,149 epoch 8 - iter 0/22 - loss 0.47846365 - samples/sec: 31.48\n",
      "2019-11-27 11:38:19,439 epoch 8 - iter 2/22 - loss 0.40870012 - samples/sec: 28.21\n",
      "2019-11-27 11:38:21,175 epoch 8 - iter 4/22 - loss 0.34859429 - samples/sec: 37.14\n",
      "2019-11-27 11:38:23,537 epoch 8 - iter 6/22 - loss 0.37342864 - samples/sec: 27.30\n",
      "2019-11-27 11:38:27,586 epoch 8 - iter 8/22 - loss 0.36093609 - samples/sec: 15.87\n",
      "2019-11-27 11:38:30,625 epoch 8 - iter 10/22 - loss 0.36863031 - samples/sec: 21.15\n",
      "2019-11-27 11:38:33,066 epoch 8 - iter 12/22 - loss 0.35695172 - samples/sec: 26.45\n",
      "2019-11-27 11:38:36,174 epoch 8 - iter 14/22 - loss 0.35123262 - samples/sec: 20.69\n",
      "2019-11-27 11:38:38,897 epoch 8 - iter 16/22 - loss 0.36283661 - samples/sec: 23.63\n",
      "2019-11-27 11:38:40,796 epoch 8 - iter 18/22 - loss 0.37077698 - samples/sec: 33.94\n",
      "2019-11-27 11:38:43,387 epoch 8 - iter 20/22 - loss 0.36751997 - samples/sec: 24.84\n",
      "2019-11-27 11:38:43,999 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:38:44,000 EPOCH 8 done: loss 0.3734 - lr 0.0500\n",
      "2019-11-27 11:38:47,115 DEV : loss 0.10619760304689407 - score 0.9765\n",
      "2019-11-27 11:38:47,146 BAD EPOCHS (no improvement): 1\n",
      "2019-11-27 11:38:47,147 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:38:48,514 epoch 9 - iter 0/22 - loss 0.51239234 - samples/sec: 63.45\n",
      "2019-11-27 11:38:51,529 epoch 9 - iter 2/22 - loss 0.40558754 - samples/sec: 21.38\n",
      "2019-11-27 11:38:53,455 epoch 9 - iter 4/22 - loss 0.39011211 - samples/sec: 33.41\n",
      "2019-11-27 11:38:55,357 epoch 9 - iter 6/22 - loss 0.39524334 - samples/sec: 34.06\n",
      "2019-11-27 11:38:57,559 epoch 9 - iter 8/22 - loss 0.40344390 - samples/sec: 29.22\n",
      "2019-11-27 11:38:59,868 epoch 9 - iter 10/22 - loss 0.38801063 - samples/sec: 27.86\n",
      "2019-11-27 11:39:03,408 epoch 9 - iter 12/22 - loss 0.37152140 - samples/sec: 18.20\n",
      "2019-11-27 11:39:06,840 epoch 9 - iter 14/22 - loss 0.36232657 - samples/sec: 18.72\n",
      "2019-11-27 11:39:10,161 epoch 9 - iter 16/22 - loss 0.35606464 - samples/sec: 19.36\n",
      "2019-11-27 11:39:12,311 epoch 9 - iter 18/22 - loss 0.33978216 - samples/sec: 30.06\n",
      "2019-11-27 11:39:15,098 epoch 9 - iter 20/22 - loss 0.34421812 - samples/sec: 23.09\n",
      "2019-11-27 11:39:15,752 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:39:15,753 EPOCH 9 done: loss 0.3299 - lr 0.0500\n",
      "2019-11-27 11:39:19,599 DEV : loss 0.4437425136566162 - score 0.7882\n",
      "2019-11-27 11:39:19,647 BAD EPOCHS (no improvement): 2\n",
      "2019-11-27 11:39:19,649 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:39:21,442 epoch 10 - iter 0/22 - loss 0.37963292 - samples/sec: 47.91\n",
      "2019-11-27 11:39:24,440 epoch 10 - iter 2/22 - loss 0.37946714 - samples/sec: 21.49\n",
      "2019-11-27 11:39:28,084 epoch 10 - iter 4/22 - loss 0.33985621 - samples/sec: 17.69\n",
      "2019-11-27 11:39:30,606 epoch 10 - iter 6/22 - loss 0.33035437 - samples/sec: 25.49\n",
      "2019-11-27 11:39:33,607 epoch 10 - iter 8/22 - loss 0.32087535 - samples/sec: 21.41\n",
      "2019-11-27 11:39:35,611 epoch 10 - iter 10/22 - loss 0.33333686 - samples/sec: 32.27\n",
      "2019-11-27 11:39:37,716 epoch 10 - iter 12/22 - loss 0.32826106 - samples/sec: 30.56\n",
      "2019-11-27 11:39:39,765 epoch 10 - iter 14/22 - loss 0.31402384 - samples/sec: 31.54\n",
      "2019-11-27 11:39:42,567 epoch 10 - iter 16/22 - loss 0.32019160 - samples/sec: 23.03\n",
      "2019-11-27 11:39:45,257 epoch 10 - iter 18/22 - loss 0.32569852 - samples/sec: 23.90\n",
      "2019-11-27 11:39:47,298 epoch 10 - iter 20/22 - loss 0.32478760 - samples/sec: 31.53\n",
      "2019-11-27 11:39:47,840 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:39:47,841 EPOCH 10 done: loss 0.3303 - lr 0.0500\n",
      "2019-11-27 11:39:51,757 DEV : loss 0.1730353832244873 - score 0.9294\n",
      "2019-11-27 11:39:51,798 BAD EPOCHS (no improvement): 3\n",
      "2019-11-27 11:39:55,101 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:39:55,101 Testing using best model ...\n",
      "2019-11-27 11:39:55,102 loading file test_csv/title10/best-model.pt\n",
      "2019-11-27 11:40:01,846 1.0\t1.0\t1.0\n",
      "2019-11-27 11:40:01,847 \n",
      "MICRO_AVG: acc 1.0 - f1-score 1.0\n",
      "MACRO_AVG: acc 0.5 - f1-score 0.5\n",
      "fake       tp: 0 - fp: 0 - fn: 0 - tn: 84 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "real       tp: 84 - fp: 0 - fn: 0 - tn: 0 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
      "2019-11-27 11:40:01,848 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:01,850 loading file ./test_csv/title10/best-model.pt\n",
      "acc:  0.7735849056603774\n",
      "precision:  0.8679245283018868\n",
      "recall:  0.5287356321839081\n",
      "f1:  0.6571428571428571\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/title10'\n",
    "make_test(train_title, test_title, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "13\n",
      "796\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "train_url = [(x['url'], label) for x, label in train_content] \n",
    "test_url = [(x['url'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_url if x == '']))\n",
    "print(len([x for x, label in test_url if x == '']))\n",
    "train_url = [(x, label) for x, label in train_url if x != ''] \n",
    "test_url = [(x, label) for x, label in test_url if x != '']\n",
    "print(len(train_url))\n",
    "print(len(test_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:40:39,631 Reading data from test_csv/url1\n",
      "2019-11-27 11:40:39,632 Train: test_csv/url1/train.csv\n",
      "2019-11-27 11:40:39,633 Dev: test_csv/url1/dev.csv\n",
      "2019-11-27 11:40:39,633 Test: test_csv/url1/test.csv\n",
      "2019-11-27 11:40:39,643 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:00<00:00, 910.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:40:41,117 [b'fake', b'real']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:40:42,707 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:42,708 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-27 11:40:42,709 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:42,710 Corpus: \"Corpus: 636 train + 80 dev + 80 test sentences\"\n",
      "2019-11-27 11:40:42,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:42,710 Parameters:\n",
      "2019-11-27 11:40:42,711  - learning_rate: \"0.1\"\n",
      "2019-11-27 11:40:42,711  - mini_batch_size: \"32\"\n",
      "2019-11-27 11:40:42,712  - patience: \"3\"\n",
      "2019-11-27 11:40:42,712  - anneal_factor: \"0.5\"\n",
      "2019-11-27 11:40:42,713  - max_epochs: \"1\"\n",
      "2019-11-27 11:40:42,713  - shuffle: \"True\"\n",
      "2019-11-27 11:40:42,714  - train_with_dev: \"False\"\n",
      "2019-11-27 11:40:42,714  - batch_growth_annealing: \"False\"\n",
      "2019-11-27 11:40:42,715 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:42,726 Model training base path: \"test_csv/url1\"\n",
      "2019-11-27 11:40:42,726 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:42,727 Device: cpu\n",
      "2019-11-27 11:40:42,729 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:42,729 Embeddings storage mode: cpu\n",
      "2019-11-27 11:40:42,731 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:40:45,441 epoch 1 - iter 0/20 - loss 0.74317402 - samples/sec: 28.76\n",
      "2019-11-27 11:40:49,016 epoch 1 - iter 2/20 - loss 0.70250938 - samples/sec: 17.97\n",
      "2019-11-27 11:40:52,474 epoch 1 - iter 4/20 - loss 0.66270604 - samples/sec: 18.57\n",
      "2019-11-27 11:40:55,276 epoch 1 - iter 6/20 - loss 0.63783776 - samples/sec: 23.19\n",
      "2019-11-27 11:40:59,663 epoch 1 - iter 8/20 - loss 0.62721086 - samples/sec: 14.63\n",
      "2019-11-27 11:41:03,524 epoch 1 - iter 10/20 - loss 0.60400017 - samples/sec: 16.62\n",
      "2019-11-27 11:41:07,440 epoch 1 - iter 12/20 - loss 0.60525944 - samples/sec: 16.57\n",
      "2019-11-27 11:41:10,616 epoch 1 - iter 14/20 - loss 0.59618705 - samples/sec: 20.24\n",
      "2019-11-27 11:41:13,845 epoch 1 - iter 16/20 - loss 0.58213376 - samples/sec: 20.00\n",
      "2019-11-27 11:41:17,117 epoch 1 - iter 18/20 - loss 0.58289418 - samples/sec: 19.72\n",
      "2019-11-27 11:41:18,522 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:41:18,523 EPOCH 1 done: loss 0.5709 - lr 0.1000\n",
      "2019-11-27 11:41:23,208 DEV : loss 0.6505634784698486 - score 0.65\n",
      "2019-11-27 11:41:23,250 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:41:29,032 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:41:29,034 Testing using best model ...\n",
      "2019-11-27 11:41:29,037 loading file test_csv/url1/best-model.pt\n",
      "2019-11-27 11:41:34,251 0.6875\t0.6875\t0.6875\n",
      "2019-11-27 11:41:34,253 \n",
      "MICRO_AVG: acc 0.5238 - f1-score 0.6875\n",
      "MACRO_AVG: acc 0.3438 - f1-score 0.4074\n",
      "fake       tp: 0 - fp: 25 - fn: 0 - tn: 55 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "real       tp: 55 - fp: 0 - fn: 25 - tn: 0 - precision: 1.0000 - recall: 0.6875 - accuracy: 0.6875 - f1-score: 0.8148\n",
      "2019-11-27 11:41:34,253 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:41:34,255 loading file ./test_csv/url1/best-model.pt\n",
      "acc:  0.6934673366834171\n",
      "precision:  0.8787878787878788\n",
      "recall:  0.3372093023255814\n",
      "f1:  0.48739495798319327\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/url1'\n",
    "make_test(train_url, test_url, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:42:15,261 Reading data from test_csv/url10\n",
      "2019-11-27 11:42:15,263 Train: test_csv/url10/train.csv\n",
      "2019-11-27 11:42:15,263 Dev: test_csv/url10/dev.csv\n",
      "2019-11-27 11:42:15,264 Test: test_csv/url10/test.csv\n",
      "2019-11-27 11:42:15,268 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 636/636 [00:00<00:00, 1400.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:42:16,385 [b'fake', b'real']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:42:17,107 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:17,108 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-27 11:42:17,109 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:17,110 Corpus: \"Corpus: 636 train + 80 dev + 80 test sentences\"\n",
      "2019-11-27 11:42:17,110 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:17,110 Parameters:\n",
      "2019-11-27 11:42:17,111  - learning_rate: \"0.1\"\n",
      "2019-11-27 11:42:17,111  - mini_batch_size: \"32\"\n",
      "2019-11-27 11:42:17,112  - patience: \"3\"\n",
      "2019-11-27 11:42:17,113  - anneal_factor: \"0.5\"\n",
      "2019-11-27 11:42:17,114  - max_epochs: \"10\"\n",
      "2019-11-27 11:42:17,115  - shuffle: \"True\"\n",
      "2019-11-27 11:42:17,116  - train_with_dev: \"False\"\n",
      "2019-11-27 11:42:17,116  - batch_growth_annealing: \"False\"\n",
      "2019-11-27 11:42:17,117 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:17,118 Model training base path: \"test_csv/url10\"\n",
      "2019-11-27 11:42:17,118 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:17,119 Device: cpu\n",
      "2019-11-27 11:42:17,120 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:17,120 Embeddings storage mode: cpu\n",
      "2019-11-27 11:42:17,122 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:19,961 epoch 1 - iter 0/20 - loss 0.72919273 - samples/sec: 28.58\n",
      "2019-11-27 11:42:23,396 epoch 1 - iter 2/20 - loss 0.68151025 - samples/sec: 18.72\n",
      "2019-11-27 11:42:27,263 epoch 1 - iter 4/20 - loss 0.65880415 - samples/sec: 16.59\n",
      "2019-11-27 11:42:30,629 epoch 1 - iter 6/20 - loss 0.62902809 - samples/sec: 19.15\n",
      "2019-11-27 11:42:33,698 epoch 1 - iter 8/20 - loss 0.61004081 - samples/sec: 20.94\n",
      "2019-11-27 11:42:36,719 epoch 1 - iter 10/20 - loss 0.60476736 - samples/sec: 21.27\n",
      "2019-11-27 11:42:39,984 epoch 1 - iter 12/20 - loss 0.59068210 - samples/sec: 19.74\n",
      "2019-11-27 11:42:42,510 epoch 1 - iter 14/20 - loss 0.57503751 - samples/sec: 25.47\n",
      "2019-11-27 11:42:45,545 epoch 1 - iter 16/20 - loss 0.57277547 - samples/sec: 21.17\n",
      "2019-11-27 11:42:48,351 epoch 1 - iter 18/20 - loss 0.58432305 - samples/sec: 22.91\n",
      "2019-11-27 11:42:49,976 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:49,977 EPOCH 1 done: loss 0.5769 - lr 0.1000\n",
      "2019-11-27 11:42:54,778 DEV : loss 0.3830251395702362 - score 0.8125\n",
      "2019-11-27 11:42:54,818 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-27 11:42:57,829 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:42:59,850 epoch 2 - iter 0/20 - loss 0.51298398 - samples/sec: 43.79\n",
      "2019-11-27 11:43:02,981 epoch 2 - iter 2/20 - loss 0.45409431 - samples/sec: 20.58\n",
      "2019-11-27 11:43:06,845 epoch 2 - iter 4/20 - loss 0.49931511 - samples/sec: 16.63\n",
      "2019-11-27 11:43:10,623 epoch 2 - iter 6/20 - loss 0.50904400 - samples/sec: 17.03\n",
      "2019-11-27 11:43:13,581 epoch 2 - iter 8/20 - loss 0.50336256 - samples/sec: 21.83\n",
      "2019-11-27 11:43:16,344 epoch 2 - iter 10/20 - loss 0.50507953 - samples/sec: 23.26\n",
      "2019-11-27 11:43:18,997 epoch 2 - iter 12/20 - loss 0.51089454 - samples/sec: 24.22\n",
      "2019-11-27 11:43:22,152 epoch 2 - iter 14/20 - loss 0.49423039 - samples/sec: 20.43\n",
      "2019-11-27 11:43:25,135 epoch 2 - iter 16/20 - loss 0.47709250 - samples/sec: 21.53\n",
      "2019-11-27 11:43:28,245 epoch 2 - iter 18/20 - loss 0.46806451 - samples/sec: 20.67\n",
      "2019-11-27 11:43:30,223 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:43:30,224 EPOCH 2 done: loss 0.4649 - lr 0.1000\n",
      "2019-11-27 11:43:34,919 DEV : loss 0.49356400966644287 - score 0.7625\n",
      "2019-11-27 11:43:34,962 BAD EPOCHS (no improvement): 1\n",
      "2019-11-27 11:43:34,963 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 11:43:37,276 epoch 3 - iter 0/20 - loss 0.44449434 - samples/sec: 35.89\n",
      "2019-11-27 14:45:28,725 epoch 3 - iter 2/20 - loss 0.41312192 - samples/sec: 0.01\n",
      "2019-11-27 14:45:32,286 epoch 3 - iter 4/20 - loss 0.38531275 - samples/sec: 18.07\n",
      "2019-11-27 14:45:35,395 epoch 3 - iter 6/20 - loss 0.39290197 - samples/sec: 20.69\n",
      "2019-11-27 14:45:39,849 epoch 3 - iter 8/20 - loss 0.39860581 - samples/sec: 14.45\n",
      "2019-11-27 14:45:45,367 epoch 3 - iter 10/20 - loss 0.43869451 - samples/sec: 11.63\n",
      "2019-11-27 14:45:53,029 epoch 3 - iter 12/20 - loss 0.42413494 - samples/sec: 8.38\n",
      "2019-11-27 14:45:59,882 epoch 3 - iter 14/20 - loss 0.43972582 - samples/sec: 9.38\n",
      "2019-11-27 14:46:04,308 epoch 3 - iter 16/20 - loss 0.45549599 - samples/sec: 14.51\n",
      "2019-11-27 14:46:08,241 epoch 3 - iter 18/20 - loss 0.47846638 - samples/sec: 16.34\n",
      "2019-11-27 14:46:10,908 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:46:10,909 EPOCH 3 done: loss 0.4875 - lr 0.1000\n",
      "2019-11-27 14:46:16,478 DEV : loss 0.27530622482299805 - score 0.8625\n",
      "2019-11-27 14:46:16,518 BAD EPOCHS (no improvement): 0\n",
      "2019-11-27 14:46:19,560 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:46:21,846 epoch 4 - iter 0/20 - loss 0.32709271 - samples/sec: 36.84\n",
      "2019-11-27 14:46:25,261 epoch 4 - iter 2/20 - loss 0.32745391 - samples/sec: 18.89\n",
      "2019-11-27 14:46:28,550 epoch 4 - iter 4/20 - loss 0.43183991 - samples/sec: 19.55\n",
      "2019-11-27 14:46:31,814 epoch 4 - iter 6/20 - loss 0.43873119 - samples/sec: 19.67\n",
      "2019-11-27 14:46:34,929 epoch 4 - iter 8/20 - loss 0.43810417 - samples/sec: 20.71\n",
      "2019-11-27 14:46:37,598 epoch 4 - iter 10/20 - loss 0.43086745 - samples/sec: 24.10\n",
      "2019-11-27 14:46:40,768 epoch 4 - iter 12/20 - loss 0.41554453 - samples/sec: 20.34\n",
      "2019-11-27 14:46:44,898 epoch 4 - iter 14/20 - loss 0.42951763 - samples/sec: 15.56\n",
      "2019-11-27 14:46:51,125 epoch 4 - iter 16/20 - loss 0.42928657 - samples/sec: 10.32\n",
      "2019-11-27 14:46:55,921 epoch 4 - iter 18/20 - loss 0.42497616 - samples/sec: 13.40\n",
      "2019-11-27 14:46:58,654 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:46:58,655 EPOCH 4 done: loss 0.4208 - lr 0.1000\n",
      "2019-11-27 14:47:03,716 DEV : loss 0.4541865885257721 - score 0.7625\n",
      "2019-11-27 14:47:03,753 BAD EPOCHS (no improvement): 1\n",
      "2019-11-27 14:47:03,754 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:47:05,919 epoch 5 - iter 0/20 - loss 0.34867480 - samples/sec: 39.39\n",
      "2019-11-27 14:47:09,323 epoch 5 - iter 2/20 - loss 0.46067016 - samples/sec: 18.90\n",
      "2019-11-27 14:47:12,319 epoch 5 - iter 4/20 - loss 0.52085195 - samples/sec: 21.47\n",
      "2019-11-27 14:47:15,242 epoch 5 - iter 6/20 - loss 0.47628881 - samples/sec: 22.06\n",
      "2019-11-27 14:47:18,118 epoch 5 - iter 8/20 - loss 0.45014702 - samples/sec: 22.34\n",
      "2019-11-27 14:47:21,071 epoch 5 - iter 10/20 - loss 0.44923373 - samples/sec: 21.76\n",
      "2019-11-27 14:47:24,591 epoch 5 - iter 12/20 - loss 0.46105399 - samples/sec: 18.30\n",
      "2019-11-27 14:47:27,467 epoch 5 - iter 14/20 - loss 0.44394856 - samples/sec: 22.36\n",
      "2019-11-27 14:47:30,247 epoch 5 - iter 16/20 - loss 0.43502089 - samples/sec: 23.11\n",
      "2019-11-27 14:47:34,112 epoch 5 - iter 18/20 - loss 0.43589033 - samples/sec: 16.63\n",
      "2019-11-27 14:47:37,613 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:47:37,614 EPOCH 5 done: loss 0.4304 - lr 0.1000\n",
      "2019-11-27 14:47:43,775 DEV : loss 0.34907475113868713 - score 0.8375\n",
      "2019-11-27 14:47:43,812 BAD EPOCHS (no improvement): 2\n",
      "2019-11-27 14:47:43,813 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:47:46,614 epoch 6 - iter 0/20 - loss 0.52670795 - samples/sec: 28.41\n",
      "2019-11-27 14:47:50,586 epoch 6 - iter 2/20 - loss 0.43790950 - samples/sec: 16.20\n",
      "2019-11-27 14:47:54,619 epoch 6 - iter 4/20 - loss 0.37787608 - samples/sec: 15.95\n",
      "2019-11-27 14:47:58,428 epoch 6 - iter 6/20 - loss 0.36026692 - samples/sec: 16.91\n",
      "2019-11-27 14:48:03,203 epoch 6 - iter 8/20 - loss 0.37449673 - samples/sec: 13.44\n",
      "2019-11-27 14:48:07,528 epoch 6 - iter 10/20 - loss 0.37294400 - samples/sec: 14.87\n",
      "2019-11-27 14:48:11,654 epoch 6 - iter 12/20 - loss 0.39329330 - samples/sec: 15.61\n",
      "2019-11-27 14:48:15,999 epoch 6 - iter 14/20 - loss 0.39269692 - samples/sec: 14.77\n",
      "2019-11-27 14:48:19,227 epoch 6 - iter 16/20 - loss 0.38454851 - samples/sec: 19.95\n",
      "2019-11-27 14:48:22,633 epoch 6 - iter 18/20 - loss 0.38278106 - samples/sec: 18.90\n",
      "2019-11-27 14:48:24,531 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:48:24,532 EPOCH 6 done: loss 0.3890 - lr 0.1000\n",
      "2019-11-27 14:48:29,925 DEV : loss 0.09179391711950302 - score 1.0\n",
      "2019-11-27 14:48:29,970 BAD EPOCHS (no improvement): 0\n",
      "2019-11-27 14:48:33,613 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-27 14:48:36,444 epoch 7 - iter 0/20 - loss 0.45820940 - samples/sec: 30.86\n",
      "2019-11-27 14:48:40,814 epoch 7 - iter 2/20 - loss 0.36640675 - samples/sec: 14.72\n",
      "2019-11-27 14:48:44,268 epoch 7 - iter 4/20 - loss 0.37941625 - samples/sec: 18.59\n",
      "2019-11-27 14:48:48,661 epoch 7 - iter 6/20 - loss 0.39555894 - samples/sec: 19.86\n",
      "2019-11-27 14:48:51,681 epoch 7 - iter 8/20 - loss 0.44093777 - samples/sec: 21.32\n",
      "2019-11-27 14:48:54,944 epoch 7 - iter 10/20 - loss 0.47317500 - samples/sec: 19.69\n",
      "2019-11-27 14:48:58,998 epoch 7 - iter 12/20 - loss 0.46004126 - samples/sec: 15.87\n",
      "2019-11-27 14:49:04,009 epoch 7 - iter 14/20 - loss 0.45200798 - samples/sec: 12.81\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/url10'\n",
    "make_test(train_url, test_url, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mix = [(x['url'] + ', ' + x['title'], label) for x, label in train_content] \n",
    "test_mix = [(x['url'] + ', ' + x['title'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_mix if x == '']))\n",
    "print(len([x for x, label in test_mix if x == '']))\n",
    "train_mix = [(x, label) for x, label in train_mix if x != ''] \n",
    "test_mix = [(x, label) for x, label in test_mix if x != '']\n",
    "print(len(train_mix))\n",
    "print(len(test_mix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './test_csv/mix1'\n",
    "make_test(train_mix, test_mix, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './test_csv/mix10'\n",
    "make_test(train_mix, test_mix, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
