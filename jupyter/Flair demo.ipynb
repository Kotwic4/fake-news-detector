{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import CSVClassificationCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the word embeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
    "flair_embedding_backward = FlairEmbeddings('news-backward')\n",
    "\n",
    "# initialize the document embeddings, mode = mean\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding,\n",
    "                                              flair_embedding_backward,\n",
    "                                              flair_embedding_forward])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4196"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green . And the sky is blue .')\n",
    "document_embeddings.embed(sentence)\n",
    "len(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4196"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2 = Sentence('The grass is green.')\n",
    "document_embeddings.embed(sentence2)\n",
    "len(sentence2.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_words = ['king', 'monarch', \"queen\", \"emperor\", \"empress\"]\n",
    "fake_words = ['worker', 'dweller', 'resident', 'craftswoman', 'craftsman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_number = 300\n",
    "real_data = [{'label': 'real', 'text': x} for x in np.random.choice(real_words, data_number)]\n",
    "fake_data = [{'label': 'fake', 'text': x} for x in np.random.choice(fake_words, data_number)]\n",
    "data = real_data + fake_data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data = pd.DataFrame(data)\n",
    "frame_data.iloc[0:int(len(data)*0.8)].to_csv('./data/train.csv', sep='\\t', index = False, header = False)\n",
    "frame_data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('./data/test.csv', sep='\\t', index = False, header = False)\n",
    "frame_data.iloc[int(len(data)*0.9):].to_csv('./data/dev.csv', sep='\\t', index = False, header = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-23 22:21:35,231 Reading data from data\n",
      "2019-11-23 22:21:35,232 Train: data/train.csv\n",
      "2019-11-23 22:21:35,233 Dev: data/dev.csv\n",
      "2019-11-23 22:21:35,234 Test: data/test.csv\n",
      "2019-11-23 22:21:35,237 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 480/480 [00:00<00:00, 2543.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-23 22:21:35,573 [b'fake', b'real']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-23 22:21:37,418 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,421 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-23 22:21:37,422 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,422 Corpus: \"Corpus: 480 train + 60 dev + 60 test sentences\"\n",
      "2019-11-23 22:21:37,424 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,426 Parameters:\n",
      "2019-11-23 22:21:37,431  - learning_rate: \"0.1\"\n",
      "2019-11-23 22:21:37,433  - mini_batch_size: \"32\"\n",
      "2019-11-23 22:21:37,435  - patience: \"3\"\n",
      "2019-11-23 22:21:37,436  - anneal_factor: \"0.5\"\n",
      "2019-11-23 22:21:37,437  - max_epochs: \"1\"\n",
      "2019-11-23 22:21:37,437  - shuffle: \"True\"\n",
      "2019-11-23 22:21:37,438  - train_with_dev: \"False\"\n",
      "2019-11-23 22:21:37,439  - batch_growth_annealing: \"False\"\n",
      "2019-11-23 22:21:37,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,465 Model training base path: \"model\"\n",
      "2019-11-23 22:21:37,471 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,472 Device: cpu\n",
      "2019-11-23 22:21:37,473 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,475 Embeddings storage mode: cpu\n",
      "2019-11-23 22:21:37,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:37,988 epoch 1 - iter 0/15 - loss 0.67064863 - samples/sec: 114.42\n",
      "2019-11-23 22:21:38,331 epoch 1 - iter 1/15 - loss 0.64998382 - samples/sec: 99.79\n",
      "2019-11-23 22:21:38,676 epoch 1 - iter 2/15 - loss 0.61262085 - samples/sec: 97.91\n",
      "2019-11-23 22:21:39,058 epoch 1 - iter 3/15 - loss 0.58659095 - samples/sec: 87.65\n",
      "2019-11-23 22:21:39,461 epoch 1 - iter 4/15 - loss 0.55020483 - samples/sec: 83.34\n",
      "2019-11-23 22:21:39,762 epoch 1 - iter 5/15 - loss 0.51382280 - samples/sec: 136.93\n",
      "2019-11-23 22:21:40,018 epoch 1 - iter 6/15 - loss 0.48066110 - samples/sec: 134.97\n",
      "2019-11-23 22:21:40,264 epoch 1 - iter 7/15 - loss 0.45707447 - samples/sec: 139.27\n",
      "2019-11-23 22:21:40,557 epoch 1 - iter 8/15 - loss 0.42779113 - samples/sec: 124.26\n",
      "2019-11-23 22:21:40,805 epoch 1 - iter 9/15 - loss 0.40636447 - samples/sec: 140.60\n",
      "2019-11-23 22:21:41,053 epoch 1 - iter 10/15 - loss 0.38800210 - samples/sec: 146.13\n",
      "2019-11-23 22:21:41,286 epoch 1 - iter 11/15 - loss 0.37115223 - samples/sec: 150.78\n",
      "2019-11-23 22:21:41,506 epoch 1 - iter 12/15 - loss 0.35374029 - samples/sec: 155.03\n",
      "2019-11-23 22:21:41,729 epoch 1 - iter 13/15 - loss 0.33911882 - samples/sec: 160.99\n",
      "2019-11-23 22:21:41,952 epoch 1 - iter 14/15 - loss 0.32245121 - samples/sec: 154.11\n",
      "2019-11-23 22:21:42,020 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:42,021 EPOCH 1 done: loss 0.3225 - lr 0.1000\n",
      "2019-11-23 22:21:42,572 DEV : loss 0.07174180448055267 - score 1.0\n",
      "2019-11-23 22:21:42,586 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-23 22:21:50,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-23 22:21:50,807 Testing using best model ...\n",
      "2019-11-23 22:21:50,808 loading file model/best-model.pt\n",
      "2019-11-23 22:21:53,561 1.0\t1.0\t1.0\n",
      "2019-11-23 22:21:53,563 \n",
      "MICRO_AVG: acc 1.0 - f1-score 1.0\n",
      "MACRO_AVG: acc 1.0 - f1-score 1.0\n",
      "fake       tp: 32 - fp: 0 - fn: 0 - tn: 28 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
      "real       tp: 28 - fp: 0 - fn: 0 - tn: 32 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
      "2019-11-23 22:21:53,564 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 1.0,\n",
       " 'dev_score_history': [1.0],\n",
       " 'train_loss_history': [0.3224512050549189],\n",
       " 'dev_loss_history': [tensor(0.0717)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name_map = {1: \"text\", 0: \"label\"}\n",
    "\n",
    "corpus = CSVClassificationCorpus('data',\n",
    "                                 column_name_map,\n",
    "                                 delimiter='\\t',\n",
    "                              test_file='test.csv',\n",
    "                              dev_file='dev.csv',\n",
    "                              train_file='train.csv')\n",
    "\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "word_embeddings = [\n",
    "    WordEmbeddings('glove'),\n",
    "    FlairEmbeddings('news-forward-fast'),\n",
    "    FlairEmbeddings('news-backward-fast')\n",
    "]\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                            hidden_size=512,\n",
    "                                            reproject_words=True,\n",
    "                                            reproject_words_dimension=256)\n",
    "\n",
    "classifier = TextClassifier(document_embeddings,\n",
    "                            label_dictionary=label_dict)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "trainer.train('model', max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-23 22:21:53,618 loading file ./model/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "classifier = TextClassifier.load('./model/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "    return sentence.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[real (0.9592270255088806)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king [real (0.9592270255088806)]\n",
      "monarch [real (0.9225751757621765)]\n",
      "queen [real (0.9279063940048218)]\n",
      "emperor [real (0.9752405881881714)]\n",
      "empress [real (0.9544050693511963)]\n",
      "\n",
      "worker [fake (0.9427129626274109)]\n",
      "dweller [fake (0.9414699077606201)]\n",
      "resident [fake (0.9087944626808167)]\n",
      "craftswoman [fake (0.8037753701210022)]\n",
      "craftsman [fake (0.9538108110427856)]\n"
     ]
    }
   ],
   "source": [
    "for w in real_words:\n",
    "    print(w, predict(w))\n",
    "    \n",
    "print()\n",
    "\n",
    "for w in fake_words:\n",
    "    print(w, predict(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[real (0.8956785202026367)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"prince\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[fake (0.6483678817749023)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"hammer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[real (0.8655360341072083)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"crown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[fake (0.7046210169792175)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[real (0.8526270389556885)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"kingdom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[real (0.7863451242446899)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"lord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[fake (0.8844714164733887)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"farmer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[real (0.7795140743255615)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"palace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
