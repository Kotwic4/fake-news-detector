{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../fakenewsnet_dataset/dataset'\n",
    "DATASET_NAME = 'politifact'\n",
    "DATASET_PATH = '{}/{}'.format(DATA_PATH, DATASET_NAME)\n",
    "REAL_DATA_PATH = '{}_real.csv'.format(DATASET_PATH)\n",
    "FAKE_DATA_PATH = '{}_fake.csv'.format(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_arts = pd.read_csv(FAKE_DATA_PATH, na_values=['nan'], keep_default_na=False)\n",
    "real_arts = pd.read_csv(REAL_DATA_PATH, na_values=['nan'], keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_art_data_frame(df):\n",
    "    return [{'id': id, 'url': url, 'title': title} for id, url, title, tweets in df.values]\n",
    "    \n",
    "fake_arts_with_content = parse_art_data_frame(fake_arts)\n",
    "real_arts_with_content = parse_art_data_frame(real_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = [(art, 'fake') for art in fake_arts_with_content]\n",
    "real_data = [(art, 'real') for art in real_arts_with_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(fake_data)\n",
    "np.random.shuffle(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fake_data[0:int(len(fake_data)*0.8)] + real_data[0:int(len(real_data)*0.8)]\n",
    "test_data = fake_data[int(len(fake_data)*0.8):] + real_data[int(len(real_data)*0.8):]\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844\n",
      "212\n",
      "1056\n",
      "1056\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(train_data) + len(test_data))\n",
    "print(len(fake_data) + len(real_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def predict(self, text):\n",
    "        text = clear_text(text)\n",
    "        sentence = Sentence(text)\n",
    "        self.classifier.predict(sentence)\n",
    "        return sentence.labels[0]\n",
    "\n",
    "def transform_data(data):\n",
    "    return [{'label': label, 'text': clear_text(x)} for x, label in data]\n",
    "\n",
    "def save_data(data, data_folder = '.'):\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    data = transform_data(data)\n",
    "    frame_data = pd.DataFrame(data)\n",
    "    train_path = '{}/train.csv'.format(data_folder)\n",
    "    test_path = '{}/test.csv'.format(data_folder)\n",
    "    dev_path = '{}/dev.csv'.format(data_folder)\n",
    "    frame_data.iloc[0:int(len(data)*0.8)].to_csv(train_path, sep='\\t', index = False, header = False)\n",
    "    frame_data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv(test_path, sep='\\t', index = False, header = False)\n",
    "    frame_data.iloc[int(len(data)*0.9):].to_csv(dev_path, sep='\\t', index = False, header = False)\n",
    "\n",
    "def load_corpus(data_folder = '.'):\n",
    "    column_name_map = {1: \"text\", 0: \"label\"}\n",
    "    return CSVClassificationCorpus(data_folder,\n",
    "                                     column_name_map,\n",
    "                                     delimiter='\\t',\n",
    "                                  test_file='test.csv',\n",
    "                                  dev_file='dev.csv',\n",
    "                                  train_file='train.csv')\n",
    "    \n",
    "def train_classifier(corpus, model_folder = '.', max_epochs = 1):\n",
    "    label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "    word_embeddings = [\n",
    "        WordEmbeddings('glove'),\n",
    "        FlairEmbeddings('news-forward-fast'),\n",
    "        FlairEmbeddings('news-backward-fast')\n",
    "    ]\n",
    "\n",
    "    document_embeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                hidden_size=512,\n",
    "                                                reproject_words=True,\n",
    "                                                reproject_words_dimension=256)\n",
    "\n",
    "    classifier = TextClassifier(document_embeddings,\n",
    "                                label_dictionary=label_dict)\n",
    "\n",
    "    trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "    trainer.train(model_folder, max_epochs=max_epochs)\n",
    "    \n",
    "    return TextClassifier.load('{}/best-model.pt'.format(model_folder))\n",
    "    \n",
    "def train_model(train_data,\n",
    "               data_folder = '.',\n",
    "               model_folder = '.',\n",
    "               max_epochs=1\n",
    "               ):\n",
    "    save_data(train_data, data_folder)\n",
    "    corpus = load_corpus(data_folder)\n",
    "    classifier = train_classifier(corpus, model_folder, max_epochs)\n",
    "    return Classifier(classifier)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, pos_label = 'fake'):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=pos_label)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=pos_label)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "def validate_model(test_data, classifier):\n",
    "    y_true = [label for x, label in test_data]\n",
    "    y_pred = [classifier.predict(x).value for x, label in test_data]\n",
    "    acc, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
    "    print(\"acc: \", acc)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1: \", f1)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "def make_test(train_data, test_data, data_folder, model_folder, max_epochs):\n",
    "    classifier = train_model(train_data, data_folder, model_folder, max_epochs)\n",
    "    validate_model(test_data, classifier)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content = [(x, label) for x, label in train_data] \n",
    "test_content = [(x, label) for x, label in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "844\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "train_title = [(x['title'], label) for x, label in train_content] \n",
    "test_title = [(x['title'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_title if x == '']))\n",
    "print(len([x for x, label in test_title if x == '']))\n",
    "train_title = [(x, label) for x, label in train_title if x != ''] \n",
    "test_title = [(x, label) for x, label in test_title if x != '']\n",
    "print(len(train_title))\n",
    "print(len(test_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:12:31,661 Reading data from test_csv/title1\n",
      "2019-11-24 12:12:31,662 Train: test_csv/title1/train.csv\n",
      "2019-11-24 12:12:31,663 Dev: test_csv/title1/dev.csv\n",
      "2019-11-24 12:12:31,665 Test: test_csv/title1/test.csv\n",
      "2019-11-24 12:12:31,672 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:00<00:00, 2709.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:12:32,142 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:12:33,751 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:33,752 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 12:12:33,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:33,753 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
      "2019-11-24 12:12:33,754 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:33,754 Parameters:\n",
      "2019-11-24 12:12:33,755  - learning_rate: \"0.1\"\n",
      "2019-11-24 12:12:33,755  - mini_batch_size: \"32\"\n",
      "2019-11-24 12:12:33,757  - patience: \"3\"\n",
      "2019-11-24 12:12:33,757  - anneal_factor: \"0.5\"\n",
      "2019-11-24 12:12:33,758  - max_epochs: \"1\"\n",
      "2019-11-24 12:12:33,758  - shuffle: \"True\"\n",
      "2019-11-24 12:12:33,759  - train_with_dev: \"False\"\n",
      "2019-11-24 12:12:33,774  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 12:12:33,778 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:33,779 Model training base path: \"test_csv/title1\"\n",
      "2019-11-24 12:12:33,780 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:33,787 Device: cpu\n",
      "2019-11-24 12:12:33,790 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:33,791 Embeddings storage mode: cpu\n",
      "2019-11-24 12:12:33,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:12:35,893 epoch 1 - iter 0/22 - loss 0.71580696 - samples/sec: 34.25\n",
      "2019-11-24 12:12:37,924 epoch 1 - iter 2/22 - loss 0.68485812 - samples/sec: 31.84\n",
      "2019-11-24 12:12:40,346 epoch 1 - iter 4/22 - loss 0.67322880 - samples/sec: 26.67\n",
      "2019-11-24 12:12:42,911 epoch 1 - iter 6/22 - loss 0.65307019 - samples/sec: 25.26\n",
      "2019-11-24 12:12:45,555 epoch 1 - iter 8/22 - loss 0.63348600 - samples/sec: 24.35\n",
      "2019-11-24 12:12:49,104 epoch 1 - iter 10/22 - loss 0.62450510 - samples/sec: 18.16\n",
      "2019-11-24 12:12:52,141 epoch 1 - iter 12/22 - loss 0.61854380 - samples/sec: 21.29\n",
      "2019-11-24 12:12:54,741 epoch 1 - iter 14/22 - loss 0.60885560 - samples/sec: 24.78\n",
      "2019-11-24 12:12:56,675 epoch 1 - iter 16/22 - loss 0.59325451 - samples/sec: 33.56\n",
      "2019-11-24 12:12:59,493 epoch 1 - iter 18/22 - loss 0.58349455 - samples/sec: 22.90\n",
      "2019-11-24 12:13:02,159 epoch 1 - iter 20/22 - loss 0.57424057 - samples/sec: 24.13\n",
      "2019-11-24 12:13:02,938 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:02,939 EPOCH 1 done: loss 0.5679 - lr 0.1000\n",
      "2019-11-24 12:13:08,032 DEV : loss 0.5629549026489258 - score 0.7176\n",
      "2019-11-24 12:13:08,136 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:13:14,913 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:14,915 Testing using best model ...\n",
      "2019-11-24 12:13:14,919 loading file test_csv/title1/best-model.pt\n",
      "2019-11-24 12:13:19,557 0.75\t0.75\t0.75\n",
      "2019-11-24 12:13:19,559 \n",
      "MICRO_AVG: acc 0.6 - f1-score 0.75\n",
      "MACRO_AVG: acc 0.5834 - f1-score 0.73335\n",
      "fake       tp: 21 - fp: 3 - fn: 18 - tn: 42 - precision: 0.8750 - recall: 0.5385 - accuracy: 0.5000 - f1-score: 0.6667\n",
      "real       tp: 42 - fp: 18 - fn: 3 - tn: 21 - precision: 0.7000 - recall: 0.9333 - accuracy: 0.6667 - f1-score: 0.8000\n",
      "2019-11-24 12:13:19,559 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:19,561 loading file ./test_csv/title1/best-model.pt\n",
      "acc:  0.7547169811320755\n",
      "precision:  0.8888888888888888\n",
      "recall:  0.45977011494252873\n",
      "f1:  0.6060606060606061\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/title1'\n",
    "make_test(train_title, test_title, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:13:55,353 Reading data from test_csv/title10\n",
      "2019-11-24 12:13:55,354 Train: test_csv/title10/train.csv\n",
      "2019-11-24 12:13:55,355 Dev: test_csv/title10/dev.csv\n",
      "2019-11-24 12:13:55,356 Test: test_csv/title10/test.csv\n",
      "2019-11-24 12:13:55,361 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:00<00:00, 1783.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:13:56,093 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:13:57,721 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:57,725 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 12:13:57,727 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:57,728 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
      "2019-11-24 12:13:57,729 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:57,729 Parameters:\n",
      "2019-11-24 12:13:57,730  - learning_rate: \"0.1\"\n",
      "2019-11-24 12:13:57,730  - mini_batch_size: \"32\"\n",
      "2019-11-24 12:13:57,731  - patience: \"3\"\n",
      "2019-11-24 12:13:57,731  - anneal_factor: \"0.5\"\n",
      "2019-11-24 12:13:57,732  - max_epochs: \"10\"\n",
      "2019-11-24 12:13:57,732  - shuffle: \"True\"\n",
      "2019-11-24 12:13:57,733  - train_with_dev: \"False\"\n",
      "2019-11-24 12:13:57,734  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 12:13:57,734 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:57,738 Model training base path: \"test_csv/title10\"\n",
      "2019-11-24 12:13:57,750 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:57,753 Device: cpu\n",
      "2019-11-24 12:13:57,753 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:57,754 Embeddings storage mode: cpu\n",
      "2019-11-24 12:13:57,757 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:13:59,841 epoch 1 - iter 0/22 - loss 0.73186839 - samples/sec: 36.21\n",
      "2019-11-24 12:14:02,889 epoch 1 - iter 2/22 - loss 0.69975718 - samples/sec: 21.52\n",
      "2019-11-24 12:14:05,008 epoch 1 - iter 4/22 - loss 0.69500808 - samples/sec: 30.39\n",
      "2019-11-24 12:14:07,824 epoch 1 - iter 6/22 - loss 0.68215388 - samples/sec: 23.07\n",
      "2019-11-24 12:14:11,825 epoch 1 - iter 8/22 - loss 0.65899465 - samples/sec: 16.09\n",
      "2019-11-24 12:14:14,996 epoch 1 - iter 10/22 - loss 0.64734416 - samples/sec: 20.38\n",
      "2019-11-24 12:14:17,180 epoch 1 - iter 12/22 - loss 0.64378874 - samples/sec: 29.52\n",
      "2019-11-24 12:14:19,332 epoch 1 - iter 14/22 - loss 0.63319663 - samples/sec: 30.08\n",
      "2019-11-24 12:14:22,807 epoch 1 - iter 16/22 - loss 0.62119171 - samples/sec: 18.56\n",
      "2019-11-24 12:14:24,724 epoch 1 - iter 18/22 - loss 0.61309906 - samples/sec: 33.58\n",
      "2019-11-24 12:14:26,955 epoch 1 - iter 20/22 - loss 0.60483279 - samples/sec: 28.93\n",
      "2019-11-24 12:14:27,543 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:14:27,544 EPOCH 1 done: loss 0.6144 - lr 0.1000\n",
      "2019-11-24 12:14:31,337 DEV : loss 0.6883397102355957 - score 0.6118\n",
      "2019-11-24 12:14:31,385 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:14:33,986 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:14:36,127 epoch 2 - iter 0/22 - loss 0.83200014 - samples/sec: 34.47\n",
      "2019-11-24 12:14:39,152 epoch 2 - iter 2/22 - loss 0.60657870 - samples/sec: 21.31\n",
      "2019-11-24 12:14:41,253 epoch 2 - iter 4/22 - loss 0.56062165 - samples/sec: 30.73\n",
      "2019-11-24 12:14:43,446 epoch 2 - iter 6/22 - loss 0.56072778 - samples/sec: 29.44\n",
      "2019-11-24 12:14:45,830 epoch 2 - iter 8/22 - loss 0.53798973 - samples/sec: 26.98\n",
      "2019-11-24 12:14:47,950 epoch 2 - iter 10/22 - loss 0.50823598 - samples/sec: 30.63\n",
      "2019-11-24 12:14:50,729 epoch 2 - iter 12/22 - loss 0.50241212 - samples/sec: 23.14\n",
      "2019-11-24 12:14:54,127 epoch 2 - iter 14/22 - loss 0.50276741 - samples/sec: 18.90\n",
      "2019-11-24 12:14:56,614 epoch 2 - iter 16/22 - loss 0.49032348 - samples/sec: 25.99\n",
      "2019-11-24 12:15:00,199 epoch 2 - iter 18/22 - loss 0.49319046 - samples/sec: 17.93\n",
      "2019-11-24 12:15:03,699 epoch 2 - iter 20/22 - loss 0.48475509 - samples/sec: 18.43\n",
      "2019-11-24 12:15:04,759 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:15:04,760 EPOCH 2 done: loss 0.4814 - lr 0.1000\n",
      "2019-11-24 12:15:09,556 DEV : loss 0.9752599596977234 - score 0.6235\n",
      "2019-11-24 12:15:09,607 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:15:13,194 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:15:14,862 epoch 3 - iter 0/22 - loss 1.12093890 - samples/sec: 47.52\n",
      "2019-11-24 12:15:17,786 epoch 3 - iter 2/22 - loss 0.68515261 - samples/sec: 22.14\n",
      "2019-11-24 12:15:20,283 epoch 3 - iter 4/22 - loss 0.57046925 - samples/sec: 25.81\n",
      "2019-11-24 12:15:22,331 epoch 3 - iter 6/22 - loss 0.51720166 - samples/sec: 31.59\n",
      "2019-11-24 12:15:25,037 epoch 3 - iter 8/22 - loss 0.50318012 - samples/sec: 23.83\n",
      "2019-11-24 12:15:28,490 epoch 3 - iter 10/22 - loss 0.50597396 - samples/sec: 18.64\n",
      "2019-11-24 12:15:31,610 epoch 3 - iter 12/22 - loss 0.49785333 - samples/sec: 20.64\n",
      "2019-11-24 12:15:33,544 epoch 3 - iter 14/22 - loss 0.49039357 - samples/sec: 33.56\n",
      "2019-11-24 12:15:35,615 epoch 3 - iter 16/22 - loss 0.48999025 - samples/sec: 31.11\n",
      "2019-11-24 12:15:38,652 epoch 3 - iter 18/22 - loss 0.49356095 - samples/sec: 21.21\n",
      "2019-11-24 12:15:41,544 epoch 3 - iter 20/22 - loss 0.48283214 - samples/sec: 22.24\n",
      "2019-11-24 12:15:42,085 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:15:42,086 EPOCH 3 done: loss 0.4849 - lr 0.1000\n",
      "2019-11-24 12:15:45,960 DEV : loss 0.45504137873649597 - score 0.7882\n",
      "2019-11-24 12:15:46,006 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:15:49,073 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:15:50,351 epoch 4 - iter 0/22 - loss 0.22469963 - samples/sec: 68.37\n",
      "2019-11-24 12:15:52,826 epoch 4 - iter 2/22 - loss 0.27912534 - samples/sec: 26.17\n",
      "2019-11-24 12:15:55,677 epoch 4 - iter 4/22 - loss 0.33620035 - samples/sec: 22.58\n",
      "2019-11-24 12:16:01,417 epoch 4 - iter 6/22 - loss 0.39518969 - samples/sec: 11.18\n",
      "2019-11-24 12:16:04,667 epoch 4 - iter 8/22 - loss 0.40793237 - samples/sec: 19.92\n",
      "2019-11-24 12:16:07,361 epoch 4 - iter 10/22 - loss 0.42665221 - samples/sec: 24.04\n",
      "2019-11-24 12:16:10,446 epoch 4 - iter 12/22 - loss 0.41596153 - samples/sec: 20.84\n",
      "2019-11-24 12:16:14,248 epoch 4 - iter 14/22 - loss 0.42175644 - samples/sec: 17.03\n",
      "2019-11-24 12:16:16,629 epoch 4 - iter 16/22 - loss 0.41709885 - samples/sec: 27.23\n",
      "2019-11-24 12:16:19,727 epoch 4 - iter 18/22 - loss 0.41780410 - samples/sec: 20.74\n",
      "2019-11-24 12:16:23,745 epoch 4 - iter 20/22 - loss 0.41712817 - samples/sec: 16.02\n",
      "2019-11-24 12:16:24,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:16:24,467 EPOCH 4 done: loss 0.4195 - lr 0.1000\n",
      "2019-11-24 12:16:28,818 DEV : loss 0.5868441462516785 - score 0.7176\n",
      "2019-11-24 12:16:28,873 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:16:28,874 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:16:31,059 epoch 5 - iter 0/22 - loss 0.48876667 - samples/sec: 37.13\n",
      "2019-11-24 12:16:33,825 epoch 5 - iter 2/22 - loss 0.44584803 - samples/sec: 23.44\n",
      "2019-11-24 12:16:37,102 epoch 5 - iter 4/22 - loss 0.52444896 - samples/sec: 19.66\n",
      "2019-11-24 12:16:40,142 epoch 5 - iter 6/22 - loss 0.48395041 - samples/sec: 21.15\n",
      "2019-11-24 12:16:42,658 epoch 5 - iter 8/22 - loss 0.46528618 - samples/sec: 25.64\n",
      "2019-11-24 12:16:45,844 epoch 5 - iter 10/22 - loss 0.44019287 - samples/sec: 20.26\n",
      "2019-11-24 12:16:47,898 epoch 5 - iter 12/22 - loss 0.42086709 - samples/sec: 31.36\n",
      "2019-11-24 12:16:49,901 epoch 5 - iter 14/22 - loss 0.42242035 - samples/sec: 32.14\n",
      "2019-11-24 12:16:52,959 epoch 5 - iter 16/22 - loss 0.42227201 - samples/sec: 21.09\n",
      "2019-11-24 12:16:55,084 epoch 5 - iter 18/22 - loss 0.41821145 - samples/sec: 30.29\n",
      "2019-11-24 12:16:58,491 epoch 5 - iter 20/22 - loss 0.40445131 - samples/sec: 18.88\n",
      "2019-11-24 12:16:59,239 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:16:59,240 EPOCH 5 done: loss 0.4034 - lr 0.1000\n",
      "2019-11-24 12:17:03,165 DEV : loss 0.42298659682273865 - score 0.8353\n",
      "2019-11-24 12:17:03,221 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:17:06,805 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:17:09,109 epoch 6 - iter 0/22 - loss 0.40028012 - samples/sec: 35.41\n",
      "2019-11-24 12:17:11,481 epoch 6 - iter 2/22 - loss 0.43195572 - samples/sec: 27.16\n",
      "2019-11-24 12:17:14,435 epoch 6 - iter 4/22 - loss 0.42962711 - samples/sec: 21.81\n",
      "2019-11-24 12:17:17,503 epoch 6 - iter 6/22 - loss 0.41305633 - samples/sec: 21.02\n",
      "2019-11-24 12:17:20,509 epoch 6 - iter 8/22 - loss 0.39331734 - samples/sec: 21.41\n",
      "2019-11-24 12:17:24,190 epoch 6 - iter 10/22 - loss 0.38254623 - samples/sec: 17.50\n",
      "2019-11-24 12:17:26,659 epoch 6 - iter 12/22 - loss 0.39318662 - samples/sec: 26.16\n",
      "2019-11-24 12:17:29,606 epoch 6 - iter 14/22 - loss 0.41522882 - samples/sec: 21.86\n",
      "2019-11-24 12:17:31,991 epoch 6 - iter 16/22 - loss 0.40996124 - samples/sec: 27.01\n",
      "2019-11-24 12:17:34,541 epoch 6 - iter 18/22 - loss 0.39497030 - samples/sec: 25.34\n",
      "2019-11-24 12:17:36,882 epoch 6 - iter 20/22 - loss 0.38800117 - samples/sec: 27.52\n",
      "2019-11-24 12:17:37,669 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:17:37,670 EPOCH 6 done: loss 0.3775 - lr 0.1000\n",
      "2019-11-24 12:17:41,743 DEV : loss 0.41052353382110596 - score 0.8353\n",
      "2019-11-24 12:17:41,798 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:17:44,970 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:17:46,482 epoch 7 - iter 0/22 - loss 0.22932787 - samples/sec: 59.61\n",
      "2019-11-24 12:17:49,104 epoch 7 - iter 2/22 - loss 0.28526386 - samples/sec: 24.69\n",
      "2019-11-24 12:17:52,129 epoch 7 - iter 4/22 - loss 0.38400977 - samples/sec: 21.30\n",
      "2019-11-24 12:17:55,284 epoch 7 - iter 6/22 - loss 0.36412957 - samples/sec: 20.38\n",
      "2019-11-24 12:17:57,884 epoch 7 - iter 8/22 - loss 0.36040660 - samples/sec: 24.92\n",
      "2019-11-24 12:18:00,798 epoch 7 - iter 10/22 - loss 0.34966318 - samples/sec: 22.09\n",
      "2019-11-24 12:18:02,950 epoch 7 - iter 12/22 - loss 0.38785120 - samples/sec: 30.07\n",
      "2019-11-24 12:18:06,359 epoch 7 - iter 14/22 - loss 0.40645752 - samples/sec: 18.88\n",
      "2019-11-24 12:18:08,479 epoch 7 - iter 16/22 - loss 0.39131597 - samples/sec: 30.45\n",
      "2019-11-24 12:18:10,441 epoch 7 - iter 18/22 - loss 0.38867453 - samples/sec: 33.09\n",
      "2019-11-24 12:18:14,108 epoch 7 - iter 20/22 - loss 0.38050982 - samples/sec: 17.52\n",
      "2019-11-24 12:18:14,663 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:18:14,664 EPOCH 7 done: loss 0.3699 - lr 0.1000\n",
      "2019-11-24 12:18:18,809 DEV : loss 0.5712733864784241 - score 0.7059\n",
      "2019-11-24 12:18:18,875 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 12:18:18,876 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:18:20,685 epoch 8 - iter 0/22 - loss 0.26477787 - samples/sec: 49.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:18:23,027 epoch 8 - iter 2/22 - loss 0.25025801 - samples/sec: 27.59\n",
      "2019-11-24 12:18:26,214 epoch 8 - iter 4/22 - loss 0.29075018 - samples/sec: 20.23\n",
      "2019-11-24 12:18:29,271 epoch 8 - iter 6/22 - loss 0.26344068 - samples/sec: 21.11\n",
      "2019-11-24 12:18:31,161 epoch 8 - iter 8/22 - loss 0.24776872 - samples/sec: 34.20\n",
      "2019-11-24 12:18:33,903 epoch 8 - iter 10/22 - loss 0.27362899 - samples/sec: 23.55\n",
      "2019-11-24 12:18:36,990 epoch 8 - iter 12/22 - loss 0.30034924 - samples/sec: 20.87\n",
      "2019-11-24 12:18:40,108 epoch 8 - iter 14/22 - loss 0.29200192 - samples/sec: 20.62\n",
      "2019-11-24 12:18:43,150 epoch 8 - iter 16/22 - loss 0.31749090 - samples/sec: 21.21\n",
      "2019-11-24 12:18:46,267 epoch 8 - iter 18/22 - loss 0.31883654 - samples/sec: 20.64\n",
      "2019-11-24 12:18:48,601 epoch 8 - iter 20/22 - loss 0.31931001 - samples/sec: 27.60\n",
      "2019-11-24 12:18:49,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:18:49,280 EPOCH 8 done: loss 0.3055 - lr 0.1000\n",
      "2019-11-24 12:18:53,518 DEV : loss 0.45752599835395813 - score 0.8118\n",
      "2019-11-24 12:18:53,567 BAD EPOCHS (no improvement): 3\n",
      "2019-11-24 12:18:53,569 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:18:55,606 epoch 9 - iter 0/22 - loss 0.41534439 - samples/sec: 46.34\n",
      "2019-11-24 12:18:59,720 epoch 9 - iter 2/22 - loss 0.54110286 - samples/sec: 15.63\n",
      "2019-11-24 12:19:02,173 epoch 9 - iter 4/22 - loss 0.41865834 - samples/sec: 26.33\n",
      "2019-11-24 12:19:04,460 epoch 9 - iter 6/22 - loss 0.38813563 - samples/sec: 28.30\n",
      "2019-11-24 12:19:07,816 epoch 9 - iter 8/22 - loss 0.36091887 - samples/sec: 19.21\n",
      "2019-11-24 12:19:09,635 epoch 9 - iter 10/22 - loss 0.34089920 - samples/sec: 35.44\n",
      "2019-11-24 12:19:11,800 epoch 9 - iter 12/22 - loss 0.34843945 - samples/sec: 29.75\n",
      "2019-11-24 12:19:15,797 epoch 9 - iter 14/22 - loss 0.34696790 - samples/sec: 16.10\n",
      "2019-11-24 12:19:18,425 epoch 9 - iter 16/22 - loss 0.36228403 - samples/sec: 24.49\n",
      "2019-11-24 12:19:20,515 epoch 9 - iter 18/22 - loss 0.40977424 - samples/sec: 30.81\n",
      "2019-11-24 12:19:23,915 epoch 9 - iter 20/22 - loss 0.40437792 - samples/sec: 18.95\n",
      "2019-11-24 12:19:24,665 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:19:24,666 EPOCH 9 done: loss 0.3920 - lr 0.1000\n",
      "2019-11-24 12:19:29,128 DEV : loss 0.3984542191028595 - score 0.8588\n",
      "2019-11-24 12:19:29,185 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:19:32,712 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:19:35,272 epoch 10 - iter 0/22 - loss 0.34791395 - samples/sec: 32.74\n",
      "2019-11-24 12:19:38,249 epoch 10 - iter 2/22 - loss 0.28925752 - samples/sec: 21.67\n",
      "2019-11-24 12:19:40,983 epoch 10 - iter 4/22 - loss 0.27285837 - samples/sec: 23.53\n",
      "2019-11-24 12:19:43,519 epoch 10 - iter 6/22 - loss 0.28924410 - samples/sec: 25.46\n",
      "2019-11-24 12:19:45,535 epoch 10 - iter 8/22 - loss 0.30325841 - samples/sec: 32.04\n",
      "2019-11-24 12:19:47,525 epoch 10 - iter 10/22 - loss 0.30926978 - samples/sec: 32.40\n",
      "2019-11-24 12:19:49,905 epoch 10 - iter 12/22 - loss 0.29533104 - samples/sec: 27.12\n",
      "2019-11-24 12:19:52,726 epoch 10 - iter 14/22 - loss 0.31311848 - samples/sec: 22.84\n",
      "2019-11-24 12:19:55,519 epoch 10 - iter 16/22 - loss 0.31321492 - samples/sec: 23.10\n",
      "2019-11-24 12:19:57,906 epoch 10 - iter 18/22 - loss 0.31907200 - samples/sec: 27.08\n",
      "2019-11-24 12:20:01,000 epoch 10 - iter 20/22 - loss 0.32045646 - samples/sec: 20.84\n",
      "2019-11-24 12:20:01,810 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:01,811 EPOCH 10 done: loss 0.3269 - lr 0.1000\n",
      "2019-11-24 12:20:06,083 DEV : loss 0.6734439730644226 - score 0.7059\n",
      "2019-11-24 12:20:06,131 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:20:09,058 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:09,059 Testing using best model ...\n",
      "2019-11-24 12:20:09,059 loading file test_csv/title10/best-model.pt\n",
      "2019-11-24 12:20:15,271 0.75\t0.75\t0.75\n",
      "2019-11-24 12:20:15,272 \n",
      "MICRO_AVG: acc 0.6 - f1-score 0.75\n",
      "MACRO_AVG: acc 0.5971 - f1-score 0.7471\n",
      "fake       tp: 27 - fp: 9 - fn: 12 - tn: 36 - precision: 0.7500 - recall: 0.6923 - accuracy: 0.5625 - f1-score: 0.7200\n",
      "real       tp: 36 - fp: 12 - fn: 9 - tn: 27 - precision: 0.7500 - recall: 0.8000 - accuracy: 0.6316 - f1-score: 0.7742\n",
      "2019-11-24 12:20:15,273 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:15,275 loading file ./test_csv/title10/best-model.pt\n",
      "acc:  0.8254716981132075\n",
      "precision:  0.7659574468085106\n",
      "recall:  0.8275862068965517\n",
      "f1:  0.7955801104972374\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/title10'\n",
    "make_test(train_title, test_title, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "6\n",
      "789\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "train_url = [(x['url'], label) for x, label in train_content] \n",
    "test_url = [(x['url'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_url if x == '']))\n",
    "print(len([x for x, label in test_url if x == '']))\n",
    "train_url = [(x, label) for x, label in train_url if x != ''] \n",
    "test_url = [(x, label) for x, label in test_url if x != '']\n",
    "print(len(train_url))\n",
    "print(len(test_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:20:50,843 Reading data from test_csv/url1\n",
      "2019-11-24 12:20:50,845 Train: test_csv/url1/train.csv\n",
      "2019-11-24 12:20:50,846 Dev: test_csv/url1/dev.csv\n",
      "2019-11-24 12:20:50,849 Test: test_csv/url1/test.csv\n",
      "2019-11-24 12:20:50,854 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:00<00:00, 1204.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:20:52,213 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:20:53,423 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:53,424 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 12:20:53,425 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:53,425 Corpus: \"Corpus: 631 train + 79 dev + 79 test sentences\"\n",
      "2019-11-24 12:20:53,426 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:53,427 Parameters:\n",
      "2019-11-24 12:20:53,428  - learning_rate: \"0.1\"\n",
      "2019-11-24 12:20:53,429  - mini_batch_size: \"32\"\n",
      "2019-11-24 12:20:53,430  - patience: \"3\"\n",
      "2019-11-24 12:20:53,430  - anneal_factor: \"0.5\"\n",
      "2019-11-24 12:20:53,431  - max_epochs: \"1\"\n",
      "2019-11-24 12:20:53,431  - shuffle: \"True\"\n",
      "2019-11-24 12:20:53,432  - train_with_dev: \"False\"\n",
      "2019-11-24 12:20:53,433  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 12:20:53,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:53,435 Model training base path: \"test_csv/url1\"\n",
      "2019-11-24 12:20:53,437 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:53,438 Device: cpu\n",
      "2019-11-24 12:20:53,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:53,440 Embeddings storage mode: cpu\n",
      "2019-11-24 12:20:53,442 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:20:55,949 epoch 1 - iter 0/20 - loss 0.66106552 - samples/sec: 36.58\n",
      "2019-11-24 12:20:59,289 epoch 1 - iter 2/20 - loss 0.67374045 - samples/sec: 19.28\n",
      "2019-11-24 12:21:03,981 epoch 1 - iter 4/20 - loss 0.66934286 - samples/sec: 13.70\n",
      "2019-11-24 12:21:08,564 epoch 1 - iter 6/20 - loss 0.66655474 - samples/sec: 14.07\n",
      "2019-11-24 12:21:12,885 epoch 1 - iter 8/20 - loss 0.64644206 - samples/sec: 14.87\n",
      "2019-11-24 12:21:16,133 epoch 1 - iter 10/20 - loss 0.63663877 - samples/sec: 19.83\n",
      "2019-11-24 12:21:20,025 epoch 1 - iter 12/20 - loss 0.61300495 - samples/sec: 16.56\n",
      "2019-11-24 12:21:26,260 epoch 1 - iter 14/20 - loss 0.59276337 - samples/sec: 10.30\n",
      "2019-11-24 12:21:33,096 epoch 1 - iter 16/20 - loss 0.58871606 - samples/sec: 9.41\n",
      "2019-11-24 12:21:38,025 epoch 1 - iter 18/20 - loss 0.56539864 - samples/sec: 13.07\n",
      "2019-11-24 12:21:39,980 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:21:39,981 EPOCH 1 done: loss 0.5551 - lr 0.1000\n",
      "2019-11-24 12:21:48,700 DEV : loss 0.5507956743240356 - score 0.7468\n",
      "2019-11-24 12:21:48,759 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:21:54,010 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:21:54,010 Testing using best model ...\n",
      "2019-11-24 12:21:54,011 loading file test_csv/url1/best-model.pt\n",
      "2019-11-24 12:22:01,503 0.7089\t0.7089\t0.7089\n",
      "2019-11-24 12:22:01,505 \n",
      "MICRO_AVG: acc 0.549 - f1-score 0.7089\n",
      "MACRO_AVG: acc 0.5447 - f1-score 0.70415\n",
      "fake       tp: 23 - fp: 7 - fn: 16 - tn: 33 - precision: 0.7667 - recall: 0.5897 - accuracy: 0.5000 - f1-score: 0.6667\n",
      "real       tp: 33 - fp: 16 - fn: 7 - tn: 23 - precision: 0.6735 - recall: 0.8250 - accuracy: 0.5893 - f1-score: 0.7416\n",
      "2019-11-24 12:22:01,506 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:22:01,508 loading file ./test_csv/url1/best-model.pt\n",
      "acc:  0.5776699029126213\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/url1'\n",
    "make_test(train_url, test_url, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:22:56,141 Reading data from test_csv/url10\n",
      "2019-11-24 12:22:56,142 Train: test_csv/url10/train.csv\n",
      "2019-11-24 12:22:56,143 Dev: test_csv/url10/dev.csv\n",
      "2019-11-24 12:22:56,143 Test: test_csv/url10/test.csv\n",
      "2019-11-24 12:22:56,150 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [00:01<00:00, 519.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:22:58,546 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:23:01,499 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:01,500 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 12:23:01,504 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:01,506 Corpus: \"Corpus: 631 train + 79 dev + 79 test sentences\"\n",
      "2019-11-24 12:23:01,508 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:01,509 Parameters:\n",
      "2019-11-24 12:23:01,510  - learning_rate: \"0.1\"\n",
      "2019-11-24 12:23:01,514  - mini_batch_size: \"32\"\n",
      "2019-11-24 12:23:01,515  - patience: \"3\"\n",
      "2019-11-24 12:23:01,515  - anneal_factor: \"0.5\"\n",
      "2019-11-24 12:23:01,517  - max_epochs: \"10\"\n",
      "2019-11-24 12:23:01,526  - shuffle: \"True\"\n",
      "2019-11-24 12:23:01,530  - train_with_dev: \"False\"\n",
      "2019-11-24 12:23:01,537  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 12:23:01,538 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:01,573 Model training base path: \"test_csv/url10\"\n",
      "2019-11-24 12:23:01,579 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:01,580 Device: cpu\n",
      "2019-11-24 12:23:01,582 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:01,583 Embeddings storage mode: cpu\n",
      "2019-11-24 12:23:01,586 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:06,065 epoch 1 - iter 0/20 - loss 0.66660184 - samples/sec: 19.53\n",
      "2019-11-24 12:23:11,092 epoch 1 - iter 2/20 - loss 0.64689734 - samples/sec: 12.82\n",
      "2019-11-24 12:23:15,352 epoch 1 - iter 4/20 - loss 0.64642191 - samples/sec: 15.07\n",
      "2019-11-24 12:23:20,514 epoch 1 - iter 6/20 - loss 0.62837040 - samples/sec: 12.47\n",
      "2019-11-24 12:23:24,442 epoch 1 - iter 8/20 - loss 0.60670243 - samples/sec: 16.37\n",
      "2019-11-24 12:23:28,022 epoch 1 - iter 10/20 - loss 0.60275695 - samples/sec: 17.94\n",
      "2019-11-24 12:23:33,498 epoch 1 - iter 12/20 - loss 0.58875135 - samples/sec: 11.74\n",
      "2019-11-24 12:23:37,296 epoch 1 - iter 14/20 - loss 0.57399206 - samples/sec: 16.93\n",
      "2019-11-24 12:23:41,650 epoch 1 - iter 16/20 - loss 0.56765643 - samples/sec: 14.75\n",
      "2019-11-24 12:23:44,979 epoch 1 - iter 18/20 - loss 0.55923971 - samples/sec: 19.35\n",
      "2019-11-24 12:23:46,908 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:23:46,908 EPOCH 1 done: loss 0.5476 - lr 0.1000\n",
      "2019-11-24 12:23:52,804 DEV : loss 0.6054553985595703 - score 0.7595\n",
      "2019-11-24 12:23:52,859 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:23:55,715 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:23:58,291 epoch 2 - iter 0/20 - loss 0.48626927 - samples/sec: 34.59\n",
      "2019-11-24 12:24:01,466 epoch 2 - iter 2/20 - loss 0.44420094 - samples/sec: 20.34\n",
      "2019-11-24 12:24:05,637 epoch 2 - iter 4/20 - loss 0.45653231 - samples/sec: 15.39\n",
      "2019-11-24 12:24:09,732 epoch 2 - iter 6/20 - loss 0.48278280 - samples/sec: 15.70\n",
      "2019-11-24 12:24:14,451 epoch 2 - iter 8/20 - loss 0.48724232 - samples/sec: 13.63\n",
      "2019-11-24 12:24:18,707 epoch 2 - iter 10/20 - loss 0.48095619 - samples/sec: 15.09\n",
      "2019-11-24 12:24:23,062 epoch 2 - iter 12/20 - loss 0.48030254 - samples/sec: 14.79\n",
      "2019-11-24 12:24:27,948 epoch 2 - iter 14/20 - loss 0.48882272 - samples/sec: 13.16\n",
      "2019-11-24 12:24:32,958 epoch 2 - iter 16/20 - loss 0.47248939 - samples/sec: 12.81\n",
      "2019-11-24 12:24:37,197 epoch 2 - iter 18/20 - loss 0.46479473 - samples/sec: 15.16\n",
      "2019-11-24 12:24:39,287 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:24:39,288 EPOCH 2 done: loss 0.4636 - lr 0.1000\n",
      "2019-11-24 12:24:45,837 DEV : loss 0.5528895258903503 - score 0.8101\n",
      "2019-11-24 12:24:45,889 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:24:49,356 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:24:51,748 epoch 3 - iter 0/20 - loss 0.46509558 - samples/sec: 37.51\n",
      "2019-11-24 12:24:56,308 epoch 3 - iter 2/20 - loss 0.46704109 - samples/sec: 14.11\n",
      "2019-11-24 12:24:59,963 epoch 3 - iter 4/20 - loss 0.43706079 - samples/sec: 17.60\n",
      "2019-11-24 12:25:04,518 epoch 3 - iter 6/20 - loss 0.42334333 - samples/sec: 14.15\n",
      "2019-11-24 12:25:08,552 epoch 3 - iter 8/20 - loss 0.40575897 - samples/sec: 15.97\n",
      "2019-11-24 12:25:13,819 epoch 3 - iter 10/20 - loss 0.40367129 - samples/sec: 12.22\n",
      "2019-11-24 12:25:18,905 epoch 3 - iter 12/20 - loss 0.45829602 - samples/sec: 12.66\n",
      "2019-11-24 12:25:23,559 epoch 3 - iter 14/20 - loss 0.43167629 - samples/sec: 13.80\n",
      "2019-11-24 12:25:27,494 epoch 3 - iter 16/20 - loss 0.42709588 - samples/sec: 16.38\n",
      "2019-11-24 12:25:30,985 epoch 3 - iter 18/20 - loss 0.44775842 - samples/sec: 18.43\n",
      "2019-11-24 12:25:32,798 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:25:32,798 EPOCH 3 done: loss 0.4429 - lr 0.1000\n",
      "2019-11-24 12:25:38,602 DEV : loss 0.6074779629707336 - score 0.8101\n",
      "2019-11-24 12:25:38,650 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:25:42,051 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:25:44,928 epoch 4 - iter 0/20 - loss 0.43063208 - samples/sec: 29.75\n",
      "2019-11-24 12:25:48,271 epoch 4 - iter 2/20 - loss 0.37696557 - samples/sec: 19.27\n",
      "2019-11-24 12:25:51,397 epoch 4 - iter 4/20 - loss 0.38819964 - samples/sec: 20.57\n",
      "2019-11-24 12:25:54,819 epoch 4 - iter 6/20 - loss 0.36553099 - samples/sec: 18.86\n",
      "2019-11-24 12:25:57,930 epoch 4 - iter 8/20 - loss 0.36589954 - samples/sec: 20.67\n",
      "2019-11-24 12:26:01,172 epoch 4 - iter 10/20 - loss 0.36565251 - samples/sec: 19.86\n",
      "2019-11-24 12:26:05,216 epoch 4 - iter 12/20 - loss 0.35964915 - samples/sec: 15.94\n",
      "2019-11-24 12:26:10,916 epoch 4 - iter 14/20 - loss 0.35770531 - samples/sec: 11.26\n",
      "2019-11-24 12:26:15,473 epoch 4 - iter 16/20 - loss 0.36291001 - samples/sec: 14.09\n",
      "2019-11-24 12:26:20,195 epoch 4 - iter 18/20 - loss 0.37532361 - samples/sec: 13.62\n",
      "2019-11-24 12:26:23,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:26:23,461 EPOCH 4 done: loss 0.3851 - lr 0.1000\n",
      "2019-11-24 12:26:31,903 DEV : loss 0.7813005447387695 - score 0.7089\n",
      "2019-11-24 12:26:31,949 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 12:26:31,950 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:26:35,636 epoch 5 - iter 0/20 - loss 0.36719501 - samples/sec: 23.17\n",
      "2019-11-24 12:26:40,090 epoch 5 - iter 2/20 - loss 0.35901351 - samples/sec: 14.42\n",
      "2019-11-24 12:26:43,293 epoch 5 - iter 4/20 - loss 0.38667692 - samples/sec: 20.13\n",
      "2019-11-24 12:26:47,809 epoch 5 - iter 6/20 - loss 0.36565753 - samples/sec: 14.25\n",
      "2019-11-24 12:26:51,802 epoch 5 - iter 8/20 - loss 0.37910497 - samples/sec: 16.09\n",
      "2019-11-24 12:26:56,315 epoch 5 - iter 10/20 - loss 0.35653515 - samples/sec: 14.27\n",
      "2019-11-24 12:27:00,639 epoch 5 - iter 12/20 - loss 0.35916675 - samples/sec: 14.86\n",
      "2019-11-24 12:27:04,023 epoch 5 - iter 14/20 - loss 0.37500283 - samples/sec: 18.99\n",
      "2019-11-24 12:27:07,417 epoch 5 - iter 16/20 - loss 0.36838800 - samples/sec: 18.97\n",
      "2019-11-24 12:27:11,370 epoch 5 - iter 18/20 - loss 0.37605423 - samples/sec: 16.26\n",
      "2019-11-24 12:27:12,979 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:27:12,980 EPOCH 5 done: loss 0.3738 - lr 0.1000\n",
      "2019-11-24 12:27:18,836 DEV : loss 0.6071061491966248 - score 0.8354\n",
      "2019-11-24 12:27:18,883 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:27:21,975 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:27:25,042 epoch 6 - iter 0/20 - loss 0.31539896 - samples/sec: 27.91\n",
      "2019-11-24 12:27:28,350 epoch 6 - iter 2/20 - loss 0.28172645 - samples/sec: 19.45\n",
      "2019-11-24 12:27:31,933 epoch 6 - iter 4/20 - loss 0.31644332 - samples/sec: 17.93\n",
      "2019-11-24 12:27:35,840 epoch 6 - iter 6/20 - loss 0.35827478 - samples/sec: 16.45\n",
      "2019-11-24 12:27:39,198 epoch 6 - iter 8/20 - loss 0.42348524 - samples/sec: 19.17\n",
      "2019-11-24 12:27:42,712 epoch 6 - iter 10/20 - loss 0.40765011 - samples/sec: 18.28\n",
      "2019-11-24 12:27:45,837 epoch 6 - iter 12/20 - loss 0.40347011 - samples/sec: 20.61\n",
      "2019-11-24 12:27:49,413 epoch 6 - iter 14/20 - loss 0.38623917 - samples/sec: 17.99\n",
      "2019-11-24 12:27:52,986 epoch 6 - iter 16/20 - loss 0.38072181 - samples/sec: 17.98\n",
      "2019-11-24 12:27:56,357 epoch 6 - iter 18/20 - loss 0.37688226 - samples/sec: 19.11\n",
      "2019-11-24 12:27:58,875 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:27:58,876 EPOCH 6 done: loss 0.3820 - lr 0.1000\n",
      "2019-11-24 12:28:04,607 DEV : loss 0.5538709163665771 - score 0.8354\n",
      "2019-11-24 12:28:04,651 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:28:07,977 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:28:11,809 epoch 7 - iter 0/20 - loss 0.55676979 - samples/sec: 23.21\n",
      "2019-11-24 12:28:16,245 epoch 7 - iter 2/20 - loss 0.42185626 - samples/sec: 14.52\n",
      "2019-11-24 12:28:19,833 epoch 7 - iter 4/20 - loss 0.35728542 - samples/sec: 17.90\n",
      "2019-11-24 12:28:23,142 epoch 7 - iter 6/20 - loss 0.38197863 - samples/sec: 19.41\n",
      "2019-11-24 12:28:26,763 epoch 7 - iter 8/20 - loss 0.36321563 - samples/sec: 17.80\n",
      "2019-11-24 12:28:29,530 epoch 7 - iter 10/20 - loss 0.36318213 - samples/sec: 23.29\n",
      "2019-11-24 12:28:33,565 epoch 7 - iter 12/20 - loss 0.35315581 - samples/sec: 15.91\n",
      "2019-11-24 12:28:36,995 epoch 7 - iter 14/20 - loss 0.36252655 - samples/sec: 18.74\n",
      "2019-11-24 12:28:40,844 epoch 7 - iter 16/20 - loss 0.37445891 - samples/sec: 16.71\n",
      "2019-11-24 12:28:44,475 epoch 7 - iter 18/20 - loss 0.37584523 - samples/sec: 17.69\n",
      "2019-11-24 12:28:46,235 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:28:46,236 EPOCH 7 done: loss 0.3764 - lr 0.1000\n",
      "2019-11-24 12:28:51,849 DEV : loss 0.5595110058784485 - score 0.8481\n",
      "2019-11-24 12:28:51,891 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:28:55,064 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:28:57,415 epoch 8 - iter 0/20 - loss 0.43234119 - samples/sec: 38.44\n",
      "2019-11-24 12:29:00,943 epoch 8 - iter 2/20 - loss 0.36655982 - samples/sec: 18.25\n",
      "2019-11-24 12:29:03,937 epoch 8 - iter 4/20 - loss 0.35773223 - samples/sec: 21.46\n",
      "2019-11-24 12:29:07,701 epoch 8 - iter 6/20 - loss 0.34253863 - samples/sec: 17.09\n",
      "2019-11-24 12:29:11,171 epoch 8 - iter 8/20 - loss 0.31422728 - samples/sec: 18.55\n",
      "2019-11-24 12:29:14,856 epoch 8 - iter 10/20 - loss 0.33031617 - samples/sec: 17.42\n",
      "2019-11-24 12:29:18,249 epoch 8 - iter 12/20 - loss 0.32590352 - samples/sec: 18.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:29:22,282 epoch 8 - iter 14/20 - loss 0.33203665 - samples/sec: 15.94\n",
      "2019-11-24 12:29:25,706 epoch 8 - iter 16/20 - loss 0.33968798 - samples/sec: 18.76\n",
      "2019-11-24 12:29:28,980 epoch 8 - iter 18/20 - loss 0.34494895 - samples/sec: 19.64\n",
      "2019-11-24 12:29:30,512 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:29:30,513 EPOCH 8 done: loss 0.3557 - lr 0.1000\n",
      "2019-11-24 12:29:36,236 DEV : loss 0.543102502822876 - score 0.8481\n",
      "2019-11-24 12:29:36,277 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:29:39,347 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:29:41,858 epoch 9 - iter 0/20 - loss 0.30012253 - samples/sec: 36.82\n",
      "2019-11-24 12:29:45,286 epoch 9 - iter 2/20 - loss 0.39369624 - samples/sec: 18.77\n",
      "2019-11-24 12:29:48,799 epoch 9 - iter 4/20 - loss 0.44359489 - samples/sec: 18.31\n",
      "2019-11-24 12:29:52,297 epoch 9 - iter 6/20 - loss 0.41848513 - samples/sec: 18.41\n",
      "2019-11-24 12:29:56,222 epoch 9 - iter 8/20 - loss 0.38195982 - samples/sec: 16.37\n",
      "2019-11-24 12:29:59,611 epoch 9 - iter 10/20 - loss 0.38144111 - samples/sec: 18.98\n",
      "2019-11-24 12:30:03,062 epoch 9 - iter 12/20 - loss 0.36992345 - samples/sec: 18.67\n",
      "2019-11-24 12:30:06,155 epoch 9 - iter 14/20 - loss 0.36118534 - samples/sec: 20.80\n",
      "2019-11-24 12:30:10,313 epoch 9 - iter 16/20 - loss 0.35321125 - samples/sec: 15.46\n",
      "2019-11-24 12:30:13,857 epoch 9 - iter 18/20 - loss 0.35127947 - samples/sec: 18.13\n",
      "2019-11-24 12:30:15,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:30:15,552 EPOCH 9 done: loss 0.3526 - lr 0.1000\n",
      "2019-11-24 12:30:21,384 DEV : loss 0.5960184931755066 - score 0.8481\n",
      "2019-11-24 12:30:21,426 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 12:30:24,358 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:30:26,836 epoch 10 - iter 0/20 - loss 0.32488340 - samples/sec: 38.98\n",
      "2019-11-24 12:30:30,864 epoch 10 - iter 2/20 - loss 0.28789376 - samples/sec: 15.95\n",
      "2019-11-24 12:30:34,153 epoch 10 - iter 4/20 - loss 0.30724164 - samples/sec: 19.56\n",
      "2019-11-24 12:30:37,379 epoch 10 - iter 6/20 - loss 0.35610664 - samples/sec: 19.95\n",
      "2019-11-24 12:30:40,704 epoch 10 - iter 8/20 - loss 0.33321235 - samples/sec: 19.33\n",
      "2019-11-24 12:30:44,322 epoch 10 - iter 10/20 - loss 0.35998823 - samples/sec: 17.79\n",
      "2019-11-24 12:30:47,980 epoch 10 - iter 12/20 - loss 0.35376102 - samples/sec: 17.59\n",
      "2019-11-24 12:30:52,594 epoch 10 - iter 14/20 - loss 0.37867098 - samples/sec: 13.92\n",
      "2019-11-24 12:30:56,113 epoch 10 - iter 16/20 - loss 0.37398876 - samples/sec: 18.27\n",
      "2019-11-24 12:30:59,699 epoch 10 - iter 18/20 - loss 0.37471858 - samples/sec: 17.93\n",
      "2019-11-24 12:31:01,770 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:31:01,771 EPOCH 10 done: loss 0.3680 - lr 0.1000\n",
      "2019-11-24 12:31:07,845 DEV : loss 0.6769692897796631 - score 0.7595\n",
      "2019-11-24 12:31:07,887 BAD EPOCHS (no improvement): 3\n",
      "2019-11-24 12:31:10,729 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:31:10,743 Testing using best model ...\n",
      "2019-11-24 12:31:10,745 loading file test_csv/url10/best-model.pt\n",
      "2019-11-24 12:31:18,561 0.7848\t0.7848\t0.7848\n",
      "2019-11-24 12:31:18,563 \n",
      "MICRO_AVG: acc 0.6458 - f1-score 0.7848\n",
      "MACRO_AVG: acc 0.6444 - f1-score 0.78355\n",
      "fake       tp: 28 - fp: 6 - fn: 11 - tn: 34 - precision: 0.8235 - recall: 0.7179 - accuracy: 0.6222 - f1-score: 0.7671\n",
      "real       tp: 34 - fp: 11 - fn: 6 - tn: 28 - precision: 0.7556 - recall: 0.8500 - accuracy: 0.6667 - f1-score: 0.8000\n",
      "2019-11-24 12:31:18,564 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:31:18,566 loading file ./test_csv/url10/best-model.pt\n",
      "acc:  0.7621359223300971\n",
      "precision:  0.7375\n",
      "recall:  0.6781609195402298\n",
      "f1:  0.7065868263473054\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/url10'\n",
    "make_test(train_url, test_url, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "844\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "train_mix = [(x['url'] + ', ' + x['title'], label) for x, label in train_content] \n",
    "test_mix = [(x['url'] + ', ' + x['title'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_mix if x == '']))\n",
    "print(len([x for x, label in test_mix if x == '']))\n",
    "train_mix = [(x, label) for x, label in train_mix if x != ''] \n",
    "test_mix = [(x, label) for x, label in test_mix if x != '']\n",
    "print(len(train_mix))\n",
    "print(len(test_mix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:40:23,281 Reading data from test_csv/mix1\n",
      "2019-11-24 12:40:23,282 Train: test_csv/mix1/train.csv\n",
      "2019-11-24 12:40:23,283 Dev: test_csv/mix1/dev.csv\n",
      "2019-11-24 12:40:23,284 Test: test_csv/mix1/test.csv\n",
      "2019-11-24 12:40:23,289 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:01<00:00, 415.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:40:26,444 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:40:28,183 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:28,184 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 12:40:28,185 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:28,186 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
      "2019-11-24 12:40:28,186 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:28,187 Parameters:\n",
      "2019-11-24 12:40:28,188  - learning_rate: \"0.1\"\n",
      "2019-11-24 12:40:28,190  - mini_batch_size: \"32\"\n",
      "2019-11-24 12:40:28,191  - patience: \"3\"\n",
      "2019-11-24 12:40:28,192  - anneal_factor: \"0.5\"\n",
      "2019-11-24 12:40:28,193  - max_epochs: \"1\"\n",
      "2019-11-24 12:40:28,195  - shuffle: \"True\"\n",
      "2019-11-24 12:40:28,198  - train_with_dev: \"False\"\n",
      "2019-11-24 12:40:28,201  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 12:40:28,203 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:28,205 Model training base path: \"test_csv/mix1\"\n",
      "2019-11-24 12:40:28,207 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:28,209 Device: cpu\n",
      "2019-11-24 12:40:28,215 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:28,218 Embeddings storage mode: cpu\n",
      "2019-11-24 12:40:28,224 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:40:33,946 epoch 1 - iter 0/22 - loss 0.77211881 - samples/sec: 14.92\n",
      "2019-11-24 12:40:42,513 epoch 1 - iter 2/22 - loss 0.77658580 - samples/sec: 7.49\n",
      "2019-11-24 12:40:49,601 epoch 1 - iter 4/22 - loss 0.74236267 - samples/sec: 9.05\n",
      "2019-11-24 12:40:53,945 epoch 1 - iter 6/22 - loss 0.70006612 - samples/sec: 14.92\n",
      "2019-11-24 12:40:59,539 epoch 1 - iter 8/22 - loss 0.67241652 - samples/sec: 11.47\n",
      "2019-11-24 12:41:06,091 epoch 1 - iter 10/22 - loss 0.66881111 - samples/sec: 9.79\n",
      "2019-11-24 12:41:12,128 epoch 1 - iter 12/22 - loss 0.66816616 - samples/sec: 10.66\n",
      "2019-11-24 12:41:19,340 epoch 1 - iter 14/22 - loss 0.65755189 - samples/sec: 8.89\n",
      "2019-11-24 12:41:31,887 epoch 1 - iter 16/22 - loss 0.65168301 - samples/sec: 5.11\n",
      "2019-11-24 12:41:38,955 epoch 1 - iter 18/22 - loss 0.64027187 - samples/sec: 9.17\n",
      "2019-11-24 12:41:45,313 epoch 1 - iter 20/22 - loss 0.63511097 - samples/sec: 10.09\n",
      "2019-11-24 12:41:47,237 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:41:47,238 EPOCH 1 done: loss 0.6325 - lr 0.1000\n",
      "2019-11-24 12:41:58,994 DEV : loss 0.73826664686203 - score 0.6118\n",
      "2019-11-24 12:41:59,073 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:42:05,598 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:42:05,599 Testing using best model ...\n",
      "2019-11-24 12:42:05,600 loading file test_csv/mix1/best-model.pt\n",
      "2019-11-24 12:42:16,177 0.5357\t0.5357\t0.5357\n",
      "2019-11-24 12:42:16,178 \n",
      "MICRO_AVG: acc 0.3659 - f1-score 0.5357\n",
      "MACRO_AVG: acc 0.2678 - f1-score 0.34885\n",
      "fake       tp: 0 - fp: 0 - fn: 39 - tn: 45 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "real       tp: 45 - fp: 39 - fn: 0 - tn: 0 - precision: 0.5357 - recall: 1.0000 - accuracy: 0.5357 - f1-score: 0.6977\n",
      "2019-11-24 12:42:16,179 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:42:16,181 loading file ./test_csv/mix1/best-model.pt\n",
      "acc:  0.6084905660377359\n",
      "precision:  1.0\n",
      "recall:  0.04597701149425287\n",
      "f1:  0.08791208791208792\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/mix1'\n",
    "make_test(train_mix, test_mix, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:51:15,602 Reading data from test_csv/mix10\n",
      "2019-11-24 12:51:15,603 Train: test_csv/mix10/train.csv\n",
      "2019-11-24 12:51:15,603 Dev: test_csv/mix10/dev.csv\n",
      "2019-11-24 12:51:15,604 Test: test_csv/mix10/test.csv\n",
      "2019-11-24 12:51:15,608 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 675/675 [00:00<00:00, 2648.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:51:15,962 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:51:17,488 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:17,489 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 12:51:17,490 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:17,491 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
      "2019-11-24 12:51:17,491 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:17,492 Parameters:\n",
      "2019-11-24 12:51:17,493  - learning_rate: \"0.1\"\n",
      "2019-11-24 12:51:17,493  - mini_batch_size: \"32\"\n",
      "2019-11-24 12:51:17,494  - patience: \"3\"\n",
      "2019-11-24 12:51:17,495  - anneal_factor: \"0.5\"\n",
      "2019-11-24 12:51:17,496  - max_epochs: \"10\"\n",
      "2019-11-24 12:51:17,497  - shuffle: \"True\"\n",
      "2019-11-24 12:51:17,497  - train_with_dev: \"False\"\n",
      "2019-11-24 12:51:17,498  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 12:51:17,498 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:17,499 Model training base path: \"test_csv/mix10\"\n",
      "2019-11-24 12:51:17,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:17,500 Device: cpu\n",
      "2019-11-24 12:51:17,501 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:17,504 Embeddings storage mode: cpu\n",
      "2019-11-24 12:51:17,506 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:51:21,096 epoch 1 - iter 0/22 - loss 0.69223469 - samples/sec: 18.55\n",
      "2019-11-24 12:51:26,195 epoch 1 - iter 2/22 - loss 0.67696941 - samples/sec: 12.63\n",
      "2019-11-24 12:51:31,612 epoch 1 - iter 4/22 - loss 0.65945069 - samples/sec: 11.85\n",
      "2019-11-24 12:51:36,596 epoch 1 - iter 6/22 - loss 0.65065566 - samples/sec: 13.56\n",
      "2019-11-24 12:51:42,221 epoch 1 - iter 8/22 - loss 0.63988186 - samples/sec: 11.43\n",
      "2019-11-24 12:51:46,755 epoch 1 - iter 10/22 - loss 0.63884748 - samples/sec: 14.15\n",
      "2019-11-24 12:51:52,787 epoch 1 - iter 12/22 - loss 0.62892862 - samples/sec: 10.65\n",
      "2019-11-24 12:51:58,821 epoch 1 - iter 14/22 - loss 0.62449671 - samples/sec: 10.65\n",
      "2019-11-24 12:52:11,098 epoch 1 - iter 16/22 - loss 0.62128268 - samples/sec: 5.22\n",
      "2019-11-24 12:52:17,334 epoch 1 - iter 18/22 - loss 0.60370065 - samples/sec: 10.30\n",
      "2019-11-24 12:52:22,055 epoch 1 - iter 20/22 - loss 0.60372316 - samples/sec: 13.60\n",
      "2019-11-24 12:52:24,027 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:52:24,028 EPOCH 1 done: loss 0.5909 - lr 0.1000\n",
      "2019-11-24 12:52:31,624 DEV : loss 0.6977316737174988 - score 0.6\n",
      "2019-11-24 12:52:31,696 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:52:34,710 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:52:37,888 epoch 2 - iter 0/22 - loss 0.33519256 - samples/sec: 21.99\n",
      "2019-11-24 12:52:44,030 epoch 2 - iter 2/22 - loss 0.39973787 - samples/sec: 10.44\n",
      "2019-11-24 12:52:50,705 epoch 2 - iter 4/22 - loss 0.43782155 - samples/sec: 9.61\n",
      "2019-11-24 12:52:55,908 epoch 2 - iter 6/22 - loss 0.48082323 - samples/sec: 12.41\n",
      "2019-11-24 12:53:02,305 epoch 2 - iter 8/22 - loss 0.47924662 - samples/sec: 10.03\n",
      "2019-11-24 12:53:07,976 epoch 2 - iter 10/22 - loss 0.47223765 - samples/sec: 11.33\n",
      "2019-11-24 12:53:15,072 epoch 2 - iter 12/22 - loss 0.47226195 - samples/sec: 9.06\n",
      "2019-11-24 12:53:24,344 epoch 2 - iter 14/22 - loss 0.49208934 - samples/sec: 6.91\n",
      "2019-11-24 12:53:29,415 epoch 2 - iter 16/22 - loss 0.49555907 - samples/sec: 12.66\n",
      "2019-11-24 12:53:35,999 epoch 2 - iter 18/22 - loss 0.50252665 - samples/sec: 10.47\n",
      "2019-11-24 12:53:42,699 epoch 2 - iter 20/22 - loss 0.51752900 - samples/sec: 9.57\n",
      "2019-11-24 12:53:44,093 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:53:44,094 EPOCH 2 done: loss 0.5130 - lr 0.1000\n",
      "2019-11-24 12:53:52,074 DEV : loss 0.6660023331642151 - score 0.6941\n",
      "2019-11-24 12:53:52,143 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:53:55,654 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:53:59,281 epoch 3 - iter 0/22 - loss 0.78764117 - samples/sec: 19.20\n",
      "2019-11-24 12:54:08,440 epoch 3 - iter 2/22 - loss 0.62130503 - samples/sec: 7.01\n",
      "2019-11-24 12:54:14,972 epoch 3 - iter 4/22 - loss 0.55542057 - samples/sec: 9.82\n",
      "2019-11-24 12:54:21,593 epoch 3 - iter 6/22 - loss 0.55098443 - samples/sec: 9.70\n",
      "2019-11-24 12:54:27,010 epoch 3 - iter 8/22 - loss 0.49532188 - samples/sec: 11.87\n",
      "2019-11-24 12:54:32,395 epoch 3 - iter 10/22 - loss 0.48436592 - samples/sec: 11.92\n",
      "2019-11-24 12:54:37,454 epoch 3 - iter 12/22 - loss 0.47882314 - samples/sec: 12.73\n",
      "2019-11-24 12:54:41,846 epoch 3 - iter 14/22 - loss 0.45797020 - samples/sec: 14.69\n",
      "2019-11-24 12:54:48,259 epoch 3 - iter 16/22 - loss 0.45503138 - samples/sec: 10.00\n",
      "2019-11-24 12:54:53,828 epoch 3 - iter 18/22 - loss 0.46723053 - samples/sec: 11.52\n",
      "2019-11-24 12:54:59,122 epoch 3 - iter 20/22 - loss 0.46284344 - samples/sec: 12.14\n",
      "2019-11-24 12:55:00,043 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:55:00,044 EPOCH 3 done: loss 0.4511 - lr 0.1000\n",
      "2019-11-24 12:55:07,524 DEV : loss 0.6951572299003601 - score 0.6471\n",
      "2019-11-24 12:55:07,594 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:55:07,595 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:55:10,627 epoch 4 - iter 0/22 - loss 0.42620647 - samples/sec: 23.56\n",
      "2019-11-24 12:55:15,842 epoch 4 - iter 2/22 - loss 0.39663966 - samples/sec: 12.31\n",
      "2019-11-24 12:55:20,178 epoch 4 - iter 4/22 - loss 0.45100699 - samples/sec: 14.82\n",
      "2019-11-24 12:55:25,682 epoch 4 - iter 6/22 - loss 0.45476078 - samples/sec: 11.70\n",
      "2019-11-24 12:55:31,099 epoch 4 - iter 8/22 - loss 0.44227819 - samples/sec: 11.85\n",
      "2019-11-24 12:55:36,347 epoch 4 - iter 10/22 - loss 0.44581281 - samples/sec: 12.22\n",
      "2019-11-24 12:55:43,073 epoch 4 - iter 12/22 - loss 0.44263638 - samples/sec: 9.55\n",
      "2019-11-24 12:55:47,994 epoch 4 - iter 14/22 - loss 0.44086162 - samples/sec: 13.05\n",
      "2019-11-24 12:55:54,239 epoch 4 - iter 16/22 - loss 0.42372659 - samples/sec: 10.27\n",
      "2019-11-24 12:55:59,575 epoch 4 - iter 18/22 - loss 0.42809297 - samples/sec: 12.05\n",
      "2019-11-24 12:56:04,560 epoch 4 - iter 20/22 - loss 0.45302304 - samples/sec: 12.88\n",
      "2019-11-24 12:56:05,733 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:56:05,734 EPOCH 4 done: loss 0.4733 - lr 0.1000\n",
      "2019-11-24 12:56:13,195 DEV : loss 0.8039163947105408 - score 0.6118\n",
      "2019-11-24 12:56:13,266 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 12:56:13,267 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:56:17,283 epoch 5 - iter 0/22 - loss 0.74555308 - samples/sec: 16.78\n",
      "2019-11-24 12:56:24,610 epoch 5 - iter 2/22 - loss 0.53306159 - samples/sec: 8.76\n",
      "2019-11-24 12:56:33,335 epoch 5 - iter 4/22 - loss 0.43299060 - samples/sec: 7.37\n",
      "2019-11-24 12:56:43,224 epoch 5 - iter 6/22 - loss 0.42263660 - samples/sec: 6.48\n",
      "2019-11-24 12:56:49,501 epoch 5 - iter 8/22 - loss 0.38540104 - samples/sec: 10.22\n",
      "2019-11-24 12:56:56,506 epoch 5 - iter 10/22 - loss 0.39356609 - samples/sec: 9.19\n",
      "2019-11-24 12:57:02,035 epoch 5 - iter 12/22 - loss 0.41841479 - samples/sec: 11.60\n",
      "2019-11-24 12:57:06,311 epoch 5 - iter 14/22 - loss 0.41903411 - samples/sec: 15.01\n",
      "2019-11-24 12:57:11,671 epoch 5 - iter 16/22 - loss 0.43720657 - samples/sec: 12.02\n",
      "2019-11-24 12:57:17,260 epoch 5 - iter 18/22 - loss 0.42695074 - samples/sec: 11.48\n",
      "2019-11-24 12:57:21,285 epoch 5 - iter 20/22 - loss 0.42890169 - samples/sec: 15.95\n",
      "2019-11-24 12:57:23,089 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:57:23,090 EPOCH 5 done: loss 0.4138 - lr 0.1000\n",
      "2019-11-24 12:57:30,840 DEV : loss 0.49836674332618713 - score 0.7412\n",
      "2019-11-24 12:57:30,913 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 12:57:33,973 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:57:36,825 epoch 6 - iter 0/22 - loss 0.49474213 - samples/sec: 25.50\n",
      "2019-11-24 12:57:42,702 epoch 6 - iter 2/22 - loss 0.59014659 - samples/sec: 11.82\n",
      "2019-11-24 12:57:48,141 epoch 6 - iter 4/22 - loss 0.49454539 - samples/sec: 11.80\n",
      "2019-11-24 12:57:57,455 epoch 6 - iter 6/22 - loss 0.46168323 - samples/sec: 6.88\n",
      "2019-11-24 12:58:03,790 epoch 6 - iter 8/22 - loss 0.44607048 - samples/sec: 10.14\n",
      "2019-11-24 12:58:11,466 epoch 6 - iter 10/22 - loss 0.46611919 - samples/sec: 8.37\n",
      "2019-11-24 12:58:18,601 epoch 6 - iter 12/22 - loss 0.45159324 - samples/sec: 9.00\n",
      "2019-11-24 12:58:27,227 epoch 6 - iter 14/22 - loss 0.45938859 - samples/sec: 7.46\n",
      "2019-11-24 12:58:35,287 epoch 6 - iter 16/22 - loss 0.45049641 - samples/sec: 7.96\n",
      "2019-11-24 12:58:42,534 epoch 6 - iter 18/22 - loss 0.45353281 - samples/sec: 8.88\n",
      "2019-11-24 12:58:48,133 epoch 6 - iter 20/22 - loss 0.44486364 - samples/sec: 11.47\n",
      "2019-11-24 12:58:50,298 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:58:50,301 EPOCH 6 done: loss 0.4538 - lr 0.1000\n",
      "2019-11-24 12:59:01,197 DEV : loss 0.7656881809234619 - score 0.6118\n",
      "2019-11-24 12:59:01,272 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 12:59:01,273 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 12:59:05,142 epoch 7 - iter 0/22 - loss 0.67264938 - samples/sec: 17.75\n",
      "2019-11-24 12:59:12,729 epoch 7 - iter 2/22 - loss 0.49751831 - samples/sec: 8.48\n",
      "2019-11-24 12:59:20,781 epoch 7 - iter 4/22 - loss 0.43946947 - samples/sec: 7.97\n",
      "2019-11-24 12:59:30,316 epoch 7 - iter 6/22 - loss 0.41775955 - samples/sec: 6.74\n",
      "2019-11-24 12:59:38,686 epoch 7 - iter 8/22 - loss 0.40051441 - samples/sec: 7.69\n",
      "2019-11-24 12:59:44,010 epoch 7 - iter 10/22 - loss 0.40709197 - samples/sec: 12.07\n",
      "2019-11-24 12:59:49,768 epoch 7 - iter 12/22 - loss 0.40664319 - samples/sec: 11.16\n",
      "2019-11-24 12:59:53,911 epoch 7 - iter 14/22 - loss 0.42084642 - samples/sec: 15.54\n",
      "2019-11-24 12:59:57,860 epoch 7 - iter 16/22 - loss 0.42792622 - samples/sec: 16.32\n",
      "2019-11-24 13:00:01,703 epoch 7 - iter 18/22 - loss 0.42768998 - samples/sec: 16.75\n",
      "2019-11-24 13:00:05,324 epoch 7 - iter 20/22 - loss 0.42464372 - samples/sec: 17.77\n",
      "2019-11-24 13:00:06,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:00:06,280 EPOCH 7 done: loss 0.4133 - lr 0.1000\n",
      "2019-11-24 13:00:13,230 DEV : loss 0.5303918719291687 - score 0.7529\n",
      "2019-11-24 13:00:13,286 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 13:00:16,055 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 13:00:18,445 epoch 8 - iter 0/22 - loss 0.51767123 - samples/sec: 28.86\n",
      "2019-11-24 13:00:22,837 epoch 8 - iter 2/22 - loss 0.53006965 - samples/sec: 14.69\n",
      "2019-11-24 13:00:26,833 epoch 8 - iter 4/22 - loss 0.48883155 - samples/sec: 16.09\n",
      "2019-11-24 13:00:31,043 epoch 8 - iter 6/22 - loss 0.45756572 - samples/sec: 15.25\n",
      "2019-11-24 13:00:34,854 epoch 8 - iter 8/22 - loss 0.43291649 - samples/sec: 16.95\n",
      "2019-11-24 13:00:40,815 epoch 8 - iter 10/22 - loss 0.40402703 - samples/sec: 10.78\n",
      "2019-11-24 13:00:46,028 epoch 8 - iter 12/22 - loss 0.40344779 - samples/sec: 12.32\n",
      "2019-11-24 13:00:51,045 epoch 8 - iter 14/22 - loss 0.39504810 - samples/sec: 12.84\n",
      "2019-11-24 13:00:55,450 epoch 8 - iter 16/22 - loss 0.38915904 - samples/sec: 14.58\n",
      "2019-11-24 13:01:00,171 epoch 8 - iter 18/22 - loss 0.37311395 - samples/sec: 13.59\n",
      "2019-11-24 13:01:04,463 epoch 8 - iter 20/22 - loss 0.37794078 - samples/sec: 14.98\n",
      "2019-11-24 13:01:05,227 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:01:05,228 EPOCH 8 done: loss 0.3718 - lr 0.1000\n",
      "2019-11-24 13:01:11,497 DEV : loss 0.9664132595062256 - score 0.5882\n",
      "2019-11-24 13:01:11,556 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 13:01:11,557 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:01:14,455 epoch 9 - iter 0/22 - loss 1.02023375 - samples/sec: 24.33\n",
      "2019-11-24 13:01:19,210 epoch 9 - iter 2/22 - loss 0.69917158 - samples/sec: 13.53\n",
      "2019-11-24 13:01:23,798 epoch 9 - iter 4/22 - loss 0.57785612 - samples/sec: 13.99\n",
      "2019-11-24 13:01:28,233 epoch 9 - iter 6/22 - loss 0.49354903 - samples/sec: 14.52\n",
      "2019-11-24 13:01:32,171 epoch 9 - iter 8/22 - loss 0.44782336 - samples/sec: 16.35\n",
      "2019-11-24 13:01:37,166 epoch 9 - iter 10/22 - loss 0.45222189 - samples/sec: 12.85\n",
      "2019-11-24 13:01:41,703 epoch 9 - iter 12/22 - loss 0.43460402 - samples/sec: 14.18\n",
      "2019-11-24 13:01:46,096 epoch 9 - iter 14/22 - loss 0.43276204 - samples/sec: 14.64\n",
      "2019-11-24 13:01:49,939 epoch 9 - iter 16/22 - loss 0.40749528 - samples/sec: 16.73\n",
      "2019-11-24 13:01:56,741 epoch 9 - iter 18/22 - loss 0.40090349 - samples/sec: 10.07\n",
      "2019-11-24 13:02:00,527 epoch 9 - iter 20/22 - loss 0.39959429 - samples/sec: 16.99\n",
      "2019-11-24 13:02:01,497 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:02:01,497 EPOCH 9 done: loss 0.3844 - lr 0.1000\n",
      "2019-11-24 13:02:07,685 DEV : loss 0.6423859000205994 - score 0.6824\n",
      "2019-11-24 13:02:07,749 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 13:02:07,750 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:02:10,904 epoch 10 - iter 0/22 - loss 0.55454332 - samples/sec: 21.57\n",
      "2019-11-24 13:02:15,112 epoch 10 - iter 2/22 - loss 0.54603940 - samples/sec: 15.26\n",
      "2019-11-24 13:02:20,001 epoch 10 - iter 4/22 - loss 0.49353381 - samples/sec: 13.13\n",
      "2019-11-24 13:02:24,057 epoch 10 - iter 6/22 - loss 0.44026107 - samples/sec: 15.91\n",
      "2019-11-24 13:02:28,152 epoch 10 - iter 8/22 - loss 0.41880458 - samples/sec: 15.70\n",
      "2019-11-24 13:02:31,949 epoch 10 - iter 10/22 - loss 0.38466830 - samples/sec: 16.93\n",
      "2019-11-24 13:02:37,141 epoch 10 - iter 12/22 - loss 0.37873908 - samples/sec: 12.42\n",
      "2019-11-24 13:02:41,222 epoch 10 - iter 14/22 - loss 0.37042443 - samples/sec: 15.76\n",
      "2019-11-24 13:02:45,483 epoch 10 - iter 16/22 - loss 0.36669339 - samples/sec: 15.10\n",
      "2019-11-24 13:02:50,529 epoch 10 - iter 18/22 - loss 0.34843445 - samples/sec: 12.72\n",
      "2019-11-24 13:02:54,865 epoch 10 - iter 20/22 - loss 0.35386676 - samples/sec: 14.81\n",
      "2019-11-24 13:02:55,884 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:02:55,885 EPOCH 10 done: loss 0.3455 - lr 0.1000\n",
      "2019-11-24 13:03:02,290 DEV : loss 0.4709831774234772 - score 0.8118\n",
      "2019-11-24 13:03:02,363 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 13:03:07,563 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:03:07,564 Testing using best model ...\n",
      "2019-11-24 13:03:07,565 loading file test_csv/mix10/best-model.pt\n",
      "2019-11-24 13:03:13,918 0.8571\t0.8571\t0.8571\n",
      "2019-11-24 13:03:13,919 \n",
      "MICRO_AVG: acc 0.75 - f1-score 0.8571\n",
      "MACRO_AVG: acc 0.7429 - f1-score 0.85175\n",
      "fake       tp: 28 - fp: 6 - fn: 6 - tn: 44 - precision: 0.8235 - recall: 0.8235 - accuracy: 0.7000 - f1-score: 0.8235\n",
      "real       tp: 44 - fp: 6 - fn: 6 - tn: 28 - precision: 0.8800 - recall: 0.8800 - accuracy: 0.7857 - f1-score: 0.8800\n",
      "2019-11-24 13:03:13,920 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 13:03:13,921 loading file ./test_csv/mix10/best-model.pt\n",
      "acc:  0.8207547169811321\n",
      "precision:  0.7289719626168224\n",
      "recall:  0.896551724137931\n",
      "f1:  0.8041237113402062\n"
     ]
    }
   ],
   "source": [
    "path = './test_csv/mix10'\n",
    "make_test(train_mix, test_mix, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
