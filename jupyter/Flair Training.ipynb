{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "import os\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../fakenewsnet_dataset'\n",
    "DATASET_NAME = 'politifact'\n",
    "DATASET_PATH = '{}/{}'.format(DATA_PATH, DATASET_NAME)\n",
    "REAL_DATA_PATH = '{}/real'.format(DATASET_PATH)\n",
    "FAKE_DATA_PATH = '{}/fake'.format(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_from_file(path):\n",
    "    with open(path) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article():\n",
    "    def __init__(self, name, path):\n",
    "        self.path = path\n",
    "        self.name = name\n",
    "        self.content = None\n",
    "        self.tweets = []\n",
    "        \n",
    "    def load_content(self):\n",
    "        content_path = \"{}/news content.json\".format(self.path)\n",
    "        if os.path.isfile(content_path):\n",
    "            self.content = load_json_from_file(content_path)\n",
    "    \n",
    "    def load_tweets(self):\n",
    "        tweets_path = \"{}/tweets\".format(self.path)\n",
    "        if os.path.isdir(tweets_path):\n",
    "            tweets_files = os.listdir(tweets_path)\n",
    "            self.tweets = [load_json_from_file(\"{}/{}\".format(tweets_path, file)) for file in tweets_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_article(name, path):\n",
    "    art = Article(name, path)\n",
    "    art.load_content()\n",
    "#     art.load_tweets()\n",
    "    return art\n",
    "\n",
    "def load_all_articles(path):\n",
    "    articles = []\n",
    "    if os.path.isdir(path):\n",
    "        articles_files = os.listdir(path)\n",
    "        articles = [load_single_article(file, \"{}/{}\".format(path, file)) for file in articles_files]\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_arts = load_all_articles(FAKE_DATA_PATH)\n",
    "real_arts = load_all_articles(REAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_arts_with_content = [art for art in fake_arts if art.content is not None]\n",
    "real_arts_with_content = [art for art in real_arts if art.content is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = [(art, 'fake') for art in fake_arts_with_content]\n",
    "real_data = [(art, 'real') for art in real_arts_with_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(fake_data)\n",
    "np.random.shuffle(real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = fake_data[0:int(len(fake_data)*0.8)] + real_data[0:int(len(real_data)*0.8)]\n",
    "test_data = fake_data[int(len(fake_data)*0.8):] + real_data[int(len(real_data)*0.8):]\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "162\n",
      "805\n",
      "805\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(train_data) + len(test_data))\n",
    "print(len(fake_data) + len(real_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def predict(self, text):\n",
    "        text = clear_text(text)\n",
    "        sentence = Sentence(text)\n",
    "        self.classifier.predict(sentence)\n",
    "        return sentence.labels[0]\n",
    "\n",
    "def transform_data(data):\n",
    "    return [{'label': label, 'text': clear_text(x)} for x, label in data]\n",
    "\n",
    "def save_data(data, data_folder = '.'):\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    data = transform_data(data)\n",
    "    frame_data = pd.DataFrame(data)\n",
    "    train_path = '{}/train.csv'.format(data_folder)\n",
    "    test_path = '{}/test.csv'.format(data_folder)\n",
    "    dev_path = '{}/dev.csv'.format(data_folder)\n",
    "    frame_data.iloc[0:int(len(data)*0.8)].to_csv(train_path, sep='\\t', index = False, header = False)\n",
    "    frame_data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv(test_path, sep='\\t', index = False, header = False)\n",
    "    frame_data.iloc[int(len(data)*0.9):].to_csv(dev_path, sep='\\t', index = False, header = False)\n",
    "\n",
    "def load_corpus(data_folder = '.'):\n",
    "    column_name_map = {1: \"text\", 0: \"label\"}\n",
    "    return CSVClassificationCorpus(data_folder,\n",
    "                                     column_name_map,\n",
    "                                     delimiter='\\t',\n",
    "                                  test_file='test.csv',\n",
    "                                  dev_file='dev.csv',\n",
    "                                  train_file='train.csv')\n",
    "    \n",
    "def train_classifier(corpus, model_folder = '.', max_epochs = 1):\n",
    "    label_dict = corpus.make_label_dictionary()\n",
    "\n",
    "    word_embeddings = [\n",
    "        WordEmbeddings('glove'),\n",
    "        FlairEmbeddings('news-forward-fast'),\n",
    "        FlairEmbeddings('news-backward-fast')\n",
    "    ]\n",
    "\n",
    "    document_embeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                hidden_size=512,\n",
    "                                                reproject_words=True,\n",
    "                                                reproject_words_dimension=256)\n",
    "\n",
    "    classifier = TextClassifier(document_embeddings,\n",
    "                                label_dictionary=label_dict)\n",
    "\n",
    "    trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "    trainer.train(model_folder, max_epochs=max_epochs)\n",
    "    \n",
    "    return TextClassifier.load('{}/best-model.pt'.format(model_folder))\n",
    "    \n",
    "def train_model(train_data,\n",
    "               data_folder = '.',\n",
    "               model_folder = '.',\n",
    "               max_epochs=1\n",
    "               ):\n",
    "    save_data(train_data, data_folder)\n",
    "    corpus = load_corpus(data_folder)\n",
    "    classifier = train_classifier(corpus, model_folder, max_epochs)\n",
    "    return Classifier(classifier)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, pos_label = 'fake'):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=pos_label)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=pos_label)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "def validate_model(test_data, classifier):\n",
    "    y_true = [label for x, label in test_data]\n",
    "    y_pred = [classifier.predict(x).value for x, label in test_data]\n",
    "    acc, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
    "    print(\"acc: \", acc)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1: \", f1)\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "def make_test(train_data, test_data, data_folder, model_folder, max_epochs):\n",
    "    classifier = train_model(train_data, data_folder, model_folder, max_epochs)\n",
    "    validate_model(test_data, classifier)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_content = [(x.content, label) for x, label in train_data] \n",
    "test_content = [(x.content, label) for x, label in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "8\n",
      "610\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "train_title = [(x['title'], label) for x, label in train_content] \n",
    "test_title = [(x['title'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_title if x == '']))\n",
    "print(len([x for x, label in test_title if x == '']))\n",
    "train_title = [(x, label) for x, label in train_title if x != ''] \n",
    "test_title = [(x, label) for x, label in test_title if x != '']\n",
    "print(len(train_title))\n",
    "print(len(test_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:34:43,752 Reading data from test/title1\n",
      "2019-11-24 09:34:43,752 Train: test/title1/train.csv\n",
      "2019-11-24 09:34:43,753 Dev: test/title1/dev.csv\n",
      "2019-11-24 09:34:43,754 Test: test/title1/test.csv\n",
      "2019-11-24 09:34:43,758 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:00<00:00, 3931.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:34:43,975 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:34:45,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:45,467 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 09:34:45,468 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:45,469 Corpus: \"Corpus: 488 train + 61 dev + 61 test sentences\"\n",
      "2019-11-24 09:34:45,469 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:45,470 Parameters:\n",
      "2019-11-24 09:34:45,471  - learning_rate: \"0.1\"\n",
      "2019-11-24 09:34:45,471  - mini_batch_size: \"32\"\n",
      "2019-11-24 09:34:45,472  - patience: \"3\"\n",
      "2019-11-24 09:34:45,473  - anneal_factor: \"0.5\"\n",
      "2019-11-24 09:34:45,474  - max_epochs: \"1\"\n",
      "2019-11-24 09:34:45,475  - shuffle: \"True\"\n",
      "2019-11-24 09:34:45,476  - train_with_dev: \"False\"\n",
      "2019-11-24 09:34:45,477  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 09:34:45,477 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:45,478 Model training base path: \"test/title1\"\n",
      "2019-11-24 09:34:45,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:45,479 Device: cpu\n",
      "2019-11-24 09:34:45,480 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:45,480 Embeddings storage mode: cpu\n",
      "2019-11-24 09:34:45,482 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:34:46,655 epoch 1 - iter 0/16 - loss 0.69617647 - samples/sec: 31.29\n",
      "2019-11-24 09:34:48,865 epoch 1 - iter 1/16 - loss 0.68262613 - samples/sec: 14.65\n",
      "2019-11-24 09:34:49,965 epoch 1 - iter 2/16 - loss 0.67755071 - samples/sec: 29.60\n",
      "2019-11-24 09:34:51,154 epoch 1 - iter 3/16 - loss 0.68728031 - samples/sec: 27.27\n",
      "2019-11-24 09:34:52,313 epoch 1 - iter 4/16 - loss 0.69390866 - samples/sec: 28.21\n",
      "2019-11-24 09:34:53,852 epoch 1 - iter 5/16 - loss 0.68828339 - samples/sec: 21.03\n",
      "2019-11-24 09:34:55,626 epoch 1 - iter 6/16 - loss 0.67564819 - samples/sec: 18.27\n",
      "2019-11-24 09:34:57,218 epoch 1 - iter 7/16 - loss 0.68449492 - samples/sec: 20.30\n",
      "2019-11-24 09:34:58,813 epoch 1 - iter 8/16 - loss 0.67133878 - samples/sec: 20.34\n",
      "2019-11-24 09:34:59,770 epoch 1 - iter 9/16 - loss 0.65749220 - samples/sec: 33.90\n",
      "2019-11-24 09:35:01,318 epoch 1 - iter 10/16 - loss 0.66134192 - samples/sec: 20.86\n",
      "2019-11-24 09:35:02,167 epoch 1 - iter 11/16 - loss 0.65707356 - samples/sec: 38.36\n",
      "2019-11-24 09:35:03,843 epoch 1 - iter 12/16 - loss 0.65024028 - samples/sec: 19.33\n",
      "2019-11-24 09:35:04,677 epoch 1 - iter 13/16 - loss 0.65048519 - samples/sec: 39.26\n",
      "2019-11-24 09:35:05,668 epoch 1 - iter 14/16 - loss 0.65098318 - samples/sec: 32.81\n",
      "2019-11-24 09:35:06,246 epoch 1 - iter 15/16 - loss 0.63764043 - samples/sec: 56.51\n",
      "2019-11-24 09:35:06,289 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:35:06,291 EPOCH 1 done: loss 0.6376 - lr 0.1000\n",
      "2019-11-24 09:35:09,657 DEV : loss 0.64480060338974 - score 0.5574\n",
      "2019-11-24 09:35:09,701 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:35:16,027 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:35:16,028 Testing using best model ...\n",
      "2019-11-24 09:35:16,029 loading file test/title1/best-model.pt\n",
      "2019-11-24 09:35:20,531 0.6721\t0.6721\t0.6721\n",
      "2019-11-24 09:35:20,533 \n",
      "MICRO_AVG: acc 0.5062 - f1-score 0.6721\n",
      "MACRO_AVG: acc 0.4445 - f1-score 0.59225\n",
      "fake       tp: 7 - fp: 0 - fn: 20 - tn: 34 - precision: 1.0000 - recall: 0.2593 - accuracy: 0.2593 - f1-score: 0.4118\n",
      "real       tp: 34 - fp: 20 - fn: 0 - tn: 7 - precision: 0.6296 - recall: 1.0000 - accuracy: 0.6296 - f1-score: 0.7727\n",
      "2019-11-24 09:35:20,533 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:35:20,535 loading file ./test/title1/best-model.pt\n",
      "acc:  0.6428571428571429\n",
      "precision:  0.9285714285714286\n",
      "recall:  0.3291139240506329\n",
      "f1:  0.48598130841121495\n"
     ]
    }
   ],
   "source": [
    "path = './test/title1'\n",
    "make_test(train_title, test_title, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:36:59,771 Reading data from test/title10\n",
      "2019-11-24 09:36:59,772 Train: test/title10/train.csv\n",
      "2019-11-24 09:36:59,773 Dev: test/title10/dev.csv\n",
      "2019-11-24 09:36:59,773 Test: test/title10/test.csv\n",
      "2019-11-24 09:36:59,776 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:00<00:00, 2336.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:37:00,221 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:37:01,406 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:01,407 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 09:37:01,408 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:01,409 Corpus: \"Corpus: 488 train + 61 dev + 61 test sentences\"\n",
      "2019-11-24 09:37:01,409 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:01,410 Parameters:\n",
      "2019-11-24 09:37:01,410  - learning_rate: \"0.1\"\n",
      "2019-11-24 09:37:01,411  - mini_batch_size: \"32\"\n",
      "2019-11-24 09:37:01,412  - patience: \"3\"\n",
      "2019-11-24 09:37:01,412  - anneal_factor: \"0.5\"\n",
      "2019-11-24 09:37:01,415  - max_epochs: \"10\"\n",
      "2019-11-24 09:37:01,416  - shuffle: \"True\"\n",
      "2019-11-24 09:37:01,416  - train_with_dev: \"False\"\n",
      "2019-11-24 09:37:01,417  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 09:37:01,418 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:01,418 Model training base path: \"test/title10\"\n",
      "2019-11-24 09:37:01,419 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:01,439 Device: cpu\n",
      "2019-11-24 09:37:01,448 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:01,450 Embeddings storage mode: cpu\n",
      "2019-11-24 09:37:01,453 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:02,647 epoch 1 - iter 0/16 - loss 0.69992131 - samples/sec: 33.03\n",
      "2019-11-24 09:37:03,763 epoch 1 - iter 1/16 - loss 0.70038471 - samples/sec: 29.23\n",
      "2019-11-24 09:37:04,596 epoch 1 - iter 2/16 - loss 0.70696986 - samples/sec: 39.87\n",
      "2019-11-24 09:37:06,215 epoch 1 - iter 3/16 - loss 0.69765772 - samples/sec: 19.97\n",
      "2019-11-24 09:37:08,154 epoch 1 - iter 4/16 - loss 0.69336394 - samples/sec: 16.67\n",
      "2019-11-24 09:37:09,877 epoch 1 - iter 5/16 - loss 0.68796116 - samples/sec: 18.76\n",
      "2019-11-24 09:37:11,296 epoch 1 - iter 6/16 - loss 0.68814603 - samples/sec: 22.88\n",
      "2019-11-24 09:37:12,936 epoch 1 - iter 7/16 - loss 0.68117103 - samples/sec: 19.82\n",
      "2019-11-24 09:37:13,936 epoch 1 - iter 8/16 - loss 0.68364230 - samples/sec: 32.46\n",
      "2019-11-24 09:37:15,577 epoch 1 - iter 9/16 - loss 0.67312411 - samples/sec: 19.69\n",
      "2019-11-24 09:37:16,418 epoch 1 - iter 10/16 - loss 0.66424430 - samples/sec: 38.80\n",
      "2019-11-24 09:37:17,978 epoch 1 - iter 11/16 - loss 0.65671936 - samples/sec: 20.71\n",
      "2019-11-24 09:37:19,408 epoch 1 - iter 12/16 - loss 0.64751946 - samples/sec: 22.62\n",
      "2019-11-24 09:37:20,449 epoch 1 - iter 13/16 - loss 0.64454967 - samples/sec: 31.38\n",
      "2019-11-24 09:37:21,615 epoch 1 - iter 14/16 - loss 0.63809055 - samples/sec: 27.79\n",
      "2019-11-24 09:37:22,243 epoch 1 - iter 15/16 - loss 0.64149364 - samples/sec: 52.04\n",
      "2019-11-24 09:37:22,368 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:22,369 EPOCH 1 done: loss 0.6415 - lr 0.1000\n",
      "2019-11-24 09:37:25,415 DEV : loss 0.7773809432983398 - score 0.5082\n",
      "2019-11-24 09:37:25,458 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:37:28,617 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:30,140 epoch 2 - iter 0/16 - loss 0.82085043 - samples/sec: 24.43\n",
      "2019-11-24 09:37:31,368 epoch 2 - iter 1/16 - loss 0.70614460 - samples/sec: 26.64\n",
      "2019-11-24 09:37:32,388 epoch 2 - iter 2/16 - loss 0.67093490 - samples/sec: 31.74\n",
      "2019-11-24 09:37:34,225 epoch 2 - iter 3/16 - loss 0.65052827 - samples/sec: 17.58\n",
      "2019-11-24 09:37:35,422 epoch 2 - iter 4/16 - loss 0.62875946 - samples/sec: 27.01\n",
      "2019-11-24 09:37:37,100 epoch 2 - iter 5/16 - loss 0.61309786 - samples/sec: 19.40\n",
      "2019-11-24 09:37:38,233 epoch 2 - iter 6/16 - loss 0.61597365 - samples/sec: 28.69\n",
      "2019-11-24 09:37:39,181 epoch 2 - iter 7/16 - loss 0.58863124 - samples/sec: 34.50\n",
      "2019-11-24 09:37:41,714 epoch 2 - iter 8/16 - loss 0.56685092 - samples/sec: 12.70\n",
      "2019-11-24 09:37:43,576 epoch 2 - iter 9/16 - loss 0.56555685 - samples/sec: 17.36\n",
      "2019-11-24 09:37:44,867 epoch 2 - iter 10/16 - loss 0.56735665 - samples/sec: 25.12\n",
      "2019-11-24 09:37:45,847 epoch 2 - iter 11/16 - loss 0.57043844 - samples/sec: 33.42\n",
      "2019-11-24 09:37:46,755 epoch 2 - iter 12/16 - loss 0.56564499 - samples/sec: 35.86\n",
      "2019-11-24 09:37:49,519 epoch 2 - iter 13/16 - loss 0.56265623 - samples/sec: 11.66\n",
      "2019-11-24 09:37:51,784 epoch 2 - iter 14/16 - loss 0.55816150 - samples/sec: 14.21\n",
      "2019-11-24 09:37:52,588 epoch 2 - iter 15/16 - loss 0.54919663 - samples/sec: 40.69\n",
      "2019-11-24 09:37:52,706 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:37:52,707 EPOCH 2 done: loss 0.5492 - lr 0.1000\n",
      "2019-11-24 09:37:56,451 DEV : loss 0.5702894330024719 - score 0.6393\n",
      "2019-11-24 09:37:56,492 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 09:37:59,742 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:38:01,148 epoch 3 - iter 0/16 - loss 0.51257509 - samples/sec: 28.02\n",
      "2019-11-24 09:38:02,349 epoch 3 - iter 1/16 - loss 0.46684465 - samples/sec: 26.95\n",
      "2019-11-24 09:38:04,059 epoch 3 - iter 2/16 - loss 0.45138842 - samples/sec: 18.99\n",
      "2019-11-24 09:38:04,936 epoch 3 - iter 3/16 - loss 0.46612366 - samples/sec: 37.12\n",
      "2019-11-24 09:38:06,656 epoch 3 - iter 4/16 - loss 0.48485079 - samples/sec: 18.75\n",
      "2019-11-24 09:38:07,786 epoch 3 - iter 5/16 - loss 0.47294740 - samples/sec: 28.78\n",
      "2019-11-24 09:38:08,787 epoch 3 - iter 6/16 - loss 0.49552871 - samples/sec: 32.83\n",
      "2019-11-24 09:38:11,263 epoch 3 - iter 7/16 - loss 0.48038705 - samples/sec: 13.00\n",
      "2019-11-24 09:38:13,007 epoch 3 - iter 8/16 - loss 0.49021137 - samples/sec: 18.69\n",
      "2019-11-24 09:38:15,288 epoch 3 - iter 9/16 - loss 0.48236511 - samples/sec: 14.09\n",
      "2019-11-24 09:38:17,033 epoch 3 - iter 10/16 - loss 0.48378210 - samples/sec: 18.52\n",
      "2019-11-24 09:38:18,138 epoch 3 - iter 11/16 - loss 0.49232813 - samples/sec: 29.43\n",
      "2019-11-24 09:38:19,829 epoch 3 - iter 12/16 - loss 0.49684121 - samples/sec: 19.12\n",
      "2019-11-24 09:38:21,183 epoch 3 - iter 13/16 - loss 0.49466848 - samples/sec: 23.90\n",
      "2019-11-24 09:38:23,544 epoch 3 - iter 14/16 - loss 0.49387576 - samples/sec: 13.64\n",
      "2019-11-24 09:38:24,135 epoch 3 - iter 15/16 - loss 0.50815585 - samples/sec: 55.53\n",
      "2019-11-24 09:38:24,291 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:38:24,292 EPOCH 3 done: loss 0.5082 - lr 0.1000\n",
      "2019-11-24 09:38:27,766 DEV : loss 0.8347216844558716 - score 0.5738\n",
      "2019-11-24 09:38:27,807 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 09:38:27,808 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:38:29,318 epoch 4 - iter 0/16 - loss 0.54620510 - samples/sec: 25.96\n",
      "2019-11-24 09:38:30,717 epoch 4 - iter 1/16 - loss 0.44345939 - samples/sec: 23.44\n",
      "2019-11-24 09:38:32,062 epoch 4 - iter 2/16 - loss 0.45792498 - samples/sec: 24.06\n",
      "2019-11-24 09:38:34,390 epoch 4 - iter 3/16 - loss 0.44750846 - samples/sec: 13.83\n",
      "2019-11-24 09:38:36,864 epoch 4 - iter 4/16 - loss 0.45593442 - samples/sec: 13.10\n",
      "2019-11-24 09:38:39,007 epoch 4 - iter 5/16 - loss 0.44881604 - samples/sec: 15.08\n",
      "2019-11-24 09:38:41,484 epoch 4 - iter 6/16 - loss 0.44727342 - samples/sec: 12.99\n",
      "2019-11-24 09:38:42,662 epoch 4 - iter 7/16 - loss 0.43807139 - samples/sec: 27.69\n",
      "2019-11-24 09:38:45,068 epoch 4 - iter 8/16 - loss 0.43658300 - samples/sec: 13.39\n",
      "2019-11-24 09:38:46,286 epoch 4 - iter 9/16 - loss 0.44691787 - samples/sec: 26.97\n",
      "2019-11-24 09:38:48,217 epoch 4 - iter 10/16 - loss 0.45960316 - samples/sec: 16.70\n",
      "2019-11-24 09:38:49,872 epoch 4 - iter 11/16 - loss 0.45586964 - samples/sec: 19.54\n",
      "2019-11-24 09:38:51,867 epoch 4 - iter 12/16 - loss 0.45140700 - samples/sec: 16.14\n",
      "2019-11-24 09:38:53,653 epoch 4 - iter 13/16 - loss 0.44934429 - samples/sec: 18.07\n",
      "2019-11-24 09:38:54,782 epoch 4 - iter 14/16 - loss 0.45126210 - samples/sec: 28.67\n",
      "2019-11-24 09:38:55,530 epoch 4 - iter 15/16 - loss 0.44594616 - samples/sec: 43.81\n",
      "2019-11-24 09:38:55,687 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:38:55,689 EPOCH 4 done: loss 0.4459 - lr 0.1000\n",
      "2019-11-24 09:38:59,421 DEV : loss 0.5460681319236755 - score 0.7213\n",
      "2019-11-24 09:38:59,464 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 09:39:02,665 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:39:04,892 epoch 5 - iter 0/16 - loss 0.29474908 - samples/sec: 16.69\n",
      "2019-11-24 09:39:06,507 epoch 5 - iter 1/16 - loss 0.29335988 - samples/sec: 20.06\n",
      "2019-11-24 09:39:07,430 epoch 5 - iter 2/16 - loss 0.31650597 - samples/sec: 35.37\n",
      "2019-11-24 09:39:08,660 epoch 5 - iter 3/16 - loss 0.34616825 - samples/sec: 26.34\n",
      "2019-11-24 09:39:10,383 epoch 5 - iter 4/16 - loss 0.42446967 - samples/sec: 18.77\n",
      "2019-11-24 09:39:11,391 epoch 5 - iter 5/16 - loss 0.48980081 - samples/sec: 32.56\n",
      "2019-11-24 09:39:12,567 epoch 5 - iter 6/16 - loss 0.51891278 - samples/sec: 27.70\n",
      "2019-11-24 09:39:13,445 epoch 5 - iter 7/16 - loss 0.51585881 - samples/sec: 36.91\n",
      "2019-11-24 09:39:14,491 epoch 5 - iter 8/16 - loss 0.54248334 - samples/sec: 30.96\n",
      "2019-11-24 09:39:15,587 epoch 5 - iter 9/16 - loss 0.54948313 - samples/sec: 29.74\n",
      "2019-11-24 09:39:17,434 epoch 5 - iter 10/16 - loss 0.55372330 - samples/sec: 17.47\n",
      "2019-11-24 09:39:18,353 epoch 5 - iter 11/16 - loss 0.56208343 - samples/sec: 35.87\n",
      "2019-11-24 09:39:19,967 epoch 5 - iter 12/16 - loss 0.56231089 - samples/sec: 19.99\n",
      "2019-11-24 09:39:21,615 epoch 5 - iter 13/16 - loss 0.55911043 - samples/sec: 19.56\n",
      "2019-11-24 09:39:23,084 epoch 5 - iter 14/16 - loss 0.55278721 - samples/sec: 21.95\n",
      "2019-11-24 09:39:24,195 epoch 5 - iter 15/16 - loss 0.55225286 - samples/sec: 29.17\n",
      "2019-11-24 09:39:24,362 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:39:24,363 EPOCH 5 done: loss 0.5523 - lr 0.1000\n",
      "2019-11-24 09:39:27,548 DEV : loss 0.5312714576721191 - score 0.6885\n",
      "2019-11-24 09:39:27,589 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 09:39:27,591 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:39:29,135 epoch 6 - iter 0/16 - loss 0.38392586 - samples/sec: 26.59\n",
      "2019-11-24 09:39:31,177 epoch 6 - iter 1/16 - loss 0.39233747 - samples/sec: 15.83\n",
      "2019-11-24 09:39:34,007 epoch 6 - iter 2/16 - loss 0.34370377 - samples/sec: 11.38\n",
      "2019-11-24 09:39:36,085 epoch 6 - iter 3/16 - loss 0.38976784 - samples/sec: 15.53\n",
      "2019-11-24 09:39:37,893 epoch 6 - iter 4/16 - loss 0.39953205 - samples/sec: 18.09\n",
      "2019-11-24 09:39:39,125 epoch 6 - iter 5/16 - loss 0.39074713 - samples/sec: 26.25\n",
      "2019-11-24 09:39:41,263 epoch 6 - iter 6/16 - loss 0.39179562 - samples/sec: 15.08\n",
      "2019-11-24 09:39:42,518 epoch 6 - iter 7/16 - loss 0.39952573 - samples/sec: 25.78\n",
      "2019-11-24 09:39:43,626 epoch 6 - iter 8/16 - loss 0.40388064 - samples/sec: 29.19\n",
      "2019-11-24 09:39:45,477 epoch 6 - iter 9/16 - loss 0.40206835 - samples/sec: 17.44\n",
      "2019-11-24 09:39:46,592 epoch 6 - iter 10/16 - loss 0.40592218 - samples/sec: 29.15\n",
      "2019-11-24 09:39:47,794 epoch 6 - iter 11/16 - loss 0.40029307 - samples/sec: 26.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:39:48,775 epoch 6 - iter 12/16 - loss 0.39615053 - samples/sec: 33.10\n",
      "2019-11-24 09:39:50,503 epoch 6 - iter 13/16 - loss 0.39545979 - samples/sec: 18.72\n",
      "2019-11-24 09:39:52,306 epoch 6 - iter 14/16 - loss 0.38564175 - samples/sec: 17.89\n",
      "2019-11-24 09:39:52,848 epoch 6 - iter 15/16 - loss 0.38875379 - samples/sec: 60.79\n",
      "2019-11-24 09:39:53,194 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:39:53,195 EPOCH 6 done: loss 0.3888 - lr 0.1000\n",
      "2019-11-24 09:39:57,181 DEV : loss 0.5257899165153503 - score 0.7541\n",
      "2019-11-24 09:39:57,224 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 09:40:00,363 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:40:02,762 epoch 7 - iter 0/16 - loss 0.38311625 - samples/sec: 15.88\n",
      "2019-11-24 09:40:03,782 epoch 7 - iter 1/16 - loss 0.33764593 - samples/sec: 31.82\n",
      "2019-11-24 09:40:04,782 epoch 7 - iter 2/16 - loss 0.33280908 - samples/sec: 32.60\n",
      "2019-11-24 09:40:06,772 epoch 7 - iter 3/16 - loss 0.35362074 - samples/sec: 16.24\n",
      "2019-11-24 09:40:08,028 epoch 7 - iter 4/16 - loss 0.37121673 - samples/sec: 25.78\n",
      "2019-11-24 09:40:10,211 epoch 7 - iter 5/16 - loss 0.35598531 - samples/sec: 14.78\n",
      "2019-11-24 09:40:11,639 epoch 7 - iter 6/16 - loss 0.35479060 - samples/sec: 22.93\n",
      "2019-11-24 09:40:13,133 epoch 7 - iter 7/16 - loss 0.36627232 - samples/sec: 21.63\n",
      "2019-11-24 09:40:14,886 epoch 7 - iter 8/16 - loss 0.36681411 - samples/sec: 18.47\n",
      "2019-11-24 09:40:16,707 epoch 7 - iter 9/16 - loss 0.37350503 - samples/sec: 17.70\n",
      "2019-11-24 09:40:17,980 epoch 7 - iter 10/16 - loss 0.37089058 - samples/sec: 25.40\n",
      "2019-11-24 09:40:18,979 epoch 7 - iter 11/16 - loss 0.37049786 - samples/sec: 32.56\n",
      "2019-11-24 09:40:20,023 epoch 7 - iter 12/16 - loss 0.37548182 - samples/sec: 31.31\n",
      "2019-11-24 09:40:21,807 epoch 7 - iter 13/16 - loss 0.37084294 - samples/sec: 18.06\n",
      "2019-11-24 09:40:22,911 epoch 7 - iter 14/16 - loss 0.38393920 - samples/sec: 29.29\n",
      "2019-11-24 09:40:23,675 epoch 7 - iter 15/16 - loss 0.37230164 - samples/sec: 42.48\n",
      "2019-11-24 09:40:23,838 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:40:23,839 EPOCH 7 done: loss 0.3723 - lr 0.1000\n",
      "2019-11-24 09:40:27,188 DEV : loss 0.6032366752624512 - score 0.7377\n",
      "2019-11-24 09:40:27,230 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 09:40:27,231 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:40:28,985 epoch 8 - iter 0/16 - loss 0.34697959 - samples/sec: 23.82\n",
      "2019-11-24 09:40:30,538 epoch 8 - iter 1/16 - loss 0.34984010 - samples/sec: 20.86\n",
      "2019-11-24 09:40:32,292 epoch 8 - iter 2/16 - loss 0.39000363 - samples/sec: 18.45\n",
      "2019-11-24 09:40:33,294 epoch 8 - iter 3/16 - loss 0.38343854 - samples/sec: 32.36\n",
      "2019-11-24 09:40:34,841 epoch 8 - iter 4/16 - loss 0.39684503 - samples/sec: 21.11\n",
      "2019-11-24 09:40:35,787 epoch 8 - iter 5/16 - loss 0.38738413 - samples/sec: 34.34\n",
      "2019-11-24 09:40:36,858 epoch 8 - iter 6/16 - loss 0.37151779 - samples/sec: 30.27\n",
      "2019-11-24 09:40:38,573 epoch 8 - iter 7/16 - loss 0.40027548 - samples/sec: 18.80\n",
      "2019-11-24 09:40:40,357 epoch 8 - iter 8/16 - loss 0.39369707 - samples/sec: 18.07\n",
      "2019-11-24 09:40:41,256 epoch 8 - iter 9/16 - loss 0.38872489 - samples/sec: 36.11\n",
      "2019-11-24 09:40:42,381 epoch 8 - iter 10/16 - loss 0.36943176 - samples/sec: 29.04\n",
      "2019-11-24 09:40:44,147 epoch 8 - iter 11/16 - loss 0.37042345 - samples/sec: 18.28\n",
      "2019-11-24 09:40:45,994 epoch 8 - iter 12/16 - loss 0.37945030 - samples/sec: 17.43\n",
      "2019-11-24 09:40:46,874 epoch 8 - iter 13/16 - loss 0.37644351 - samples/sec: 36.91\n",
      "2019-11-24 09:40:48,673 epoch 8 - iter 14/16 - loss 0.38554645 - samples/sec: 17.95\n",
      "2019-11-24 09:40:49,407 epoch 8 - iter 15/16 - loss 0.38958357 - samples/sec: 44.44\n",
      "2019-11-24 09:40:49,609 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:40:49,610 EPOCH 8 done: loss 0.3896 - lr 0.1000\n",
      "2019-11-24 09:40:52,978 DEV : loss 0.5362969636917114 - score 0.7377\n",
      "2019-11-24 09:40:53,014 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 09:40:53,016 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:40:55,207 epoch 9 - iter 0/16 - loss 0.27094623 - samples/sec: 18.66\n",
      "2019-11-24 09:40:56,439 epoch 9 - iter 1/16 - loss 0.49676536 - samples/sec: 26.33\n",
      "2019-11-24 09:40:58,004 epoch 9 - iter 2/16 - loss 0.48729167 - samples/sec: 20.64\n",
      "2019-11-24 09:40:58,838 epoch 9 - iter 3/16 - loss 0.45709936 - samples/sec: 39.09\n",
      "2019-11-24 09:40:59,823 epoch 9 - iter 4/16 - loss 0.43937777 - samples/sec: 33.26\n",
      "2019-11-24 09:41:01,564 epoch 9 - iter 5/16 - loss 0.42256203 - samples/sec: 18.52\n",
      "2019-11-24 09:41:02,534 epoch 9 - iter 6/16 - loss 0.41884576 - samples/sec: 33.45\n",
      "2019-11-24 09:41:04,549 epoch 9 - iter 7/16 - loss 0.41080936 - samples/sec: 16.05\n",
      "2019-11-24 09:41:06,633 epoch 9 - iter 8/16 - loss 0.39935658 - samples/sec: 15.46\n",
      "2019-11-24 09:41:09,015 epoch 9 - iter 9/16 - loss 0.37898543 - samples/sec: 13.50\n",
      "2019-11-24 09:41:11,264 epoch 9 - iter 10/16 - loss 0.38761081 - samples/sec: 14.38\n",
      "2019-11-24 09:41:13,045 epoch 9 - iter 11/16 - loss 0.42027951 - samples/sec: 18.10\n",
      "2019-11-24 09:41:14,387 epoch 9 - iter 12/16 - loss 0.43232415 - samples/sec: 24.43\n",
      "2019-11-24 09:41:15,505 epoch 9 - iter 13/16 - loss 0.44378734 - samples/sec: 28.98\n",
      "2019-11-24 09:41:16,592 epoch 9 - iter 14/16 - loss 0.44679904 - samples/sec: 29.93\n",
      "2019-11-24 09:41:17,207 epoch 9 - iter 15/16 - loss 0.43142556 - samples/sec: 53.08\n",
      "2019-11-24 09:41:17,416 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:41:17,417 EPOCH 9 done: loss 0.4314 - lr 0.1000\n",
      "2019-11-24 09:41:21,752 DEV : loss 0.43666142225265503 - score 0.7213\n",
      "2019-11-24 09:41:21,801 BAD EPOCHS (no improvement): 3\n",
      "2019-11-24 09:41:21,803 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:41:24,260 epoch 10 - iter 0/16 - loss 0.32290056 - samples/sec: 16.52\n",
      "2019-11-24 09:41:25,308 epoch 10 - iter 1/16 - loss 0.36692773 - samples/sec: 31.14\n",
      "2019-11-24 09:41:26,603 epoch 10 - iter 2/16 - loss 0.32639251 - samples/sec: 25.38\n",
      "2019-11-24 09:41:28,054 epoch 10 - iter 3/16 - loss 0.29138411 - samples/sec: 22.29\n",
      "2019-11-24 09:41:29,997 epoch 10 - iter 4/16 - loss 0.31976747 - samples/sec: 16.66\n",
      "2019-11-24 09:41:31,414 epoch 10 - iter 5/16 - loss 0.31054483 - samples/sec: 22.96\n",
      "2019-11-24 09:41:32,708 epoch 10 - iter 6/16 - loss 0.30779024 - samples/sec: 25.13\n",
      "2019-11-24 09:41:34,633 epoch 10 - iter 7/16 - loss 0.31060267 - samples/sec: 16.71\n",
      "2019-11-24 09:41:36,583 epoch 10 - iter 8/16 - loss 0.33244627 - samples/sec: 16.55\n",
      "2019-11-24 09:41:38,890 epoch 10 - iter 9/16 - loss 0.33264155 - samples/sec: 14.02\n",
      "2019-11-24 09:41:40,928 epoch 10 - iter 10/16 - loss 0.33523125 - samples/sec: 15.81\n",
      "2019-11-24 09:41:42,872 epoch 10 - iter 11/16 - loss 0.34625963 - samples/sec: 16.60\n",
      "2019-11-24 09:41:44,112 epoch 10 - iter 12/16 - loss 0.34889929 - samples/sec: 26.17\n",
      "2019-11-24 09:41:45,378 epoch 10 - iter 13/16 - loss 0.37034510 - samples/sec: 25.62\n",
      "2019-11-24 09:41:47,491 epoch 10 - iter 14/16 - loss 0.36781773 - samples/sec: 15.26\n",
      "2019-11-24 09:41:47,993 epoch 10 - iter 15/16 - loss 0.37107615 - samples/sec: 65.75\n",
      "2019-11-24 09:41:48,371 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:41:48,374 EPOCH 10 done: loss 0.3711 - lr 0.1000\n",
      "2019-11-24 09:41:51,954 DEV : loss 0.8395968079566956 - score 0.623\n",
      "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-11-24 09:41:51,994 BAD EPOCHS (no improvement): 4\n",
      "2019-11-24 09:41:55,250 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:41:55,251 Testing using best model ...\n",
      "2019-11-24 09:41:55,252 loading file test/title10/best-model.pt\n",
      "2019-11-24 09:41:59,752 0.8689\t0.8689\t0.8689\n",
      "2019-11-24 09:41:59,753 \n",
      "MICRO_AVG: acc 0.7681 - f1-score 0.8689\n",
      "MACRO_AVG: acc 0.7681 - f1-score 0.86885\n",
      "fake       tp: 26 - fp: 7 - fn: 1 - tn: 27 - precision: 0.7879 - recall: 0.9630 - accuracy: 0.7647 - f1-score: 0.8667\n",
      "real       tp: 27 - fp: 1 - fn: 7 - tn: 26 - precision: 0.9643 - recall: 0.7941 - accuracy: 0.7714 - f1-score: 0.8710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 09:41:59,754 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 09:41:59,755 loading file ./test/title10/best-model.pt\n",
      "acc:  0.7337662337662337\n",
      "precision:  0.7261904761904762\n",
      "recall:  0.7721518987341772\n",
      "f1:  0.7484662576687117\n"
     ]
    }
   ],
   "source": [
    "path = './test/title10'\n",
    "make_test(train_title, test_title, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['url', 'text', 'images', 'top_img', 'keywords', 'authors', 'canonical_link', 'title', 'meta_data', 'movies', 'publish_date', 'source', 'summary'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_content[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643\n",
      "162\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_summary = [(x['summary'], label) for x, label in train_content] \n",
    "test_summary = [(x['summary'], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_summary if x == '']))\n",
    "print(len([x for x, label in test_summary if x == '']))\n",
    "train_summary = [(x, label) for x, label in train_summary if x != ''] \n",
    "test_summary = [(x, label) for x, label in test_summary if x != '']\n",
    "print(len(train_summary))\n",
    "print(len(test_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "12\n",
      "582\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "train_text = [(x['text'][:100], label) for x, label in train_content] \n",
    "test_text = [(x['text'][:100], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_text if x == '']))\n",
    "print(len([x for x, label in test_text if x == '']))\n",
    "train_text = [(x, label) for x, label in train_text if x != ''] \n",
    "test_text = [(x, label) for x, label in test_text if x != '']\n",
    "print(len(train_text))\n",
    "print(len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:09:17,387 Reading data from test/text1\n",
      "2019-11-24 10:09:17,388 Train: test/text1/train.csv\n",
      "2019-11-24 10:09:17,389 Dev: test/text1/dev.csv\n",
      "2019-11-24 10:09:17,390 Test: test/text1/test.csv\n",
      "2019-11-24 10:09:17,395 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 2855.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:09:17,665 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:09:19,204 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:19,205 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 10:09:19,206 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:19,206 Corpus: \"Corpus: 465 train + 59 dev + 58 test sentences\"\n",
      "2019-11-24 10:09:19,208 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:19,208 Parameters:\n",
      "2019-11-24 10:09:19,209  - learning_rate: \"0.1\"\n",
      "2019-11-24 10:09:19,210  - mini_batch_size: \"32\"\n",
      "2019-11-24 10:09:19,211  - patience: \"3\"\n",
      "2019-11-24 10:09:19,212  - anneal_factor: \"0.5\"\n",
      "2019-11-24 10:09:19,213  - max_epochs: \"1\"\n",
      "2019-11-24 10:09:19,216  - shuffle: \"True\"\n",
      "2019-11-24 10:09:19,217  - train_with_dev: \"False\"\n",
      "2019-11-24 10:09:19,218  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 10:09:19,219 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:19,219 Model training base path: \"test/text1\"\n",
      "2019-11-24 10:09:19,221 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:19,225 Device: cpu\n",
      "2019-11-24 10:09:19,226 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:19,228 Embeddings storage mode: cpu\n",
      "2019-11-24 10:09:19,232 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:20,821 epoch 1 - iter 0/15 - loss 0.68888623 - samples/sec: 22.60\n",
      "2019-11-24 10:09:22,010 epoch 1 - iter 1/15 - loss 0.72436053 - samples/sec: 27.83\n",
      "2019-11-24 10:09:23,073 epoch 1 - iter 2/15 - loss 0.70654768 - samples/sec: 30.53\n",
      "2019-11-24 10:09:24,125 epoch 1 - iter 3/15 - loss 0.70862959 - samples/sec: 30.85\n",
      "2019-11-24 10:09:25,217 epoch 1 - iter 4/15 - loss 0.69953331 - samples/sec: 29.69\n",
      "2019-11-24 10:09:26,160 epoch 1 - iter 5/15 - loss 0.70002906 - samples/sec: 34.36\n",
      "2019-11-24 10:09:27,343 epoch 1 - iter 6/15 - loss 0.70015259 - samples/sec: 27.45\n",
      "2019-11-24 10:09:28,270 epoch 1 - iter 7/15 - loss 0.69701709 - samples/sec: 35.57\n",
      "2019-11-24 10:09:29,217 epoch 1 - iter 8/15 - loss 0.69487153 - samples/sec: 34.37\n",
      "2019-11-24 10:09:30,142 epoch 1 - iter 9/15 - loss 0.68798032 - samples/sec: 35.20\n",
      "2019-11-24 10:09:31,073 epoch 1 - iter 10/15 - loss 0.69237144 - samples/sec: 34.80\n",
      "2019-11-24 10:09:32,122 epoch 1 - iter 11/15 - loss 0.69189975 - samples/sec: 30.94\n",
      "2019-11-24 10:09:33,160 epoch 1 - iter 12/15 - loss 0.69437377 - samples/sec: 31.67\n",
      "2019-11-24 10:09:34,117 epoch 1 - iter 13/15 - loss 0.69549353 - samples/sec: 34.18\n",
      "2019-11-24 10:09:34,863 epoch 1 - iter 14/15 - loss 0.69113661 - samples/sec: 43.54\n",
      "2019-11-24 10:09:34,915 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:34,916 EPOCH 1 done: loss 0.6911 - lr 0.1000\n",
      "2019-11-24 10:09:36,755 DEV : loss 0.666548490524292 - score 0.5254\n",
      "2019-11-24 10:09:36,807 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:09:42,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:42,280 Testing using best model ...\n",
      "2019-11-24 10:09:42,281 loading file test/text1/best-model.pt\n",
      "2019-11-24 10:09:45,363 0.569\t0.569\t0.569\n",
      "2019-11-24 10:09:45,364 \n",
      "MICRO_AVG: acc 0.3976 - f1-score 0.569\n",
      "MACRO_AVG: acc 0.2999 - f1-score 0.39659999999999995\n",
      "fake       tp: 1 - fp: 0 - fn: 25 - tn: 32 - precision: 1.0000 - recall: 0.0385 - accuracy: 0.0385 - f1-score: 0.0741\n",
      "real       tp: 32 - fp: 25 - fn: 0 - tn: 1 - precision: 0.5614 - recall: 1.0000 - accuracy: 0.5614 - f1-score: 0.7191\n",
      "2019-11-24 10:09:45,364 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:09:45,366 loading file ./test/text1/best-model.pt\n",
      "acc:  0.5\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.02631578947368421\n",
      "f1:  0.05063291139240506\n"
     ]
    }
   ],
   "source": [
    "path = './test/text1'\n",
    "make_test(train_text, test_text, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:10:29,469 Reading data from test/text1\n",
      "2019-11-24 10:10:29,470 Train: test/text1/train.csv\n",
      "2019-11-24 10:10:29,471 Dev: test/text1/dev.csv\n",
      "2019-11-24 10:10:29,472 Test: test/text1/test.csv\n",
      "2019-11-24 10:10:29,478 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [00:00<00:00, 2025.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:10:29,929 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:10:31,102 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:31,103 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 10:10:31,104 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:31,104 Corpus: \"Corpus: 465 train + 59 dev + 58 test sentences\"\n",
      "2019-11-24 10:10:31,105 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:31,106 Parameters:\n",
      "2019-11-24 10:10:31,107  - learning_rate: \"0.1\"\n",
      "2019-11-24 10:10:31,107  - mini_batch_size: \"32\"\n",
      "2019-11-24 10:10:31,108  - patience: \"3\"\n",
      "2019-11-24 10:10:31,108  - anneal_factor: \"0.5\"\n",
      "2019-11-24 10:10:31,109  - max_epochs: \"10\"\n",
      "2019-11-24 10:10:31,109  - shuffle: \"True\"\n",
      "2019-11-24 10:10:31,110  - train_with_dev: \"False\"\n",
      "2019-11-24 10:10:31,110  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 10:10:31,111 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:31,127 Model training base path: \"test/text1\"\n",
      "2019-11-24 10:10:31,128 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:31,129 Device: cpu\n",
      "2019-11-24 10:10:31,130 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:31,131 Embeddings storage mode: cpu\n",
      "2019-11-24 10:10:31,132 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:32,869 epoch 1 - iter 0/15 - loss 0.69420803 - samples/sec: 23.26\n",
      "2019-11-24 10:10:34,450 epoch 1 - iter 1/15 - loss 0.70164040 - samples/sec: 20.46\n",
      "2019-11-24 10:10:35,491 epoch 1 - iter 2/15 - loss 0.70385971 - samples/sec: 31.15\n",
      "2019-11-24 10:10:36,522 epoch 1 - iter 3/15 - loss 0.70627920 - samples/sec: 31.47\n",
      "2019-11-24 10:10:37,557 epoch 1 - iter 4/15 - loss 0.69590334 - samples/sec: 31.50\n",
      "2019-11-24 10:10:38,586 epoch 1 - iter 5/15 - loss 0.68983970 - samples/sec: 31.46\n",
      "2019-11-24 10:10:39,603 epoch 1 - iter 6/15 - loss 0.69837208 - samples/sec: 32.93\n",
      "2019-11-24 10:10:40,771 epoch 1 - iter 7/15 - loss 0.70510374 - samples/sec: 27.67\n",
      "2019-11-24 10:10:41,792 epoch 1 - iter 8/15 - loss 0.69930912 - samples/sec: 31.74\n",
      "2019-11-24 10:10:42,801 epoch 1 - iter 9/15 - loss 0.69397897 - samples/sec: 32.08\n",
      "2019-11-24 10:10:43,801 epoch 1 - iter 10/15 - loss 0.69008311 - samples/sec: 32.79\n",
      "2019-11-24 10:10:45,024 epoch 1 - iter 11/15 - loss 0.68509794 - samples/sec: 26.59\n",
      "2019-11-24 10:10:46,176 epoch 1 - iter 12/15 - loss 0.68197292 - samples/sec: 28.39\n",
      "2019-11-24 10:10:47,183 epoch 1 - iter 13/15 - loss 0.67985953 - samples/sec: 32.21\n",
      "2019-11-24 10:10:47,941 epoch 1 - iter 14/15 - loss 0.67961064 - samples/sec: 43.19\n",
      "2019-11-24 10:10:48,043 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:48,044 EPOCH 1 done: loss 0.6796 - lr 0.1000\n",
      "2019-11-24 10:10:50,064 DEV : loss 0.7264953851699829 - score 0.5424\n",
      "2019-11-24 10:10:50,108 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:10:53,512 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:10:54,982 epoch 2 - iter 0/15 - loss 0.58215338 - samples/sec: 25.49\n",
      "2019-11-24 10:10:56,353 epoch 2 - iter 1/15 - loss 0.60061797 - samples/sec: 23.83\n",
      "2019-11-24 10:10:57,427 epoch 2 - iter 2/15 - loss 0.63327116 - samples/sec: 30.30\n",
      "2019-11-24 10:10:58,443 epoch 2 - iter 3/15 - loss 0.64355038 - samples/sec: 32.81\n",
      "2019-11-24 10:10:59,511 epoch 2 - iter 4/15 - loss 0.63696632 - samples/sec: 30.32\n",
      "2019-11-24 10:11:00,594 epoch 2 - iter 5/15 - loss 0.63926754 - samples/sec: 29.99\n",
      "2019-11-24 10:11:01,624 epoch 2 - iter 6/15 - loss 0.63069227 - samples/sec: 31.58\n",
      "2019-11-24 10:11:02,695 epoch 2 - iter 7/15 - loss 0.64185501 - samples/sec: 30.21\n",
      "2019-11-24 10:11:03,717 epoch 2 - iter 8/15 - loss 0.64677330 - samples/sec: 32.04\n",
      "2019-11-24 10:11:04,845 epoch 2 - iter 9/15 - loss 0.64320197 - samples/sec: 29.16\n",
      "2019-11-24 10:11:05,979 epoch 2 - iter 10/15 - loss 0.64011414 - samples/sec: 28.58\n",
      "2019-11-24 10:11:07,284 epoch 2 - iter 11/15 - loss 0.64152934 - samples/sec: 24.75\n",
      "2019-11-24 10:11:08,845 epoch 2 - iter 12/15 - loss 0.64356526 - samples/sec: 20.69\n",
      "2019-11-24 10:11:10,218 epoch 2 - iter 13/15 - loss 0.63807227 - samples/sec: 23.57\n",
      "2019-11-24 10:11:11,233 epoch 2 - iter 14/15 - loss 0.63564059 - samples/sec: 31.99\n",
      "2019-11-24 10:11:11,313 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:11:11,314 EPOCH 2 done: loss 0.6356 - lr 0.1000\n",
      "2019-11-24 10:11:13,553 DEV : loss 0.6417226791381836 - score 0.5932\n",
      "2019-11-24 10:11:13,607 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 10:11:16,901 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:11:18,338 epoch 3 - iter 0/15 - loss 0.51316029 - samples/sec: 26.64\n",
      "2019-11-24 10:11:19,408 epoch 3 - iter 1/15 - loss 0.57671815 - samples/sec: 30.44\n",
      "2019-11-24 10:11:20,450 epoch 3 - iter 2/15 - loss 0.55446599 - samples/sec: 31.16\n",
      "2019-11-24 10:11:21,566 epoch 3 - iter 3/15 - loss 0.59271954 - samples/sec: 29.20\n",
      "2019-11-24 10:11:22,661 epoch 3 - iter 4/15 - loss 0.62297373 - samples/sec: 29.53\n",
      "2019-11-24 10:11:23,758 epoch 3 - iter 5/15 - loss 0.61414464 - samples/sec: 29.62\n",
      "2019-11-24 10:11:24,898 epoch 3 - iter 6/15 - loss 0.60774616 - samples/sec: 28.67\n",
      "2019-11-24 10:11:26,086 epoch 3 - iter 7/15 - loss 0.62250873 - samples/sec: 27.45\n",
      "2019-11-24 10:11:27,278 epoch 3 - iter 8/15 - loss 0.63108545 - samples/sec: 27.10\n",
      "2019-11-24 10:11:28,579 epoch 3 - iter 9/15 - loss 0.62872418 - samples/sec: 25.10\n",
      "2019-11-24 10:11:29,776 epoch 3 - iter 10/15 - loss 0.62268746 - samples/sec: 27.05\n",
      "2019-11-24 10:11:30,829 epoch 3 - iter 11/15 - loss 0.62712226 - samples/sec: 30.69\n",
      "2019-11-24 10:11:31,834 epoch 3 - iter 12/15 - loss 0.62467645 - samples/sec: 32.29\n",
      "2019-11-24 10:11:32,933 epoch 3 - iter 13/15 - loss 0.62739334 - samples/sec: 29.53\n",
      "2019-11-24 10:11:33,753 epoch 3 - iter 14/15 - loss 0.61973663 - samples/sec: 39.55\n",
      "2019-11-24 10:11:33,867 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:11:33,867 EPOCH 3 done: loss 0.6197 - lr 0.1000\n",
      "2019-11-24 10:11:36,199 DEV : loss 0.7332628965377808 - score 0.6102\n",
      "2019-11-24 10:11:36,244 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 10:11:39,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:11:40,921 epoch 4 - iter 0/15 - loss 0.51161039 - samples/sec: 27.18\n",
      "2019-11-24 10:11:42,206 epoch 4 - iter 1/15 - loss 0.55833495 - samples/sec: 25.29\n",
      "2019-11-24 10:11:43,265 epoch 4 - iter 2/15 - loss 0.56039405 - samples/sec: 30.64\n",
      "2019-11-24 10:11:44,323 epoch 4 - iter 3/15 - loss 0.56264260 - samples/sec: 30.59\n",
      "2019-11-24 10:11:45,411 epoch 4 - iter 4/15 - loss 0.56257575 - samples/sec: 29.85\n",
      "2019-11-24 10:11:46,451 epoch 4 - iter 5/15 - loss 0.59023644 - samples/sec: 31.23\n",
      "2019-11-24 10:11:47,554 epoch 4 - iter 6/15 - loss 0.58959866 - samples/sec: 29.43\n",
      "2019-11-24 10:11:48,605 epoch 4 - iter 7/15 - loss 0.59553696 - samples/sec: 31.09\n",
      "2019-11-24 10:11:49,694 epoch 4 - iter 8/15 - loss 0.58524023 - samples/sec: 29.66\n",
      "2019-11-24 10:11:50,733 epoch 4 - iter 9/15 - loss 0.58168306 - samples/sec: 31.17\n",
      "2019-11-24 10:11:51,852 epoch 4 - iter 10/15 - loss 0.57191020 - samples/sec: 28.96\n",
      "2019-11-24 10:11:52,973 epoch 4 - iter 11/15 - loss 0.57614772 - samples/sec: 28.91\n",
      "2019-11-24 10:11:54,039 epoch 4 - iter 12/15 - loss 0.58392840 - samples/sec: 30.41\n",
      "2019-11-24 10:11:55,051 epoch 4 - iter 13/15 - loss 0.57685488 - samples/sec: 32.18\n",
      "2019-11-24 10:11:55,872 epoch 4 - iter 14/15 - loss 0.59073661 - samples/sec: 39.54\n",
      "2019-11-24 10:11:55,995 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:11:55,996 EPOCH 4 done: loss 0.5907 - lr 0.1000\n",
      "2019-11-24 10:11:58,335 DEV : loss 0.6344838738441467 - score 0.5763\n",
      "2019-11-24 10:11:58,378 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 10:11:58,379 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:12:00,040 epoch 5 - iter 0/15 - loss 0.65332592 - samples/sec: 24.07\n",
      "2019-11-24 10:12:01,305 epoch 5 - iter 1/15 - loss 0.58583885 - samples/sec: 25.66\n",
      "2019-11-24 10:12:02,420 epoch 5 - iter 2/15 - loss 0.56865114 - samples/sec: 29.12\n",
      "2019-11-24 10:12:03,624 epoch 5 - iter 3/15 - loss 0.54591371 - samples/sec: 26.96\n",
      "2019-11-24 10:12:04,654 epoch 5 - iter 4/15 - loss 0.55530099 - samples/sec: 31.55\n",
      "2019-11-24 10:12:05,851 epoch 5 - iter 5/15 - loss 0.57961975 - samples/sec: 27.09\n",
      "2019-11-24 10:12:06,925 epoch 5 - iter 6/15 - loss 0.56678868 - samples/sec: 30.29\n",
      "2019-11-24 10:12:08,031 epoch 5 - iter 7/15 - loss 0.55511070 - samples/sec: 29.45\n",
      "2019-11-24 10:12:09,177 epoch 5 - iter 8/15 - loss 0.58609025 - samples/sec: 28.24\n",
      "2019-11-24 10:12:10,257 epoch 5 - iter 9/15 - loss 0.58684728 - samples/sec: 30.19\n",
      "2019-11-24 10:12:11,364 epoch 5 - iter 10/15 - loss 0.58099868 - samples/sec: 29.28\n",
      "2019-11-24 10:12:12,418 epoch 5 - iter 11/15 - loss 0.57981255 - samples/sec: 30.79\n",
      "2019-11-24 10:12:13,529 epoch 5 - iter 12/15 - loss 0.57890732 - samples/sec: 29.25\n",
      "2019-11-24 10:12:14,575 epoch 5 - iter 13/15 - loss 0.57541486 - samples/sec: 31.16\n",
      "2019-11-24 10:12:15,397 epoch 5 - iter 14/15 - loss 0.56890327 - samples/sec: 39.70\n",
      "2019-11-24 10:12:15,511 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:12:15,512 EPOCH 5 done: loss 0.5689 - lr 0.1000\n",
      "2019-11-24 10:12:17,814 DEV : loss 0.6310573816299438 - score 0.678\n",
      "2019-11-24 10:12:17,859 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 10:12:21,031 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:12:22,619 epoch 6 - iter 0/15 - loss 0.44826972 - samples/sec: 24.92\n",
      "2019-11-24 10:12:23,706 epoch 6 - iter 1/15 - loss 0.52698213 - samples/sec: 29.91\n",
      "2019-11-24 10:12:24,774 epoch 6 - iter 2/15 - loss 0.53342893 - samples/sec: 30.44\n",
      "2019-11-24 10:12:25,872 epoch 6 - iter 3/15 - loss 0.52791557 - samples/sec: 29.62\n",
      "2019-11-24 10:12:27,041 epoch 6 - iter 4/15 - loss 0.51888544 - samples/sec: 27.87\n",
      "2019-11-24 10:12:28,076 epoch 6 - iter 5/15 - loss 0.52995938 - samples/sec: 31.34\n",
      "2019-11-24 10:12:29,109 epoch 6 - iter 6/15 - loss 0.57394393 - samples/sec: 31.40\n",
      "2019-11-24 10:12:30,169 epoch 6 - iter 7/15 - loss 0.60612687 - samples/sec: 30.69\n",
      "2019-11-24 10:12:31,257 epoch 6 - iter 8/15 - loss 0.62086595 - samples/sec: 29.80\n",
      "2019-11-24 10:12:32,324 epoch 6 - iter 9/15 - loss 0.60532978 - samples/sec: 30.44\n",
      "2019-11-24 10:12:33,367 epoch 6 - iter 10/15 - loss 0.58762410 - samples/sec: 31.10\n",
      "2019-11-24 10:12:34,443 epoch 6 - iter 11/15 - loss 0.57966460 - samples/sec: 30.22\n",
      "2019-11-24 10:12:35,547 epoch 6 - iter 12/15 - loss 0.56435191 - samples/sec: 29.39\n",
      "2019-11-24 10:12:36,586 epoch 6 - iter 13/15 - loss 0.57281823 - samples/sec: 31.35\n",
      "2019-11-24 10:12:37,415 epoch 6 - iter 14/15 - loss 0.57498092 - samples/sec: 39.20\n",
      "2019-11-24 10:12:37,542 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:12:37,543 EPOCH 6 done: loss 0.5750 - lr 0.1000\n",
      "2019-11-24 10:12:39,926 DEV : loss 0.7283656597137451 - score 0.5593\n",
      "2019-11-24 10:12:39,968 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 10:12:39,970 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:12:41,443 epoch 7 - iter 0/15 - loss 0.63462293 - samples/sec: 27.74\n",
      "2019-11-24 10:12:42,554 epoch 7 - iter 1/15 - loss 0.56112288 - samples/sec: 29.31\n",
      "2019-11-24 10:12:43,679 epoch 7 - iter 2/15 - loss 0.53502975 - samples/sec: 28.73\n",
      "2019-11-24 10:12:44,704 epoch 7 - iter 3/15 - loss 0.54088059 - samples/sec: 31.82\n",
      "2019-11-24 10:12:45,840 epoch 7 - iter 4/15 - loss 0.52440161 - samples/sec: 28.62\n",
      "2019-11-24 10:12:46,871 epoch 7 - iter 5/15 - loss 0.53437337 - samples/sec: 31.41\n",
      "2019-11-24 10:12:47,883 epoch 7 - iter 6/15 - loss 0.52869647 - samples/sec: 32.10\n",
      "2019-11-24 10:12:49,461 epoch 7 - iter 7/15 - loss 0.51449392 - samples/sec: 20.51\n",
      "2019-11-24 10:12:50,683 epoch 7 - iter 8/15 - loss 0.51469394 - samples/sec: 26.47\n",
      "2019-11-24 10:12:51,848 epoch 7 - iter 9/15 - loss 0.51270097 - samples/sec: 28.07\n",
      "2019-11-24 10:12:52,894 epoch 7 - iter 10/15 - loss 0.53802732 - samples/sec: 31.16\n",
      "2019-11-24 10:12:53,859 epoch 7 - iter 11/15 - loss 0.53464215 - samples/sec: 33.56\n",
      "2019-11-24 10:12:55,018 epoch 7 - iter 12/15 - loss 0.53596081 - samples/sec: 28.04\n",
      "2019-11-24 10:12:56,067 epoch 7 - iter 13/15 - loss 0.52828240 - samples/sec: 31.02\n",
      "2019-11-24 10:12:56,807 epoch 7 - iter 14/15 - loss 0.52592287 - samples/sec: 44.05\n",
      "2019-11-24 10:12:56,934 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:12:56,935 EPOCH 7 done: loss 0.5259 - lr 0.1000\n",
      "2019-11-24 10:12:59,337 DEV : loss 0.6745600700378418 - score 0.6102\n",
      "2019-11-24 10:12:59,382 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 10:12:59,383 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:13:00,883 epoch 8 - iter 0/15 - loss 0.53584206 - samples/sec: 28.31\n",
      "2019-11-24 10:13:01,977 epoch 8 - iter 1/15 - loss 0.53535882 - samples/sec: 29.60\n",
      "2019-11-24 10:13:03,027 epoch 8 - iter 2/15 - loss 0.50749950 - samples/sec: 30.87\n",
      "2019-11-24 10:13:04,070 epoch 8 - iter 3/15 - loss 0.50287348 - samples/sec: 31.07\n",
      "2019-11-24 10:13:05,100 epoch 8 - iter 4/15 - loss 0.52548630 - samples/sec: 31.57\n",
      "2019-11-24 10:13:06,124 epoch 8 - iter 5/15 - loss 0.52528387 - samples/sec: 31.64\n",
      "2019-11-24 10:13:07,239 epoch 8 - iter 6/15 - loss 0.51050780 - samples/sec: 29.30\n",
      "2019-11-24 10:13:08,245 epoch 8 - iter 7/15 - loss 0.51206234 - samples/sec: 32.16\n",
      "2019-11-24 10:13:09,335 epoch 8 - iter 8/15 - loss 0.50698696 - samples/sec: 29.65\n",
      "2019-11-24 10:13:10,333 epoch 8 - iter 9/15 - loss 0.50363528 - samples/sec: 32.53\n",
      "2019-11-24 10:13:11,368 epoch 8 - iter 10/15 - loss 0.50700499 - samples/sec: 31.28\n",
      "2019-11-24 10:13:12,380 epoch 8 - iter 11/15 - loss 0.50298297 - samples/sec: 32.07\n",
      "2019-11-24 10:13:13,406 epoch 8 - iter 12/15 - loss 0.49248550 - samples/sec: 31.68\n",
      "2019-11-24 10:13:14,423 epoch 8 - iter 13/15 - loss 0.48767917 - samples/sec: 31.86\n",
      "2019-11-24 10:13:15,184 epoch 8 - iter 14/15 - loss 0.49665542 - samples/sec: 42.63\n",
      "2019-11-24 10:13:15,328 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:13:15,329 EPOCH 8 done: loss 0.4967 - lr 0.1000\n",
      "2019-11-24 10:13:18,223 DEV : loss 0.9349395036697388 - score 0.5932\n",
      "2019-11-24 10:13:18,285 BAD EPOCHS (no improvement): 3\n",
      "2019-11-24 10:13:18,286 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:13:20,157 epoch 9 - iter 0/15 - loss 0.48896390 - samples/sec: 22.93\n",
      "2019-11-24 10:13:21,282 epoch 9 - iter 1/15 - loss 0.48665839 - samples/sec: 29.12\n",
      "2019-11-24 10:13:22,460 epoch 9 - iter 2/15 - loss 0.43717809 - samples/sec: 27.48\n",
      "2019-11-24 10:13:23,570 epoch 9 - iter 3/15 - loss 0.41492204 - samples/sec: 29.18\n",
      "2019-11-24 10:13:25,071 epoch 9 - iter 4/15 - loss 0.38248713 - samples/sec: 21.62\n",
      "2019-11-24 10:13:26,188 epoch 9 - iter 5/15 - loss 0.40024338 - samples/sec: 29.30\n",
      "2019-11-24 10:13:27,461 epoch 9 - iter 6/15 - loss 0.41766067 - samples/sec: 25.45\n",
      "2019-11-24 10:13:28,778 epoch 9 - iter 7/15 - loss 0.42360600 - samples/sec: 24.66\n",
      "2019-11-24 10:13:29,770 epoch 9 - iter 8/15 - loss 0.42337065 - samples/sec: 32.72\n",
      "2019-11-24 10:13:30,880 epoch 9 - iter 9/15 - loss 0.42457212 - samples/sec: 29.21\n",
      "2019-11-24 10:13:31,913 epoch 9 - iter 10/15 - loss 0.42427038 - samples/sec: 31.43\n",
      "2019-11-24 10:13:33,134 epoch 9 - iter 11/15 - loss 0.41617063 - samples/sec: 26.69\n",
      "2019-11-24 10:13:34,472 epoch 9 - iter 12/15 - loss 0.42072835 - samples/sec: 24.12\n",
      "2019-11-24 10:13:35,903 epoch 9 - iter 13/15 - loss 0.42168700 - samples/sec: 22.73\n",
      "2019-11-24 10:13:36,724 epoch 9 - iter 14/15 - loss 0.43775234 - samples/sec: 39.60\n",
      "2019-11-24 10:13:36,883 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:13:36,884 EPOCH 9 done: loss 0.4378 - lr 0.1000\n",
      "2019-11-24 10:13:41,026 DEV : loss 0.6851053833961487 - score 0.661\n",
      "Epoch     8: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-11-24 10:13:41,076 BAD EPOCHS (no improvement): 4\n",
      "2019-11-24 10:13:41,078 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:13:42,902 epoch 10 - iter 0/15 - loss 0.36600283 - samples/sec: 24.01\n",
      "2019-11-24 10:13:44,057 epoch 10 - iter 1/15 - loss 0.43078463 - samples/sec: 28.04\n",
      "2019-11-24 10:13:45,235 epoch 10 - iter 2/15 - loss 0.44601253 - samples/sec: 27.59\n",
      "2019-11-24 10:13:46,309 epoch 10 - iter 3/15 - loss 0.47513088 - samples/sec: 30.14\n",
      "2019-11-24 10:13:47,393 epoch 10 - iter 4/15 - loss 0.46891124 - samples/sec: 29.90\n",
      "2019-11-24 10:13:48,457 epoch 10 - iter 5/15 - loss 0.46559100 - samples/sec: 30.69\n",
      "2019-11-24 10:13:49,486 epoch 10 - iter 6/15 - loss 0.46287455 - samples/sec: 31.85\n",
      "2019-11-24 10:13:50,748 epoch 10 - iter 7/15 - loss 0.45717229 - samples/sec: 25.84\n",
      "2019-11-24 10:13:51,985 epoch 10 - iter 8/15 - loss 0.45167226 - samples/sec: 26.09\n",
      "2019-11-24 10:13:53,153 epoch 10 - iter 9/15 - loss 0.45184928 - samples/sec: 27.68\n",
      "2019-11-24 10:13:54,281 epoch 10 - iter 10/15 - loss 0.44410294 - samples/sec: 28.66\n",
      "2019-11-24 10:13:55,392 epoch 10 - iter 11/15 - loss 0.43694748 - samples/sec: 29.23\n",
      "2019-11-24 10:13:56,567 epoch 10 - iter 12/15 - loss 0.43002059 - samples/sec: 27.68\n",
      "2019-11-24 10:13:57,736 epoch 10 - iter 13/15 - loss 0.42292651 - samples/sec: 27.74\n",
      "2019-11-24 10:13:58,619 epoch 10 - iter 14/15 - loss 0.45111577 - samples/sec: 37.03\n",
      "2019-11-24 10:13:58,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:13:58,860 EPOCH 10 done: loss 0.4511 - lr 0.0500\n",
      "2019-11-24 10:14:01,339 DEV : loss 0.8154675960540771 - score 0.6102\n",
      "2019-11-24 10:14:01,390 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 10:14:04,693 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:14:04,694 Testing using best model ...\n",
      "2019-11-24 10:14:04,694 loading file test/text1/best-model.pt\n",
      "2019-11-24 10:14:07,890 0.6034\t0.6034\t0.6034\n",
      "2019-11-24 10:14:07,891 \n",
      "MICRO_AVG: acc 0.4321 - f1-score 0.6034\n",
      "MACRO_AVG: acc 0.4214 - f1-score 0.58865\n",
      "fake       tp: 23 - fp: 20 - fn: 3 - tn: 12 - precision: 0.5349 - recall: 0.8846 - accuracy: 0.5000 - f1-score: 0.6667\n",
      "real       tp: 12 - fp: 3 - fn: 20 - tn: 23 - precision: 0.8000 - recall: 0.3750 - accuracy: 0.3429 - f1-score: 0.5106\n",
      "2019-11-24 10:14:07,892 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:14:07,893 loading file ./test/text1/best-model.pt\n",
      "acc:  0.66\n",
      "precision:  0.616822429906542\n",
      "recall:  0.868421052631579\n",
      "f1:  0.721311475409836\n"
     ]
    }
   ],
   "source": [
    "path = './test/text10'\n",
    "make_test(train_text, test_text, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "643\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "train_url = [(x['url'][:100], label) for x, label in train_content] \n",
    "test_url = [(x['url'][:100], label) for x, label in test_content]\n",
    "print(len([x for x, label in train_url if x == '']))\n",
    "print(len([x for x, label in test_url if x == '']))\n",
    "train_url = [(x, label) for x, label in train_url if x != ''] \n",
    "test_url = [(x, label) for x, label in test_url if x != '']\n",
    "print(len(train_url))\n",
    "print(len(test_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:34:08,310 Reading data from test/url1\n",
      "2019-11-24 10:34:08,311 Train: test/url1/train.csv\n",
      "2019-11-24 10:34:08,312 Dev: test/url1/dev.csv\n",
      "2019-11-24 10:34:08,314 Test: test/url1/test.csv\n",
      "2019-11-24 10:34:08,318 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [00:00<00:00, 1674.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:34:09,158 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:34:10,727 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:10,728 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 10:34:10,728 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:10,729 Corpus: \"Corpus: 514 train + 65 dev + 64 test sentences\"\n",
      "2019-11-24 10:34:10,729 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:10,730 Parameters:\n",
      "2019-11-24 10:34:10,730  - learning_rate: \"0.1\"\n",
      "2019-11-24 10:34:10,731  - mini_batch_size: \"32\"\n",
      "2019-11-24 10:34:10,731  - patience: \"3\"\n",
      "2019-11-24 10:34:10,732  - anneal_factor: \"0.5\"\n",
      "2019-11-24 10:34:10,733  - max_epochs: \"1\"\n",
      "2019-11-24 10:34:10,734  - shuffle: \"True\"\n",
      "2019-11-24 10:34:10,734  - train_with_dev: \"False\"\n",
      "2019-11-24 10:34:10,736  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 10:34:10,736 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:10,756 Model training base path: \"test/url1\"\n",
      "2019-11-24 10:34:10,757 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:10,758 Device: cpu\n",
      "2019-11-24 10:34:10,759 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:10,760 Embeddings storage mode: cpu\n",
      "2019-11-24 10:34:10,761 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:12,475 epoch 1 - iter 0/17 - loss 0.68572932 - samples/sec: 25.70\n",
      "2019-11-24 10:34:13,990 epoch 1 - iter 1/17 - loss 0.68939057 - samples/sec: 21.35\n",
      "2019-11-24 10:34:15,779 epoch 1 - iter 2/17 - loss 0.68463101 - samples/sec: 18.18\n",
      "2019-11-24 10:34:16,907 epoch 1 - iter 3/17 - loss 0.68325949 - samples/sec: 28.67\n",
      "2019-11-24 10:34:18,172 epoch 1 - iter 4/17 - loss 0.68261572 - samples/sec: 25.88\n",
      "2019-11-24 10:34:19,430 epoch 1 - iter 5/17 - loss 0.68081811 - samples/sec: 25.91\n",
      "2019-11-24 10:34:20,489 epoch 1 - iter 6/17 - loss 0.66997447 - samples/sec: 30.94\n",
      "2019-11-24 10:34:21,667 epoch 1 - iter 7/17 - loss 0.66401254 - samples/sec: 27.44\n",
      "2019-11-24 10:34:22,743 epoch 1 - iter 8/17 - loss 0.66549684 - samples/sec: 30.44\n",
      "2019-11-24 10:34:23,798 epoch 1 - iter 9/17 - loss 0.65926320 - samples/sec: 30.70\n",
      "2019-11-24 10:34:24,834 epoch 1 - iter 10/17 - loss 0.65694951 - samples/sec: 31.62\n",
      "2019-11-24 10:34:25,883 epoch 1 - iter 11/17 - loss 0.65502885 - samples/sec: 31.22\n",
      "2019-11-24 10:34:26,978 epoch 1 - iter 12/17 - loss 0.64833279 - samples/sec: 29.91\n",
      "2019-11-24 10:34:28,112 epoch 1 - iter 13/17 - loss 0.63617640 - samples/sec: 29.08\n",
      "2019-11-24 10:34:29,144 epoch 1 - iter 14/17 - loss 0.63430954 - samples/sec: 31.50\n",
      "2019-11-24 10:34:30,171 epoch 1 - iter 15/17 - loss 0.63071469 - samples/sec: 31.57\n",
      "2019-11-24 10:34:30,740 epoch 1 - iter 16/17 - loss 0.62193037 - samples/sec: 57.30\n",
      "2019-11-24 10:34:30,947 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:30,948 EPOCH 1 done: loss 0.6219 - lr 0.1000\n",
      "2019-11-24 10:34:33,920 DEV : loss 0.4742874205112457 - score 0.6462\n",
      "2019-11-24 10:34:33,966 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:34:39,586 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:39,587 Testing using best model ...\n",
      "2019-11-24 10:34:39,587 loading file test/url1/best-model.pt\n",
      "2019-11-24 10:34:42,661 0.8281\t0.8281\t0.8281\n",
      "2019-11-24 10:34:42,662 \n",
      "MICRO_AVG: acc 0.7067 - f1-score 0.8281\n",
      "MACRO_AVG: acc 0.7053 - f1-score 0.8271\n",
      "fake       tp: 24 - fp: 2 - fn: 9 - tn: 29 - precision: 0.9231 - recall: 0.7273 - accuracy: 0.6857 - f1-score: 0.8136\n",
      "real       tp: 29 - fp: 9 - fn: 2 - tn: 24 - precision: 0.7632 - recall: 0.9355 - accuracy: 0.7250 - f1-score: 0.8406\n",
      "2019-11-24 10:34:42,663 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:34:42,664 loading file ./test/url1/best-model.pt\n",
      "acc:  0.5370370370370371\n",
      "precision:  0.8888888888888888\n",
      "recall:  0.0975609756097561\n",
      "f1:  0.17582417582417584\n"
     ]
    }
   ],
   "source": [
    "path = './test/url1'\n",
    "make_test(train_url, test_url, path, path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:35:24,737 Reading data from test/url10\n",
      "2019-11-24 10:35:24,738 Train: test/url10/train.csv\n",
      "2019-11-24 10:35:24,739 Dev: test/url10/dev.csv\n",
      "2019-11-24 10:35:24,739 Test: test/url10/test.csv\n",
      "2019-11-24 10:35:24,742 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [00:00<00:00, 1084.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:35:25,770 [b'real', b'fake']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:35:26,576 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:26,577 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "      (list_embedding_1): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (list_embedding_2): FlairEmbeddings(\n",
      "        (lm): LanguageModel(\n",
      "          (drop): Dropout(p=0.25, inplace=False)\n",
      "          (encoder): Embedding(275, 100)\n",
      "          (rnn): LSTM(100, 1024)\n",
      "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-11-24 10:35:26,577 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:26,578 Corpus: \"Corpus: 514 train + 65 dev + 64 test sentences\"\n",
      "2019-11-24 10:35:26,579 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:26,579 Parameters:\n",
      "2019-11-24 10:35:26,580  - learning_rate: \"0.1\"\n",
      "2019-11-24 10:35:26,581  - mini_batch_size: \"32\"\n",
      "2019-11-24 10:35:26,581  - patience: \"3\"\n",
      "2019-11-24 10:35:26,582  - anneal_factor: \"0.5\"\n",
      "2019-11-24 10:35:26,582  - max_epochs: \"10\"\n",
      "2019-11-24 10:35:26,583  - shuffle: \"True\"\n",
      "2019-11-24 10:35:26,583  - train_with_dev: \"False\"\n",
      "2019-11-24 10:35:26,584  - batch_growth_annealing: \"False\"\n",
      "2019-11-24 10:35:26,584 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:26,586 Model training base path: \"test/url10\"\n",
      "2019-11-24 10:35:26,586 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:26,587 Device: cpu\n",
      "2019-11-24 10:35:26,587 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:26,595 Embeddings storage mode: cpu\n",
      "2019-11-24 10:35:26,597 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:28,925 epoch 1 - iter 0/17 - loss 0.68454778 - samples/sec: 18.44\n",
      "2019-11-24 10:35:30,277 epoch 1 - iter 1/17 - loss 0.81806818 - samples/sec: 24.00\n",
      "2019-11-24 10:35:31,510 epoch 1 - iter 2/17 - loss 0.76267334 - samples/sec: 26.27\n",
      "2019-11-24 10:35:32,664 epoch 1 - iter 3/17 - loss 0.76592781 - samples/sec: 28.14\n",
      "2019-11-24 10:35:33,771 epoch 1 - iter 4/17 - loss 0.75784886 - samples/sec: 29.39\n",
      "2019-11-24 10:35:34,949 epoch 1 - iter 5/17 - loss 0.74445357 - samples/sec: 27.44\n",
      "2019-11-24 10:35:36,013 epoch 1 - iter 6/17 - loss 0.72826780 - samples/sec: 30.77\n",
      "2019-11-24 10:35:37,086 epoch 1 - iter 7/17 - loss 0.72107331 - samples/sec: 30.16\n",
      "2019-11-24 10:35:38,249 epoch 1 - iter 8/17 - loss 0.71126275 - samples/sec: 27.80\n",
      "2019-11-24 10:35:39,433 epoch 1 - iter 9/17 - loss 0.70106918 - samples/sec: 27.41\n",
      "2019-11-24 10:35:40,603 epoch 1 - iter 10/17 - loss 0.70055105 - samples/sec: 27.66\n",
      "2019-11-24 10:35:41,824 epoch 1 - iter 11/17 - loss 0.69066883 - samples/sec: 26.44\n",
      "2019-11-24 10:35:42,941 epoch 1 - iter 12/17 - loss 0.68461102 - samples/sec: 29.65\n",
      "2019-11-24 10:35:44,098 epoch 1 - iter 13/17 - loss 0.67989557 - samples/sec: 27.94\n",
      "2019-11-24 10:35:45,328 epoch 1 - iter 14/17 - loss 0.67221146 - samples/sec: 26.41\n",
      "2019-11-24 10:35:46,592 epoch 1 - iter 15/17 - loss 0.66397507 - samples/sec: 25.58\n",
      "2019-11-24 10:35:47,193 epoch 1 - iter 16/17 - loss 0.65377687 - samples/sec: 54.27\n",
      "2019-11-24 10:35:47,412 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:35:47,413 EPOCH 1 done: loss 0.6538 - lr 0.1000\n",
      "2019-11-24 10:35:50,329 DEV : loss 0.6223008036613464 - score 0.6769\n",
      "2019-11-24 10:35:50,368 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:35:53,191 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kotwic4/miniconda3/envs/fake_news/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:35:55,437 epoch 2 - iter 0/17 - loss 0.63785821 - samples/sec: 17.72\n",
      "2019-11-24 10:35:56,686 epoch 2 - iter 1/17 - loss 0.56365119 - samples/sec: 26.14\n",
      "2019-11-24 10:35:57,774 epoch 2 - iter 2/17 - loss 0.58134416 - samples/sec: 29.83\n",
      "2019-11-24 10:35:58,870 epoch 2 - iter 3/17 - loss 0.57210638 - samples/sec: 29.53\n",
      "2019-11-24 10:36:00,055 epoch 2 - iter 4/17 - loss 0.57372680 - samples/sec: 27.38\n",
      "2019-11-24 10:36:01,107 epoch 2 - iter 5/17 - loss 0.58562698 - samples/sec: 30.88\n",
      "2019-11-24 10:36:02,244 epoch 2 - iter 6/17 - loss 0.59531125 - samples/sec: 28.68\n",
      "2019-11-24 10:36:03,376 epoch 2 - iter 7/17 - loss 0.57621308 - samples/sec: 28.71\n",
      "2019-11-24 10:36:04,422 epoch 2 - iter 8/17 - loss 0.56678752 - samples/sec: 30.94\n",
      "2019-11-24 10:36:05,541 epoch 2 - iter 9/17 - loss 0.56836219 - samples/sec: 28.91\n",
      "2019-11-24 10:36:06,658 epoch 2 - iter 10/17 - loss 0.57183625 - samples/sec: 29.01\n",
      "2019-11-24 10:36:07,982 epoch 2 - iter 11/17 - loss 0.58069562 - samples/sec: 24.57\n",
      "2019-11-24 10:36:10,419 epoch 2 - iter 12/17 - loss 0.57757975 - samples/sec: 26.19\n",
      "2019-11-24 10:36:11,649 epoch 2 - iter 13/17 - loss 0.56414561 - samples/sec: 26.40\n",
      "2019-11-24 10:36:12,918 epoch 2 - iter 14/17 - loss 0.56336101 - samples/sec: 25.58\n",
      "2019-11-24 10:36:14,243 epoch 2 - iter 15/17 - loss 0.56274989 - samples/sec: 24.36\n",
      "2019-11-24 10:36:14,891 epoch 2 - iter 16/17 - loss 0.55498552 - samples/sec: 50.37\n",
      "2019-11-24 10:36:15,119 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:36:15,120 EPOCH 2 done: loss 0.5550 - lr 0.1000\n",
      "2019-11-24 10:36:18,238 DEV : loss 1.8457447290420532 - score 0.4769\n",
      "2019-11-24 10:36:18,276 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 10:36:18,278 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:36:19,993 epoch 3 - iter 0/17 - loss 1.85726070 - samples/sec: 25.90\n",
      "2019-11-24 10:36:21,387 epoch 3 - iter 1/17 - loss 1.25223279 - samples/sec: 23.40\n",
      "2019-11-24 10:36:22,717 epoch 3 - iter 2/17 - loss 1.01279247 - samples/sec: 24.36\n",
      "2019-11-24 10:36:23,824 epoch 3 - iter 3/17 - loss 0.90157053 - samples/sec: 29.40\n",
      "2019-11-24 10:36:24,979 epoch 3 - iter 4/17 - loss 0.81237043 - samples/sec: 28.03\n",
      "2019-11-24 10:36:26,101 epoch 3 - iter 5/17 - loss 0.77019341 - samples/sec: 29.12\n",
      "2019-11-24 10:36:27,257 epoch 3 - iter 6/17 - loss 0.72929015 - samples/sec: 28.01\n",
      "2019-11-24 10:36:28,444 epoch 3 - iter 7/17 - loss 0.70361086 - samples/sec: 27.57\n",
      "2019-11-24 10:36:29,542 epoch 3 - iter 8/17 - loss 0.68714071 - samples/sec: 29.66\n",
      "2019-11-24 10:36:30,697 epoch 3 - iter 9/17 - loss 0.65226841 - samples/sec: 28.28\n",
      "2019-11-24 10:36:31,914 epoch 3 - iter 10/17 - loss 0.63401151 - samples/sec: 26.59\n",
      "2019-11-24 10:36:33,022 epoch 3 - iter 11/17 - loss 0.62359530 - samples/sec: 29.59\n",
      "2019-11-24 10:36:34,147 epoch 3 - iter 12/17 - loss 0.60750585 - samples/sec: 28.84\n",
      "2019-11-24 10:36:35,327 epoch 3 - iter 13/17 - loss 0.60539221 - samples/sec: 27.54\n",
      "2019-11-24 10:36:36,403 epoch 3 - iter 14/17 - loss 0.59328746 - samples/sec: 30.08\n",
      "2019-11-24 10:36:37,532 epoch 3 - iter 15/17 - loss 0.58666637 - samples/sec: 28.89\n",
      "2019-11-24 10:36:38,142 epoch 3 - iter 16/17 - loss 0.57826990 - samples/sec: 54.01\n",
      "2019-11-24 10:36:38,349 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:36:38,350 EPOCH 3 done: loss 0.5783 - lr 0.1000\n",
      "2019-11-24 10:36:41,438 DEV : loss 1.1462658643722534 - score 0.5846\n",
      "2019-11-24 10:36:41,479 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 10:36:41,480 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:36:43,065 epoch 4 - iter 0/17 - loss 1.02333200 - samples/sec: 27.87\n",
      "2019-11-24 10:36:44,253 epoch 4 - iter 1/17 - loss 0.70892198 - samples/sec: 27.27\n",
      "2019-11-24 10:36:45,447 epoch 4 - iter 2/17 - loss 0.63564060 - samples/sec: 27.83\n",
      "2019-11-24 10:36:46,657 epoch 4 - iter 3/17 - loss 0.62025374 - samples/sec: 26.73\n",
      "2019-11-24 10:36:47,774 epoch 4 - iter 4/17 - loss 0.59332961 - samples/sec: 28.98\n",
      "2019-11-24 10:36:49,000 epoch 4 - iter 5/17 - loss 0.57055583 - samples/sec: 26.37\n",
      "2019-11-24 10:36:50,202 epoch 4 - iter 6/17 - loss 0.56268824 - samples/sec: 27.13\n",
      "2019-11-24 10:36:51,383 epoch 4 - iter 7/17 - loss 0.54486913 - samples/sec: 27.40\n",
      "2019-11-24 10:36:52,592 epoch 4 - iter 8/17 - loss 0.55045095 - samples/sec: 27.13\n",
      "2019-11-24 10:36:53,686 epoch 4 - iter 9/17 - loss 0.53330077 - samples/sec: 29.67\n",
      "2019-11-24 10:36:54,820 epoch 4 - iter 10/17 - loss 0.52539200 - samples/sec: 28.56\n",
      "2019-11-24 10:36:55,921 epoch 4 - iter 11/17 - loss 0.51681375 - samples/sec: 29.39\n",
      "2019-11-24 10:36:57,017 epoch 4 - iter 12/17 - loss 0.51766664 - samples/sec: 29.78\n",
      "2019-11-24 10:36:58,130 epoch 4 - iter 13/17 - loss 0.52364313 - samples/sec: 29.14\n",
      "2019-11-24 10:36:59,240 epoch 4 - iter 14/17 - loss 0.51637802 - samples/sec: 29.40\n",
      "2019-11-24 10:37:00,335 epoch 4 - iter 15/17 - loss 0.52489106 - samples/sec: 29.57\n",
      "2019-11-24 10:37:00,908 epoch 4 - iter 16/17 - loss 0.55670406 - samples/sec: 57.04\n",
      "2019-11-24 10:37:01,097 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:37:01,098 EPOCH 4 done: loss 0.5567 - lr 0.1000\n",
      "2019-11-24 10:37:04,124 DEV : loss 0.42463788390159607 - score 0.6462\n",
      "2019-11-24 10:37:04,174 BAD EPOCHS (no improvement): 3\n",
      "2019-11-24 10:37:04,175 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:37:06,036 epoch 5 - iter 0/17 - loss 0.86279911 - samples/sec: 23.86\n",
      "2019-11-24 10:37:07,335 epoch 5 - iter 1/17 - loss 0.69064194 - samples/sec: 24.91\n",
      "2019-11-24 10:37:08,695 epoch 5 - iter 2/17 - loss 0.60354379 - samples/sec: 23.79\n",
      "2019-11-24 10:37:09,968 epoch 5 - iter 3/17 - loss 0.53600670 - samples/sec: 25.56\n",
      "2019-11-24 10:37:11,217 epoch 5 - iter 4/17 - loss 0.56027828 - samples/sec: 25.86\n",
      "2019-11-24 10:37:12,496 epoch 5 - iter 5/17 - loss 0.54015795 - samples/sec: 25.39\n",
      "2019-11-24 10:37:13,780 epoch 5 - iter 6/17 - loss 0.54441994 - samples/sec: 25.28\n",
      "2019-11-24 10:37:14,903 epoch 5 - iter 7/17 - loss 0.53115160 - samples/sec: 28.96\n",
      "2019-11-24 10:37:16,023 epoch 5 - iter 8/17 - loss 0.54887143 - samples/sec: 29.07\n",
      "2019-11-24 10:37:17,220 epoch 5 - iter 9/17 - loss 0.55229557 - samples/sec: 27.02\n",
      "2019-11-24 10:37:18,408 epoch 5 - iter 10/17 - loss 0.53634990 - samples/sec: 27.22\n",
      "2019-11-24 10:37:19,516 epoch 5 - iter 11/17 - loss 0.52913014 - samples/sec: 29.43\n",
      "2019-11-24 10:37:20,808 epoch 5 - iter 12/17 - loss 0.52240015 - samples/sec: 25.10\n",
      "2019-11-24 10:37:22,009 epoch 5 - iter 13/17 - loss 0.52338896 - samples/sec: 27.19\n",
      "2019-11-24 10:37:23,129 epoch 5 - iter 14/17 - loss 0.51982740 - samples/sec: 28.86\n",
      "2019-11-24 10:37:24,392 epoch 5 - iter 15/17 - loss 0.51544981 - samples/sec: 25.58\n",
      "2019-11-24 10:37:25,018 epoch 5 - iter 16/17 - loss 0.50686369 - samples/sec: 52.30\n",
      "2019-11-24 10:37:25,218 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:37:25,219 EPOCH 5 done: loss 0.5069 - lr 0.1000\n",
      "2019-11-24 10:37:28,395 DEV : loss 0.44019293785095215 - score 0.6\n",
      "Epoch     4: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-11-24 10:37:28,438 BAD EPOCHS (no improvement): 4\n",
      "2019-11-24 10:37:28,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:37:30,162 epoch 6 - iter 0/17 - loss 0.63870239 - samples/sec: 24.87\n",
      "2019-11-24 10:37:31,408 epoch 6 - iter 1/17 - loss 0.48716442 - samples/sec: 26.12\n",
      "2019-11-24 10:37:32,690 epoch 6 - iter 2/17 - loss 0.46440223 - samples/sec: 25.29\n",
      "2019-11-24 10:37:33,818 epoch 6 - iter 3/17 - loss 0.45887215 - samples/sec: 28.79\n",
      "2019-11-24 10:37:35,223 epoch 6 - iter 4/17 - loss 0.43591260 - samples/sec: 23.18\n",
      "2019-11-24 10:37:36,559 epoch 6 - iter 5/17 - loss 0.43449450 - samples/sec: 24.27\n",
      "2019-11-24 10:37:37,948 epoch 6 - iter 6/17 - loss 0.43778898 - samples/sec: 23.31\n",
      "2019-11-24 10:37:39,338 epoch 6 - iter 7/17 - loss 0.43749847 - samples/sec: 23.44\n",
      "2019-11-24 10:37:40,646 epoch 6 - iter 8/17 - loss 0.44178701 - samples/sec: 24.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:37:41,817 epoch 6 - iter 9/17 - loss 0.44683191 - samples/sec: 27.68\n",
      "2019-11-24 10:37:42,901 epoch 6 - iter 10/17 - loss 0.46142967 - samples/sec: 30.06\n",
      "2019-11-24 10:37:43,958 epoch 6 - iter 11/17 - loss 0.45018169 - samples/sec: 30.74\n",
      "2019-11-24 10:37:45,063 epoch 6 - iter 12/17 - loss 0.45047573 - samples/sec: 29.43\n",
      "2019-11-24 10:37:46,232 epoch 6 - iter 13/17 - loss 0.45270126 - samples/sec: 27.73\n",
      "2019-11-24 10:37:47,536 epoch 6 - iter 14/17 - loss 0.45893447 - samples/sec: 24.83\n",
      "2019-11-24 10:37:48,848 epoch 6 - iter 15/17 - loss 0.45978569 - samples/sec: 24.74\n",
      "2019-11-24 10:37:49,459 epoch 6 - iter 16/17 - loss 0.45627174 - samples/sec: 53.59\n",
      "2019-11-24 10:37:49,686 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:37:49,687 EPOCH 6 done: loss 0.4563 - lr 0.0500\n",
      "2019-11-24 10:37:53,074 DEV : loss 0.5907722115516663 - score 0.6769\n",
      "2019-11-24 10:37:53,117 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 10:37:56,423 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:37:58,482 epoch 7 - iter 0/17 - loss 0.66862315 - samples/sec: 20.81\n",
      "2019-11-24 10:37:59,861 epoch 7 - iter 1/17 - loss 0.58952683 - samples/sec: 23.47\n",
      "2019-11-24 10:38:01,221 epoch 7 - iter 2/17 - loss 0.56292276 - samples/sec: 23.93\n",
      "2019-11-24 10:38:02,624 epoch 7 - iter 3/17 - loss 0.51687323 - samples/sec: 23.09\n",
      "2019-11-24 10:38:03,957 epoch 7 - iter 4/17 - loss 0.52263749 - samples/sec: 24.40\n",
      "2019-11-24 10:38:05,231 epoch 7 - iter 5/17 - loss 0.51658067 - samples/sec: 25.46\n",
      "2019-11-24 10:38:06,458 epoch 7 - iter 6/17 - loss 0.50809417 - samples/sec: 26.44\n",
      "2019-11-24 10:38:07,560 epoch 7 - iter 7/17 - loss 0.49137322 - samples/sec: 29.48\n",
      "2019-11-24 10:38:08,773 epoch 7 - iter 8/17 - loss 0.47763304 - samples/sec: 26.88\n",
      "2019-11-24 10:38:10,256 epoch 7 - iter 9/17 - loss 0.45493816 - samples/sec: 21.83\n",
      "2019-11-24 10:38:11,829 epoch 7 - iter 10/17 - loss 0.45038491 - samples/sec: 20.74\n",
      "2019-11-24 10:38:13,406 epoch 7 - iter 11/17 - loss 0.44358666 - samples/sec: 20.50\n",
      "2019-11-24 10:38:15,285 epoch 7 - iter 12/17 - loss 0.44029698 - samples/sec: 17.27\n",
      "2019-11-24 10:38:16,612 epoch 7 - iter 13/17 - loss 0.44477243 - samples/sec: 24.45\n",
      "2019-11-24 10:38:18,264 epoch 7 - iter 14/17 - loss 0.44742278 - samples/sec: 19.67\n",
      "2019-11-24 10:38:19,734 epoch 7 - iter 15/17 - loss 0.45368826 - samples/sec: 22.00\n",
      "2019-11-24 10:38:20,338 epoch 7 - iter 16/17 - loss 0.45639831 - samples/sec: 54.28\n",
      "2019-11-24 10:38:20,527 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:38:20,528 EPOCH 7 done: loss 0.4564 - lr 0.0500\n",
      "2019-11-24 10:38:23,543 DEV : loss 0.3689039647579193 - score 0.7538\n",
      "2019-11-24 10:38:23,584 BAD EPOCHS (no improvement): 0\n",
      "2019-11-24 10:38:26,794 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:38:28,425 epoch 8 - iter 0/17 - loss 0.48450068 - samples/sec: 26.70\n",
      "2019-11-24 10:38:29,545 epoch 8 - iter 1/17 - loss 0.46223097 - samples/sec: 29.34\n",
      "2019-11-24 10:38:30,627 epoch 8 - iter 2/17 - loss 0.46351754 - samples/sec: 29.98\n",
      "2019-11-24 10:38:31,828 epoch 8 - iter 3/17 - loss 0.41921546 - samples/sec: 27.13\n",
      "2019-11-24 10:38:32,885 epoch 8 - iter 4/17 - loss 0.39254623 - samples/sec: 30.70\n",
      "2019-11-24 10:38:34,023 epoch 8 - iter 5/17 - loss 0.41249761 - samples/sec: 28.44\n",
      "2019-11-24 10:38:35,101 epoch 8 - iter 6/17 - loss 0.41805858 - samples/sec: 30.17\n",
      "2019-11-24 10:38:36,270 epoch 8 - iter 7/17 - loss 0.42101755 - samples/sec: 27.90\n",
      "2019-11-24 10:38:37,388 epoch 8 - iter 8/17 - loss 0.43106069 - samples/sec: 28.98\n",
      "2019-11-24 10:38:38,512 epoch 8 - iter 9/17 - loss 0.43318206 - samples/sec: 28.89\n",
      "2019-11-24 10:38:39,656 epoch 8 - iter 10/17 - loss 0.42215661 - samples/sec: 28.31\n",
      "2019-11-24 10:38:40,767 epoch 8 - iter 11/17 - loss 0.41492924 - samples/sec: 29.09\n",
      "2019-11-24 10:38:41,880 epoch 8 - iter 12/17 - loss 0.41583717 - samples/sec: 29.19\n",
      "2019-11-24 10:38:43,071 epoch 8 - iter 13/17 - loss 0.42091278 - samples/sec: 27.43\n",
      "2019-11-24 10:38:44,197 epoch 8 - iter 14/17 - loss 0.41761648 - samples/sec: 28.76\n",
      "2019-11-24 10:38:45,353 epoch 8 - iter 15/17 - loss 0.42006820 - samples/sec: 27.99\n",
      "2019-11-24 10:38:45,838 epoch 8 - iter 16/17 - loss 0.45322649 - samples/sec: 67.84\n",
      "2019-11-24 10:38:46,051 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:38:46,052 EPOCH 8 done: loss 0.4532 - lr 0.0500\n",
      "2019-11-24 10:38:48,983 DEV : loss 0.4451386630535126 - score 0.6615\n",
      "2019-11-24 10:38:49,021 BAD EPOCHS (no improvement): 1\n",
      "2019-11-24 10:38:49,022 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:38:50,635 epoch 9 - iter 0/17 - loss 0.68260080 - samples/sec: 28.04\n",
      "2019-11-24 10:38:51,744 epoch 9 - iter 1/17 - loss 0.56542028 - samples/sec: 29.28\n",
      "2019-11-24 10:38:52,861 epoch 9 - iter 2/17 - loss 0.52005692 - samples/sec: 29.05\n",
      "2019-11-24 10:38:54,033 epoch 9 - iter 3/17 - loss 0.55679947 - samples/sec: 27.71\n",
      "2019-11-24 10:38:55,154 epoch 9 - iter 4/17 - loss 0.50756139 - samples/sec: 28.99\n",
      "2019-11-24 10:38:56,310 epoch 9 - iter 5/17 - loss 0.48427777 - samples/sec: 27.96\n",
      "2019-11-24 10:38:57,384 epoch 9 - iter 6/17 - loss 0.48195314 - samples/sec: 30.58\n",
      "2019-11-24 10:38:58,489 epoch 9 - iter 7/17 - loss 0.47704448 - samples/sec: 29.31\n",
      "2019-11-24 10:38:59,573 epoch 9 - iter 8/17 - loss 0.46574131 - samples/sec: 29.85\n",
      "2019-11-24 10:39:00,831 epoch 9 - iter 9/17 - loss 0.45816482 - samples/sec: 25.81\n",
      "2019-11-24 10:39:02,563 epoch 9 - iter 10/17 - loss 0.46097900 - samples/sec: 18.70\n",
      "2019-11-24 10:39:03,933 epoch 9 - iter 11/17 - loss 0.45666647 - samples/sec: 23.61\n",
      "2019-11-24 10:39:05,313 epoch 9 - iter 12/17 - loss 0.45849290 - samples/sec: 23.91\n",
      "2019-11-24 10:39:06,627 epoch 9 - iter 13/17 - loss 0.44542605 - samples/sec: 24.58\n",
      "2019-11-24 10:39:08,158 epoch 9 - iter 14/17 - loss 0.43694875 - samples/sec: 21.11\n",
      "2019-11-24 10:39:09,410 epoch 9 - iter 15/17 - loss 0.44424393 - samples/sec: 25.80\n",
      "2019-11-24 10:39:10,075 epoch 9 - iter 16/17 - loss 0.43199198 - samples/sec: 49.46\n",
      "2019-11-24 10:39:10,283 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:39:10,284 EPOCH 9 done: loss 0.4320 - lr 0.0500\n",
      "2019-11-24 10:39:13,502 DEV : loss 0.4206376075744629 - score 0.7385\n",
      "2019-11-24 10:39:13,544 BAD EPOCHS (no improvement): 2\n",
      "2019-11-24 10:39:13,546 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:39:15,379 epoch 10 - iter 0/17 - loss 0.46101698 - samples/sec: 25.80\n",
      "2019-11-24 10:39:16,644 epoch 10 - iter 1/17 - loss 0.39354689 - samples/sec: 25.65\n",
      "2019-11-24 10:39:17,873 epoch 10 - iter 2/17 - loss 0.39554603 - samples/sec: 26.45\n",
      "2019-11-24 10:39:19,038 epoch 10 - iter 3/17 - loss 0.43328124 - samples/sec: 27.96\n",
      "2019-11-24 10:39:20,308 epoch 10 - iter 4/17 - loss 0.43435002 - samples/sec: 25.45\n",
      "2019-11-24 10:39:21,778 epoch 10 - iter 5/17 - loss 0.41363843 - samples/sec: 22.31\n",
      "2019-11-24 10:39:23,125 epoch 10 - iter 6/17 - loss 0.39428107 - samples/sec: 23.99\n",
      "2019-11-24 10:39:24,368 epoch 10 - iter 7/17 - loss 0.40996728 - samples/sec: 25.98\n",
      "2019-11-24 10:39:25,656 epoch 10 - iter 8/17 - loss 0.41799366 - samples/sec: 25.10\n",
      "2019-11-24 10:39:26,816 epoch 10 - iter 9/17 - loss 0.42324333 - samples/sec: 28.20\n",
      "2019-11-24 10:39:28,083 epoch 10 - iter 10/17 - loss 0.41165576 - samples/sec: 25.54\n",
      "2019-11-24 10:39:29,396 epoch 10 - iter 11/17 - loss 0.42167673 - samples/sec: 24.68\n",
      "2019-11-24 10:39:30,584 epoch 10 - iter 12/17 - loss 0.41694309 - samples/sec: 27.30\n",
      "2019-11-24 10:39:31,818 epoch 10 - iter 13/17 - loss 0.40908114 - samples/sec: 26.22\n",
      "2019-11-24 10:39:32,965 epoch 10 - iter 14/17 - loss 0.40650026 - samples/sec: 28.15\n",
      "2019-11-24 10:39:34,258 epoch 10 - iter 15/17 - loss 0.40857554 - samples/sec: 25.18\n",
      "2019-11-24 10:39:34,765 epoch 10 - iter 16/17 - loss 0.40177067 - samples/sec: 65.00\n",
      "2019-11-24 10:39:34,978 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-24 10:39:34,979 EPOCH 10 done: loss 0.4018 - lr 0.0500\n",
      "2019-11-24 10:39:38,084 DEV : loss 0.4357866942882538 - score 0.6769\n",
      "2019-11-24 10:39:38,124 BAD EPOCHS (no improvement): 3\n",
      "2019-11-24 10:39:40,826 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:39:40,827 Testing using best model ...\n",
      "2019-11-24 10:39:40,828 loading file test/url10/best-model.pt\n",
      "2019-11-24 10:39:44,329 0.875\t0.875\t0.875\n",
      "2019-11-24 10:39:44,330 \n",
      "MICRO_AVG: acc 0.7778 - f1-score 0.875\n",
      "MACRO_AVG: acc 0.7778 - f1-score 0.875\n",
      "fake       tp: 28 - fp: 3 - fn: 5 - tn: 28 - precision: 0.9032 - recall: 0.8485 - accuracy: 0.7778 - f1-score: 0.8750\n",
      "real       tp: 28 - fp: 5 - fn: 3 - tn: 28 - precision: 0.8485 - recall: 0.9032 - accuracy: 0.7778 - f1-score: 0.8750\n",
      "2019-11-24 10:39:44,331 ----------------------------------------------------------------------------------------------------\n",
      "2019-11-24 10:39:44,333 loading file ./test/url10/best-model.pt\n",
      "acc:  0.7098765432098766\n",
      "precision:  0.8571428571428571\n",
      "recall:  0.5121951219512195\n",
      "f1:  0.6412213740458015\n"
     ]
    }
   ],
   "source": [
    "path = './test/url10'\n",
    "make_test(train_url, test_url, path, path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
