{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eksploracja danych",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kotwic4/fake-news-detector/blob/colab/colab/flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB2TeXhKiKEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install vaderSentiment==3.2.1 requests numpy matplotlib pandas flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIUl6fL7HcG4",
        "colab_type": "code",
        "outputId": "f7559e9c-9c8f-4a3e-82f7-d07340e24848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec  4 11:37:43 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "39c4afb4-db74-4dd0-ffa4-c305ba6af347",
        "id": "6O8DVIdyJfyc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "!wget - O politifact_fake.csv https://raw.githubusercontent.com/KaiDMML/FakeNewsNet/master/dataset/politifact_fake.csv\n",
        "!wget - O politifact_real.csv https://raw.githubusercontent.com/KaiDMML/FakeNewsNet/master/dataset/politifact_real.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-04 11:37:47--  http://-/\n",
            "Resolving - (-)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘-’\n",
            "--2019-12-04 11:37:47--  http://o/\n",
            "Resolving o (o)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘o’\n",
            "--2019-12-04 11:37:47--  http://politifact_fake.csv/\n",
            "Resolving politifact_fake.csv (politifact_fake.csv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘politifact_fake.csv’\n",
            "--2019-12-04 11:37:47--  https://raw.githubusercontent.com/KaiDMML/FakeNewsNet/master/dataset/politifact_fake.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3286418 (3.1M) [text/plain]\n",
            "Saving to: ‘politifact_fake.csv.1’\n",
            "\n",
            "\rpolitifact_fake.csv   0%[                    ]       0  --.-KB/s               \rpolitifact_fake.csv 100%[===================>]   3.13M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-12-04 11:37:47 (59.3 MB/s) - ‘politifact_fake.csv.1’ saved [3286418/3286418]\n",
            "\n",
            "FINISHED --2019-12-04 11:37:47--\n",
            "Total wall clock time: 0.1s\n",
            "Downloaded: 1 files, 3.1M in 0.05s (59.3 MB/s)\n",
            "--2019-12-04 11:37:50--  http://-/\n",
            "Resolving - (-)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘-’\n",
            "--2019-12-04 11:37:50--  http://o/\n",
            "Resolving o (o)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘o’\n",
            "--2019-12-04 11:37:50--  http://politifact_real.csv/\n",
            "Resolving politifact_real.csv (politifact_real.csv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘politifact_real.csv’\n",
            "--2019-12-04 11:37:50--  https://raw.githubusercontent.com/KaiDMML/FakeNewsNet/master/dataset/politifact_real.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8278658 (7.9M) [text/plain]\n",
            "Saving to: ‘politifact_real.csv.1’\n",
            "\n",
            "politifact_real.csv 100%[===================>]   7.89M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-12-04 11:37:50 (113 MB/s) - ‘politifact_real.csv.1’ saved [8278658/8278658]\n",
            "\n",
            "FINISHED --2019-12-04 11:37:50--\n",
            "Total wall clock time: 0.1s\n",
            "Downloaded: 1 files, 7.9M in 0.07s (113 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_0nQXIyJbQf",
        "colab_type": "code",
        "outputId": "5fc6f3d6-bdd1-4fc5-8dd1-32cdb92d9019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 22604\n",
            "-rw-r--r-- 1 root root 3286418 Dec  4 11:35 politifact_fake.csv\n",
            "-rw-r--r-- 1 root root 3286418 Dec  4 11:37 politifact_fake.csv.1\n",
            "-rw-r--r-- 1 root root 8278658 Dec  4 11:35 politifact_real.csv\n",
            "-rw-r--r-- 1 root root 8278658 Dec  4 11:37 politifact_real.csv.1\n",
            "drwxr-xr-x 1 root root    4096 Nov 21 16:30 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLvpKFNmJyUn",
        "colab_type": "code",
        "outputId": "eb5bb23b-642b-41d0-f748-df71d39074b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "import os\n",
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntSJWKqJKVGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = 'politifact'\n",
        "DATASET_PATH = './{}'.format(DATASET_NAME)\n",
        "REAL_DATA_PATH = '{}_real.csv'.format(DATASET_PATH)\n",
        "FAKE_DATA_PATH = '{}_fake.csv'.format(DATASET_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-WYXGglKpox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_arts = pd.read_csv(FAKE_DATA_PATH, na_values=['nan'], keep_default_na=False)\n",
        "real_arts = pd.read_csv(REAL_DATA_PATH, na_values=['nan'], keep_default_na=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgUChXnKt7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_art_data_frame(df):\n",
        "    return [{'id': id, 'url': url, 'title': title} for id, url, title, tweets in df.values]\n",
        "    \n",
        "fake_arts_with_content = parse_art_data_frame(fake_arts)\n",
        "real_arts_with_content = parse_art_data_frame(real_arts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XltXs2XdKv1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_data = [(art, 'fake') for art in fake_arts_with_content]\n",
        "real_data = [(art, 'real') for art in real_arts_with_content]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLQEORGsKxxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = fake_data + real_data\n",
        "X = [x for x,y in all_data]\n",
        "y = [y for x,y in all_data]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = list(zip(X_train, y_train))\n",
        "test_data = list(zip(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmpjjmBTKz6o",
        "colab_type": "code",
        "outputId": "ba65e956-9e6f-46c0-9399-5d8a8ae23712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print(len(train_data) + len(test_data))\n",
        "print(len(fake_data) + len(real_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "844\n",
            "212\n",
            "1056\n",
            "1056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08B3YnoripKw",
        "colab_type": "code",
        "outputId": "cef9cd70-6571-45c2-ba1e-db8c37303562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len([y for y in y_train if y == 'fake']))\n",
        "print(len([y for y in y_test if y == 'fake']))\n",
        "\n",
        "print(len([y for y in y_train if y == 'real']))\n",
        "print(len([y for y in y_test if y == 'real']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "334\n",
            "98\n",
            "510\n",
            "114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n74zwgCK1Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_text(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "class Classifier():\n",
        "    def __init__(self, classifier):\n",
        "        self.classifier = classifier\n",
        "        \n",
        "    def predict(self, text):\n",
        "        text = clear_text(text)\n",
        "        sentence = Sentence(text)\n",
        "        self.classifier.predict(sentence)\n",
        "        return sentence.labels[0]\n",
        "\n",
        "def transform_data(data):\n",
        "    return [{'label': label, 'text': clear_text(x)} for x, label in data]\n",
        "\n",
        "def save_data(data, data_folder = '.'):\n",
        "    if not os.path.exists(data_folder):\n",
        "        os.makedirs(data_folder)\n",
        "    data = transform_data(data)\n",
        "    frame_data = pd.DataFrame(data)\n",
        "    train_path = '{}/train.csv'.format(data_folder)\n",
        "    test_path = '{}/test.csv'.format(data_folder)\n",
        "    dev_path = '{}/dev.csv'.format(data_folder)\n",
        "    frame_data.iloc[0:int(len(data)*0.8)].to_csv(train_path, sep='\\t', index = False, header = False)\n",
        "    frame_data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv(test_path, sep='\\t', index = False, header = False)\n",
        "    frame_data.iloc[int(len(data)*0.9):].to_csv(dev_path, sep='\\t', index = False, header = False)\n",
        "\n",
        "def load_corpus(data_folder = '.'):\n",
        "    column_name_map = {1: \"text\", 0: \"label\"}\n",
        "    return CSVClassificationCorpus(data_folder,\n",
        "                                     column_name_map,\n",
        "                                     delimiter='\\t',\n",
        "                                  test_file='test.csv',\n",
        "                                  dev_file='dev.csv',\n",
        "                                  train_file='train.csv')\n",
        "    \n",
        "def train_classifier(corpus, model_folder = '.', max_epochs = 1):\n",
        "    label_dict = corpus.make_label_dictionary()\n",
        "\n",
        "    word_embeddings = [\n",
        "        WordEmbeddings('glove'),\n",
        "        FlairEmbeddings('news-forward-fast'),\n",
        "        FlairEmbeddings('news-backward-fast')\n",
        "    ]\n",
        "\n",
        "    document_embeddings = DocumentRNNEmbeddings(word_embeddings,\n",
        "                                                hidden_size=512,\n",
        "                                                reproject_words=True,\n",
        "                                                reproject_words_dimension=256)\n",
        "\n",
        "    classifier = TextClassifier(document_embeddings,\n",
        "                                label_dictionary=label_dict)\n",
        "\n",
        "    trainer = ModelTrainer(classifier, corpus)\n",
        "\n",
        "    trainer.train(model_folder, max_epochs=max_epochs)\n",
        "    \n",
        "    return TextClassifier.load('{}/best-model.pt'.format(model_folder))\n",
        "    \n",
        "def train_model(train_data,\n",
        "               data_folder = '.',\n",
        "               model_folder = '.',\n",
        "               max_epochs=1\n",
        "               ):\n",
        "    save_data(train_data, data_folder)\n",
        "    corpus = load_corpus(data_folder)\n",
        "    classifier = train_classifier(corpus, model_folder, max_epochs)\n",
        "    return Classifier(classifier)\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, pos_label = 'fake'):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, pos_label=pos_label)\n",
        "    recall = recall_score(y_true, y_pred, pos_label=pos_label)\n",
        "    f1 = f1_score(y_true, y_pred, pos_label=pos_label)\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "def validate_model(test_data, classifier):\n",
        "    y_true = [label for x, label in test_data]\n",
        "    y_pred = [classifier.predict(x).value for x, label in test_data]\n",
        "    acc, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
        "    print(\"acc: \", acc)\n",
        "    print(\"precision: \", precision)\n",
        "    print(\"recall: \", recall)\n",
        "    print(\"f1: \", f1)\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "def make_test(train_data, test_data, data_folder, model_folder, max_epochs):\n",
        "    classifier = train_model(train_data, data_folder, model_folder, max_epochs)\n",
        "    validate_model(test_data, classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMqZCSOSK4Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_content = [(x, label) for x, label in train_data] \n",
        "test_content = [(x, label) for x, label in test_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmYv9RdmK5ks",
        "colab_type": "code",
        "outputId": "ed0db1bc-9429-4585-ba24-96ae833e22cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_title = [(x['title'], label) for x, label in train_content]\n",
        "test_title = [(x['title'], label) for x, label in test_content]\n",
        "print(len([x for x, label in train_title if x == '']))\n",
        "print(len([x for x, label in test_title if x == '']))\n",
        "train_title = [(x, label) for x, label in train_title if x != ''] \n",
        "test_title = [(x, label) for x, label in test_title if x != '']\n",
        "print(len(train_title))\n",
        "print(len(test_title))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "844\n",
            "212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObpPGG7kK7et",
        "colab_type": "code",
        "outputId": "93f4c898-86ab-44ab-c8e5-030df1149b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/title1'\n",
        "make_test(train_title, test_title, path, path, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:00,013 Reading data from test_csv/title1\n",
            "2019-12-04 11:38:00,015 Train: test_csv/title1/train.csv\n",
            "2019-12-04 11:38:00,017 Dev: test_csv/title1/dev.csv\n",
            "2019-12-04 11:38:00,019 Test: test_csv/title1/test.csv\n",
            "2019-12-04 11:38:00,027 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 675/675 [00:00<00:00, 1640.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:00,558 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:00,653 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpgpbpsbj0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:03<00:00, 49344520.30B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:04,038 copying /tmp/tmpgpbpsbj0 to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:04,326 removing temp file /tmp/tmpgpbpsbj0\n",
            "2019-12-04 11:38:04,430 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpvyut7l3c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:00<00:00, 47109526.99B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:05,028 copying /tmp/tmpvyut7l3c to cache at /root/.flair/embeddings/glove.gensim\n",
            "2019-12-04 11:38:05,055 removing temp file /tmp/tmpvyut7l3c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:06,456 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpfqo6_aln\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 46999249.25B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:07,029 copying /tmp/tmpfqo6_aln to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2019-12-04 11:38:07,063 removing temp file /tmp/tmpfqo6_aln\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:13,681 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpxf3r4qy_\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 45338737.73B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:14,271 copying /tmp/tmpxf3r4qy_ to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2019-12-04 11:38:14,299 removing temp file /tmp/tmpxf3r4qy_\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:14,444 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:14,445 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:38:14,447 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:14,449 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
            "2019-12-04 11:38:14,451 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:14,453 Parameters:\n",
            "2019-12-04 11:38:14,455  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:38:14,457  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:38:14,459  - patience: \"3\"\n",
            "2019-12-04 11:38:14,461  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:38:14,462  - max_epochs: \"1\"\n",
            "2019-12-04 11:38:14,464  - shuffle: \"True\"\n",
            "2019-12-04 11:38:14,465  - train_with_dev: \"False\"\n",
            "2019-12-04 11:38:14,467  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:38:14,469 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:14,470 Model training base path: \"test_csv/title1\"\n",
            "2019-12-04 11:38:14,472 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:14,474 Device: cuda:0\n",
            "2019-12-04 11:38:14,475 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:14,477 Embeddings storage mode: cpu\n",
            "2019-12-04 11:38:14,480 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:15,173 epoch 1 - iter 0/22 - loss 0.72455007 - samples/sec: 177.74\n",
            "2019-12-04 11:38:15,472 epoch 1 - iter 2/22 - loss 0.68847803 - samples/sec: 255.96\n",
            "2019-12-04 11:38:15,776 epoch 1 - iter 4/22 - loss 0.66174694 - samples/sec: 229.08\n",
            "2019-12-04 11:38:16,044 epoch 1 - iter 6/22 - loss 0.64702404 - samples/sec: 266.97\n",
            "2019-12-04 11:38:16,382 epoch 1 - iter 8/22 - loss 0.63381735 - samples/sec: 214.52\n",
            "2019-12-04 11:38:16,689 epoch 1 - iter 10/22 - loss 0.62765988 - samples/sec: 228.93\n",
            "2019-12-04 11:38:16,951 epoch 1 - iter 12/22 - loss 0.61282729 - samples/sec: 269.69\n",
            "2019-12-04 11:38:17,193 epoch 1 - iter 14/22 - loss 0.61283611 - samples/sec: 302.96\n",
            "2019-12-04 11:38:17,520 epoch 1 - iter 16/22 - loss 0.62314908 - samples/sec: 212.99\n",
            "2019-12-04 11:38:17,808 epoch 1 - iter 18/22 - loss 0.61528554 - samples/sec: 245.09\n",
            "2019-12-04 11:38:18,084 epoch 1 - iter 20/22 - loss 0.60345471 - samples/sec: 262.45\n",
            "2019-12-04 11:38:18,245 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:18,248 EPOCH 1 done: loss 0.6093 - lr 0.1000\n",
            "2019-12-04 11:38:18,980 DEV : loss 0.5916505455970764 - score 0.6353\n",
            "2019-12-04 11:38:19,034 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:25,581 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:25,582 Testing using best model ...\n",
            "2019-12-04 11:38:25,589 loading file test_csv/title1/best-model.pt\n",
            "2019-12-04 11:38:27,432 0.5952\t0.5952\t0.5952\n",
            "2019-12-04 11:38:27,434 \n",
            "MICRO_AVG: acc 0.4237 - f1-score 0.5952\n",
            "MACRO_AVG: acc 0.4223 - f1-score 0.5931500000000001\n",
            "fake       tp: 28 - fp: 31 - fn: 3 - tn: 22 - precision: 0.4746 - recall: 0.9032 - accuracy: 0.4516 - f1-score: 0.6222\n",
            "real       tp: 22 - fp: 3 - fn: 31 - tn: 28 - precision: 0.8800 - recall: 0.4151 - accuracy: 0.3929 - f1-score: 0.5641\n",
            "2019-12-04 11:38:27,441 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:27,445 loading file ./test_csv/title1/best-model.pt\n",
            "acc:  0.660377358490566\n",
            "precision:  0.5878378378378378\n",
            "recall:  0.8877551020408163\n",
            "f1:  0.7073170731707316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIUR9DbALCaq",
        "colab_type": "code",
        "outputId": "fbaf934f-274c-41a2-afb5-8db2d44b76e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/title10'\n",
        "make_test(train_title, test_title, path, path, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:30,946 Reading data from test_csv/title10\n",
            "2019-12-04 11:38:30,947 Train: test_csv/title10/train.csv\n",
            "2019-12-04 11:38:30,948 Dev: test_csv/title10/dev.csv\n",
            "2019-12-04 11:38:30,952 Test: test_csv/title10/test.csv\n",
            "2019-12-04 11:38:30,960 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 675/675 [00:00<00:00, 1150.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:31,883 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:33,250 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,252 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:38:33,253 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,256 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
            "2019-12-04 11:38:33,258 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,262 Parameters:\n",
            "2019-12-04 11:38:33,268  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:38:33,271  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:38:33,272  - patience: \"3\"\n",
            "2019-12-04 11:38:33,276  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:38:33,281  - max_epochs: \"10\"\n",
            "2019-12-04 11:38:33,285  - shuffle: \"True\"\n",
            "2019-12-04 11:38:33,290  - train_with_dev: \"False\"\n",
            "2019-12-04 11:38:33,314  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:38:33,319 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,324 Model training base path: \"test_csv/title10\"\n",
            "2019-12-04 11:38:33,325 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,327 Device: cuda:0\n",
            "2019-12-04 11:38:33,330 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,332 Embeddings storage mode: cpu\n",
            "2019-12-04 11:38:33,335 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:33,882 epoch 1 - iter 0/22 - loss 0.65659094 - samples/sec: 355.60\n",
            "2019-12-04 11:38:34,174 epoch 1 - iter 2/22 - loss 0.77568376 - samples/sec: 246.81\n",
            "2019-12-04 11:38:34,503 epoch 1 - iter 4/22 - loss 0.71688721 - samples/sec: 215.64\n",
            "2019-12-04 11:38:34,785 epoch 1 - iter 6/22 - loss 0.68805254 - samples/sec: 264.65\n",
            "2019-12-04 11:38:35,037 epoch 1 - iter 8/22 - loss 0.69010740 - samples/sec: 289.88\n",
            "2019-12-04 11:38:35,328 epoch 1 - iter 10/22 - loss 0.67959101 - samples/sec: 243.31\n",
            "2019-12-04 11:38:35,613 epoch 1 - iter 12/22 - loss 0.65903015 - samples/sec: 253.98\n",
            "2019-12-04 11:38:35,877 epoch 1 - iter 14/22 - loss 0.64364229 - samples/sec: 277.42\n",
            "2019-12-04 11:38:36,153 epoch 1 - iter 16/22 - loss 0.63384586 - samples/sec: 270.58\n",
            "2019-12-04 11:38:36,447 epoch 1 - iter 18/22 - loss 0.62210714 - samples/sec: 244.23\n",
            "2019-12-04 11:38:36,714 epoch 1 - iter 20/22 - loss 0.62145502 - samples/sec: 271.53\n",
            "2019-12-04 11:38:36,907 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:36,910 EPOCH 1 done: loss 0.6335 - lr 0.1000\n",
            "2019-12-04 11:38:37,715 DEV : loss 0.5828449130058289 - score 0.6353\n",
            "2019-12-04 11:38:37,758 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:38:41,165 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:41,750 epoch 2 - iter 0/22 - loss 0.55306464 - samples/sec: 503.58\n",
            "2019-12-04 11:38:42,012 epoch 2 - iter 2/22 - loss 0.46997536 - samples/sec: 277.88\n",
            "2019-12-04 11:38:42,246 epoch 2 - iter 4/22 - loss 0.49628988 - samples/sec: 302.44\n",
            "2019-12-04 11:38:42,487 epoch 2 - iter 6/22 - loss 0.48343866 - samples/sec: 296.25\n",
            "2019-12-04 11:38:42,837 epoch 2 - iter 8/22 - loss 0.50570683 - samples/sec: 213.95\n",
            "2019-12-04 11:38:43,093 epoch 2 - iter 10/22 - loss 0.48435369 - samples/sec: 284.20\n",
            "2019-12-04 11:38:43,352 epoch 2 - iter 12/22 - loss 0.47704445 - samples/sec: 270.01\n",
            "2019-12-04 11:38:43,597 epoch 2 - iter 14/22 - loss 0.48344585 - samples/sec: 305.14\n",
            "2019-12-04 11:38:43,919 epoch 2 - iter 16/22 - loss 0.48895950 - samples/sec: 216.85\n",
            "2019-12-04 11:38:44,210 epoch 2 - iter 18/22 - loss 0.48897575 - samples/sec: 241.49\n",
            "2019-12-04 11:38:44,509 epoch 2 - iter 20/22 - loss 0.48532994 - samples/sec: 237.68\n",
            "2019-12-04 11:38:44,742 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:44,743 EPOCH 2 done: loss 0.4703 - lr 0.1000\n",
            "2019-12-04 11:38:45,498 DEV : loss 0.5596989393234253 - score 0.6706\n",
            "2019-12-04 11:38:45,542 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:38:48,791 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:49,356 epoch 3 - iter 0/22 - loss 0.42337042 - samples/sec: 339.06\n",
            "2019-12-04 11:38:49,739 epoch 3 - iter 2/22 - loss 0.44583759 - samples/sec: 186.45\n",
            "2019-12-04 11:38:50,018 epoch 3 - iter 4/22 - loss 0.42100508 - samples/sec: 248.16\n",
            "2019-12-04 11:38:50,267 epoch 3 - iter 6/22 - loss 0.40454908 - samples/sec: 305.10\n",
            "2019-12-04 11:38:50,531 epoch 3 - iter 8/22 - loss 0.41663182 - samples/sec: 273.40\n",
            "2019-12-04 11:38:50,816 epoch 3 - iter 10/22 - loss 0.43158709 - samples/sec: 247.24\n",
            "2019-12-04 11:38:51,034 epoch 3 - iter 12/22 - loss 0.42907743 - samples/sec: 344.68\n",
            "2019-12-04 11:38:51,314 epoch 3 - iter 14/22 - loss 0.42205345 - samples/sec: 257.34\n",
            "2019-12-04 11:38:51,616 epoch 3 - iter 16/22 - loss 0.41364352 - samples/sec: 236.36\n",
            "2019-12-04 11:38:51,905 epoch 3 - iter 18/22 - loss 0.40380153 - samples/sec: 244.57\n",
            "2019-12-04 11:38:52,163 epoch 3 - iter 20/22 - loss 0.41490644 - samples/sec: 269.26\n",
            "2019-12-04 11:38:52,391 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:52,395 EPOCH 3 done: loss 0.4406 - lr 0.1000\n",
            "2019-12-04 11:38:53,229 DEV : loss 0.9795047640800476 - score 0.4941\n",
            "2019-12-04 11:38:53,275 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:38:53,276 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:53,754 epoch 4 - iter 0/22 - loss 0.89959300 - samples/sec: 615.63\n",
            "2019-12-04 11:38:54,088 epoch 4 - iter 2/22 - loss 0.59122299 - samples/sec: 213.45\n",
            "2019-12-04 11:38:54,382 epoch 4 - iter 4/22 - loss 0.49786769 - samples/sec: 256.05\n",
            "2019-12-04 11:38:54,717 epoch 4 - iter 6/22 - loss 0.47764797 - samples/sec: 208.24\n",
            "2019-12-04 11:38:54,980 epoch 4 - iter 8/22 - loss 0.47485105 - samples/sec: 264.98\n",
            "2019-12-04 11:38:55,198 epoch 4 - iter 10/22 - loss 0.46298487 - samples/sec: 330.83\n",
            "2019-12-04 11:38:55,504 epoch 4 - iter 12/22 - loss 0.45057760 - samples/sec: 233.48\n",
            "2019-12-04 11:38:55,781 epoch 4 - iter 14/22 - loss 0.45119772 - samples/sec: 260.45\n",
            "2019-12-04 11:38:56,051 epoch 4 - iter 16/22 - loss 0.42989049 - samples/sec: 269.88\n",
            "2019-12-04 11:38:56,320 epoch 4 - iter 18/22 - loss 0.42230899 - samples/sec: 270.00\n",
            "2019-12-04 11:38:56,582 epoch 4 - iter 20/22 - loss 0.42455063 - samples/sec: 276.34\n",
            "2019-12-04 11:38:56,800 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:56,806 EPOCH 4 done: loss 0.4425 - lr 0.1000\n",
            "2019-12-04 11:38:57,627 DEV : loss 1.2459120750427246 - score 0.4471\n",
            "2019-12-04 11:38:57,676 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:38:57,677 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:38:58,168 epoch 5 - iter 0/22 - loss 0.98257357 - samples/sec: 413.54\n",
            "2019-12-04 11:38:58,457 epoch 5 - iter 2/22 - loss 0.52451942 - samples/sec: 247.10\n",
            "2019-12-04 11:38:58,691 epoch 5 - iter 4/22 - loss 0.47679840 - samples/sec: 316.45\n",
            "2019-12-04 11:38:59,002 epoch 5 - iter 6/22 - loss 0.47194943 - samples/sec: 243.27\n",
            "2019-12-04 11:38:59,233 epoch 5 - iter 8/22 - loss 0.42469052 - samples/sec: 309.39\n",
            "2019-12-04 11:38:59,526 epoch 5 - iter 10/22 - loss 0.42451777 - samples/sec: 236.16\n",
            "2019-12-04 11:38:59,820 epoch 5 - iter 12/22 - loss 0.41347833 - samples/sec: 245.22\n",
            "2019-12-04 11:39:00,058 epoch 5 - iter 14/22 - loss 0.41512048 - samples/sec: 297.42\n",
            "2019-12-04 11:39:00,356 epoch 5 - iter 16/22 - loss 0.41188473 - samples/sec: 231.15\n",
            "2019-12-04 11:39:00,612 epoch 5 - iter 18/22 - loss 0.41480821 - samples/sec: 283.85\n",
            "2019-12-04 11:39:00,929 epoch 5 - iter 20/22 - loss 0.40759434 - samples/sec: 220.74\n",
            "2019-12-04 11:39:01,153 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:01,154 EPOCH 5 done: loss 0.4053 - lr 0.1000\n",
            "2019-12-04 11:39:02,050 DEV : loss 1.0829870700836182 - score 0.6588\n",
            "2019-12-04 11:39:02,099 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:39:02,100 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:02,657 epoch 6 - iter 0/22 - loss 0.64033848 - samples/sec: 346.40\n",
            "2019-12-04 11:39:02,920 epoch 6 - iter 2/22 - loss 0.43020495 - samples/sec: 279.21\n",
            "2019-12-04 11:39:03,193 epoch 6 - iter 4/22 - loss 0.40690482 - samples/sec: 283.25\n",
            "2019-12-04 11:39:03,456 epoch 6 - iter 6/22 - loss 0.40370727 - samples/sec: 268.14\n",
            "2019-12-04 11:39:03,704 epoch 6 - iter 8/22 - loss 0.38492473 - samples/sec: 285.32\n",
            "2019-12-04 11:39:04,006 epoch 6 - iter 10/22 - loss 0.37851226 - samples/sec: 242.78\n",
            "2019-12-04 11:39:04,327 epoch 6 - iter 12/22 - loss 0.36288751 - samples/sec: 226.63\n",
            "2019-12-04 11:39:04,615 epoch 6 - iter 14/22 - loss 0.34935276 - samples/sec: 244.97\n",
            "2019-12-04 11:39:04,921 epoch 6 - iter 16/22 - loss 0.36126863 - samples/sec: 229.46\n",
            "2019-12-04 11:39:05,174 epoch 6 - iter 18/22 - loss 0.35789137 - samples/sec: 278.25\n",
            "2019-12-04 11:39:05,393 epoch 6 - iter 20/22 - loss 0.36072525 - samples/sec: 322.17\n",
            "2019-12-04 11:39:05,627 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:05,629 EPOCH 6 done: loss 0.3499 - lr 0.1000\n",
            "2019-12-04 11:39:06,524 DEV : loss 0.3923390805721283 - score 0.8235\n",
            "2019-12-04 11:39:06,566 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:39:09,931 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:10,542 epoch 7 - iter 0/22 - loss 0.31452438 - samples/sec: 348.49\n",
            "2019-12-04 11:39:10,873 epoch 7 - iter 2/22 - loss 0.27941866 - samples/sec: 212.92\n",
            "2019-12-04 11:39:11,124 epoch 7 - iter 4/22 - loss 0.36747924 - samples/sec: 279.45\n",
            "2019-12-04 11:39:11,455 epoch 7 - iter 6/22 - loss 0.36832632 - samples/sec: 216.19\n",
            "2019-12-04 11:39:11,773 epoch 7 - iter 8/22 - loss 0.33814648 - samples/sec: 231.32\n",
            "2019-12-04 11:39:12,001 epoch 7 - iter 10/22 - loss 0.32960343 - samples/sec: 308.83\n",
            "2019-12-04 11:39:12,283 epoch 7 - iter 12/22 - loss 0.33290079 - samples/sec: 245.67\n",
            "2019-12-04 11:39:12,602 epoch 7 - iter 14/22 - loss 0.34377911 - samples/sec: 231.19\n",
            "2019-12-04 11:39:12,849 epoch 7 - iter 16/22 - loss 0.33869402 - samples/sec: 299.33\n",
            "2019-12-04 11:39:13,115 epoch 7 - iter 18/22 - loss 0.35477514 - samples/sec: 263.46\n",
            "2019-12-04 11:39:13,447 epoch 7 - iter 20/22 - loss 0.35319922 - samples/sec: 208.17\n",
            "2019-12-04 11:39:13,674 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:13,679 EPOCH 7 done: loss 0.3633 - lr 0.1000\n",
            "2019-12-04 11:39:14,575 DEV : loss 1.0951638221740723 - score 0.6706\n",
            "2019-12-04 11:39:14,624 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:39:14,626 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:15,147 epoch 8 - iter 0/22 - loss 0.93702459 - samples/sec: 505.26\n",
            "2019-12-04 11:39:15,453 epoch 8 - iter 2/22 - loss 0.53392258 - samples/sec: 229.47\n",
            "2019-12-04 11:39:15,747 epoch 8 - iter 4/22 - loss 0.41558108 - samples/sec: 247.07\n",
            "2019-12-04 11:39:16,019 epoch 8 - iter 6/22 - loss 0.36353732 - samples/sec: 271.59\n",
            "2019-12-04 11:39:16,281 epoch 8 - iter 8/22 - loss 0.35710165 - samples/sec: 268.91\n",
            "2019-12-04 11:39:18,041 epoch 8 - iter 10/22 - loss 0.36608369 - samples/sec: 318.23\n",
            "2019-12-04 11:39:18,252 epoch 8 - iter 12/22 - loss 0.36698032 - samples/sec: 353.22\n",
            "2019-12-04 11:39:18,468 epoch 8 - iter 14/22 - loss 0.36131769 - samples/sec: 328.68\n",
            "2019-12-04 11:39:18,700 epoch 8 - iter 16/22 - loss 0.34933548 - samples/sec: 335.86\n",
            "2019-12-04 11:39:18,890 epoch 8 - iter 18/22 - loss 0.35266998 - samples/sec: 383.51\n",
            "2019-12-04 11:39:19,118 epoch 8 - iter 20/22 - loss 0.35741624 - samples/sec: 308.60\n",
            "2019-12-04 11:39:19,351 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:19,354 EPOCH 8 done: loss 0.3480 - lr 0.1000\n",
            "2019-12-04 11:39:20,192 DEV : loss 0.5168234705924988 - score 0.7647\n",
            "2019-12-04 11:39:20,243 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:39:20,244 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:20,807 epoch 9 - iter 0/22 - loss 0.17407548 - samples/sec: 316.51\n",
            "2019-12-04 11:39:21,030 epoch 9 - iter 2/22 - loss 0.21202547 - samples/sec: 327.55\n",
            "2019-12-04 11:39:21,252 epoch 9 - iter 4/22 - loss 0.20450437 - samples/sec: 360.61\n",
            "2019-12-04 11:39:21,494 epoch 9 - iter 6/22 - loss 0.26127520 - samples/sec: 292.75\n",
            "2019-12-04 11:39:21,780 epoch 9 - iter 8/22 - loss 0.26791987 - samples/sec: 249.19\n",
            "2019-12-04 11:39:22,015 epoch 9 - iter 10/22 - loss 0.27264601 - samples/sec: 310.07\n",
            "2019-12-04 11:39:22,243 epoch 9 - iter 12/22 - loss 0.27470585 - samples/sec: 316.01\n",
            "2019-12-04 11:39:22,469 epoch 9 - iter 14/22 - loss 0.28750220 - samples/sec: 315.99\n",
            "2019-12-04 11:39:22,686 epoch 9 - iter 16/22 - loss 0.29374317 - samples/sec: 337.86\n",
            "2019-12-04 11:39:22,968 epoch 9 - iter 18/22 - loss 0.30124399 - samples/sec: 255.32\n",
            "2019-12-04 11:39:23,191 epoch 9 - iter 20/22 - loss 0.29620358 - samples/sec: 324.28\n",
            "2019-12-04 11:39:23,430 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:23,432 EPOCH 9 done: loss 0.3328 - lr 0.1000\n",
            "2019-12-04 11:39:24,274 DEV : loss 1.160901427268982 - score 0.5059\n",
            "2019-12-04 11:39:24,327 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:39:24,328 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:24,873 epoch 10 - iter 0/22 - loss 1.13427973 - samples/sec: 516.65\n",
            "2019-12-04 11:39:25,140 epoch 10 - iter 2/22 - loss 0.61643197 - samples/sec: 278.69\n",
            "2019-12-04 11:39:25,400 epoch 10 - iter 4/22 - loss 0.48116913 - samples/sec: 269.10\n",
            "2019-12-04 11:39:25,625 epoch 10 - iter 6/22 - loss 0.42020620 - samples/sec: 318.00\n",
            "2019-12-04 11:39:25,854 epoch 10 - iter 8/22 - loss 0.38066262 - samples/sec: 317.95\n",
            "2019-12-04 11:39:26,111 epoch 10 - iter 10/22 - loss 0.36625333 - samples/sec: 281.19\n",
            "2019-12-04 11:39:26,319 epoch 10 - iter 12/22 - loss 0.36559130 - samples/sec: 344.32\n",
            "2019-12-04 11:39:26,525 epoch 10 - iter 14/22 - loss 0.36233242 - samples/sec: 361.35\n",
            "2019-12-04 11:39:26,741 epoch 10 - iter 16/22 - loss 0.36288947 - samples/sec: 341.79\n",
            "2019-12-04 11:39:26,974 epoch 10 - iter 18/22 - loss 0.36669339 - samples/sec: 311.00\n",
            "2019-12-04 11:39:27,246 epoch 10 - iter 20/22 - loss 0.35372786 - samples/sec: 264.29\n",
            "2019-12-04 11:39:27,480 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:27,486 EPOCH 10 done: loss 0.3450 - lr 0.1000\n",
            "2019-12-04 11:39:28,330 DEV : loss 0.6097254157066345 - score 0.7412\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-12-04 11:39:28,381 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:39:31,672 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:31,675 Testing using best model ...\n",
            "2019-12-04 11:39:31,679 loading file test_csv/title10/best-model.pt\n",
            "2019-12-04 11:39:33,955 0.8333\t0.8333\t0.8333\n",
            "2019-12-04 11:39:33,956 \n",
            "MICRO_AVG: acc 0.7143 - f1-score 0.8333\n",
            "MACRO_AVG: acc 0.7043 - f1-score 0.82535\n",
            "fake       tp: 26 - fp: 9 - fn: 5 - tn: 44 - precision: 0.7429 - recall: 0.8387 - accuracy: 0.6500 - f1-score: 0.7879\n",
            "real       tp: 44 - fp: 5 - fn: 9 - tn: 26 - precision: 0.8980 - recall: 0.8302 - accuracy: 0.7586 - f1-score: 0.8628\n",
            "2019-12-04 11:39:33,966 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:33,967 loading file ./test_csv/title10/best-model.pt\n",
            "acc:  0.8160377358490566\n",
            "precision:  0.7920792079207921\n",
            "recall:  0.8163265306122449\n",
            "f1:  0.8040201005025126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AJwo3TzLIBW",
        "colab_type": "code",
        "outputId": "aea6ee56-0adc-4f4e-e49b-663681301e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_url = [(x['url'], label) for x, label in train_content] \n",
        "test_url = [(x['url'], label) for x, label in test_content]\n",
        "print(len([x for x, label in train_url if x == '']))\n",
        "print(len([x for x, label in test_url if x == '']))\n",
        "train_url = [(x, label) for x, label in train_url if x != ''] \n",
        "test_url = [(x, label) for x, label in test_url if x != '']\n",
        "print(len(train_url))\n",
        "print(len(test_url))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39\n",
            "22\n",
            "805\n",
            "190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdmynZt7LLWA",
        "colab_type": "code",
        "outputId": "34d14e37-84c3-4368-f2e5-2cf66016fb02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/url1'\n",
        "make_test(train_url, test_url, path, path, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:39:36,964 Reading data from test_csv/url1\n",
            "2019-12-04 11:39:36,965 Train: test_csv/url1/train.csv\n",
            "2019-12-04 11:39:36,967 Dev: test_csv/url1/dev.csv\n",
            "2019-12-04 11:39:36,969 Test: test_csv/url1/test.csv\n",
            "2019-12-04 11:39:36,977 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 644/644 [00:00<00:00, 884.97it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:39:38,165 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:39:39,856 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:39,858 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:39:39,859 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:39,860 Corpus: \"Corpus: 644 train + 81 dev + 80 test sentences\"\n",
            "2019-12-04 11:39:39,861 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:39,863 Parameters:\n",
            "2019-12-04 11:39:39,864  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:39:39,865  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:39:39,866  - patience: \"3\"\n",
            "2019-12-04 11:39:39,868  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:39:39,869  - max_epochs: \"1\"\n",
            "2019-12-04 11:39:39,870  - shuffle: \"True\"\n",
            "2019-12-04 11:39:39,871  - train_with_dev: \"False\"\n",
            "2019-12-04 11:39:39,889  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:39:39,891 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:39,892 Model training base path: \"test_csv/url1\"\n",
            "2019-12-04 11:39:39,894 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:39,895 Device: cuda:0\n",
            "2019-12-04 11:39:39,896 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:39,898 Embeddings storage mode: cpu\n",
            "2019-12-04 11:39:39,900 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:40,680 epoch 1 - iter 0/21 - loss 0.67606831 - samples/sec: 366.01\n",
            "2019-12-04 11:39:41,058 epoch 1 - iter 2/21 - loss 0.69448785 - samples/sec: 194.27\n",
            "2019-12-04 11:39:41,411 epoch 1 - iter 4/21 - loss 0.67084180 - samples/sec: 196.65\n",
            "2019-12-04 11:39:41,851 epoch 1 - iter 6/21 - loss 0.66875521 - samples/sec: 173.04\n",
            "2019-12-04 11:39:42,192 epoch 1 - iter 8/21 - loss 0.64461035 - samples/sec: 215.42\n",
            "2019-12-04 11:39:42,472 epoch 1 - iter 10/21 - loss 0.61701611 - samples/sec: 249.88\n",
            "2019-12-04 11:39:42,745 epoch 1 - iter 12/21 - loss 0.60516999 - samples/sec: 267.67\n",
            "2019-12-04 11:39:43,075 epoch 1 - iter 14/21 - loss 0.60070390 - samples/sec: 215.00\n",
            "2019-12-04 11:39:43,402 epoch 1 - iter 16/21 - loss 0.58599338 - samples/sec: 213.19\n",
            "2019-12-04 11:39:43,739 epoch 1 - iter 18/21 - loss 0.58567143 - samples/sec: 213.38\n",
            "2019-12-04 11:39:43,928 epoch 1 - iter 20/21 - loss 0.59580526 - samples/sec: 396.13\n",
            "2019-12-04 11:39:44,195 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:44,197 EPOCH 1 done: loss 0.5958 - lr 0.1000\n",
            "2019-12-04 11:39:45,141 DEV : loss 0.949234127998352 - score 0.4815\n",
            "2019-12-04 11:39:45,191 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:39:51,840 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:51,842 Testing using best model ...\n",
            "2019-12-04 11:39:51,848 loading file test_csv/url1/best-model.pt\n",
            "2019-12-04 11:39:53,575 0.4375\t0.4375\t0.4375\n",
            "2019-12-04 11:39:53,576 \n",
            "MICRO_AVG: acc 0.28 - f1-score 0.4375\n",
            "MACRO_AVG: acc 0.2447 - f1-score 0.36515000000000003\n",
            "fake       tp: 31 - fp: 45 - fn: 0 - tn: 4 - precision: 0.4079 - recall: 1.0000 - accuracy: 0.4079 - f1-score: 0.5794\n",
            "real       tp: 4 - fp: 0 - fn: 45 - tn: 31 - precision: 1.0000 - recall: 0.0816 - accuracy: 0.0816 - f1-score: 0.1509\n",
            "2019-12-04 11:39:53,578 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:39:53,580 loading file ./test_csv/url1/best-model.pt\n",
            "acc:  0.7526315789473684\n",
            "precision:  0.6935483870967742\n",
            "recall:  0.9052631578947369\n",
            "f1:  0.7853881278538815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRtVjTMCLSze",
        "colab_type": "code",
        "outputId": "6754bd30-ef2b-412c-c9e7-983d06be5858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/url10'\n",
        "make_test(train_url, test_url, path, path, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:39:57,665 Reading data from test_csv/url10\n",
            "2019-12-04 11:39:57,668 Train: test_csv/url10/train.csv\n",
            "2019-12-04 11:39:57,670 Dev: test_csv/url10/dev.csv\n",
            "2019-12-04 11:39:57,676 Test: test_csv/url10/test.csv\n",
            "2019-12-04 11:39:57,683 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 644/644 [00:00<00:00, 695.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:39:59,165 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:40:00,132 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:00,134 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:40:00,135 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:00,137 Corpus: \"Corpus: 644 train + 81 dev + 80 test sentences\"\n",
            "2019-12-04 11:40:00,138 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:00,139 Parameters:\n",
            "2019-12-04 11:40:00,141  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:40:00,143  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:40:00,144  - patience: \"3\"\n",
            "2019-12-04 11:40:00,146  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:40:00,147  - max_epochs: \"10\"\n",
            "2019-12-04 11:40:00,148  - shuffle: \"True\"\n",
            "2019-12-04 11:40:00,150  - train_with_dev: \"False\"\n",
            "2019-12-04 11:40:00,151  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:40:00,152 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:00,154 Model training base path: \"test_csv/url10\"\n",
            "2019-12-04 11:40:00,156 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:00,157 Device: cuda:0\n",
            "2019-12-04 11:40:00,158 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:00,160 Embeddings storage mode: cpu\n",
            "2019-12-04 11:40:00,162 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:01,094 epoch 1 - iter 0/21 - loss 0.72391248 - samples/sec: 354.37\n",
            "2019-12-04 11:40:01,742 epoch 1 - iter 2/21 - loss 0.72055463 - samples/sec: 104.85\n",
            "2019-12-04 11:40:02,067 epoch 1 - iter 4/21 - loss 0.69968352 - samples/sec: 213.78\n",
            "2019-12-04 11:40:02,409 epoch 1 - iter 6/21 - loss 0.67209793 - samples/sec: 219.23\n",
            "2019-12-04 11:40:02,956 epoch 1 - iter 8/21 - loss 0.65833841 - samples/sec: 122.12\n",
            "2019-12-04 11:40:03,256 epoch 1 - iter 10/21 - loss 0.63719271 - samples/sec: 231.46\n",
            "2019-12-04 11:40:03,604 epoch 1 - iter 12/21 - loss 0.62771935 - samples/sec: 202.58\n",
            "2019-12-04 11:40:03,926 epoch 1 - iter 14/21 - loss 0.61904624 - samples/sec: 218.07\n",
            "2019-12-04 11:40:04,245 epoch 1 - iter 16/21 - loss 0.60196839 - samples/sec: 222.30\n",
            "2019-12-04 11:40:04,567 epoch 1 - iter 18/21 - loss 0.59132661 - samples/sec: 220.66\n",
            "2019-12-04 11:40:04,779 epoch 1 - iter 20/21 - loss 0.57784374 - samples/sec: 354.40\n",
            "2019-12-04 11:40:05,090 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:05,094 EPOCH 1 done: loss 0.5778 - lr 0.1000\n",
            "2019-12-04 11:40:06,145 DEV : loss 0.5085112452507019 - score 0.7901\n",
            "2019-12-04 11:40:06,194 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:40:09,606 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:10,392 epoch 2 - iter 0/21 - loss 0.48979393 - samples/sec: 300.75\n",
            "2019-12-04 11:40:10,641 epoch 2 - iter 2/21 - loss 0.58826465 - samples/sec: 292.59\n",
            "2019-12-04 11:40:10,905 epoch 2 - iter 4/21 - loss 0.55359312 - samples/sec: 281.93\n",
            "2019-12-04 11:40:11,226 epoch 2 - iter 6/21 - loss 0.51095067 - samples/sec: 217.13\n",
            "2019-12-04 11:40:11,546 epoch 2 - iter 8/21 - loss 0.52291862 - samples/sec: 216.65\n",
            "2019-12-04 11:40:11,863 epoch 2 - iter 10/21 - loss 0.52413556 - samples/sec: 241.07\n",
            "2019-12-04 11:40:12,145 epoch 2 - iter 12/21 - loss 0.51043547 - samples/sec: 247.80\n",
            "2019-12-04 11:40:12,434 epoch 2 - iter 14/21 - loss 0.52980688 - samples/sec: 241.51\n",
            "2019-12-04 11:40:12,717 epoch 2 - iter 16/21 - loss 0.55037225 - samples/sec: 254.70\n",
            "2019-12-04 11:40:13,014 epoch 2 - iter 18/21 - loss 0.54938717 - samples/sec: 243.51\n",
            "2019-12-04 11:40:13,202 epoch 2 - iter 20/21 - loss 0.55379668 - samples/sec: 390.37\n",
            "2019-12-04 11:40:13,511 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:13,516 EPOCH 2 done: loss 0.5538 - lr 0.1000\n",
            "2019-12-04 11:40:14,583 DEV : loss 0.6699284315109253 - score 0.5679\n",
            "2019-12-04 11:40:14,640 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:40:14,643 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:15,406 epoch 3 - iter 0/21 - loss 0.56414932 - samples/sec: 273.22\n",
            "2019-12-04 11:40:15,773 epoch 3 - iter 2/21 - loss 0.44248074 - samples/sec: 197.22\n",
            "2019-12-04 11:40:17,645 epoch 3 - iter 4/21 - loss 0.43136330 - samples/sec: 224.28\n",
            "2019-12-04 11:40:17,930 epoch 3 - iter 6/21 - loss 0.44793527 - samples/sec: 256.31\n",
            "2019-12-04 11:40:18,232 epoch 3 - iter 8/21 - loss 0.44699027 - samples/sec: 239.18\n",
            "2019-12-04 11:40:18,541 epoch 3 - iter 10/21 - loss 0.42816208 - samples/sec: 232.31\n",
            "2019-12-04 11:40:18,819 epoch 3 - iter 12/21 - loss 0.45418690 - samples/sec: 259.98\n",
            "2019-12-04 11:40:19,134 epoch 3 - iter 14/21 - loss 0.45172951 - samples/sec: 227.76\n",
            "2019-12-04 11:40:19,425 epoch 3 - iter 16/21 - loss 0.47038299 - samples/sec: 245.44\n",
            "2019-12-04 11:40:19,720 epoch 3 - iter 18/21 - loss 0.47347943 - samples/sec: 241.12\n",
            "2019-12-04 11:40:19,882 epoch 3 - iter 20/21 - loss 0.47262685 - samples/sec: 469.44\n",
            "2019-12-04 11:40:20,199 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:20,201 EPOCH 3 done: loss 0.4726 - lr 0.1000\n",
            "2019-12-04 11:40:21,341 DEV : loss 0.6006264686584473 - score 0.7284\n",
            "2019-12-04 11:40:21,396 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:40:21,398 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:22,137 epoch 4 - iter 0/21 - loss 0.46836466 - samples/sec: 333.57\n",
            "2019-12-04 11:40:22,426 epoch 4 - iter 2/21 - loss 0.49628292 - samples/sec: 251.31\n",
            "2019-12-04 11:40:22,725 epoch 4 - iter 4/21 - loss 0.48758759 - samples/sec: 246.72\n",
            "2019-12-04 11:40:23,020 epoch 4 - iter 6/21 - loss 0.45078890 - samples/sec: 238.58\n",
            "2019-12-04 11:40:23,312 epoch 4 - iter 8/21 - loss 0.42723451 - samples/sec: 246.08\n",
            "2019-12-04 11:40:23,571 epoch 4 - iter 10/21 - loss 0.44123977 - samples/sec: 283.49\n",
            "2019-12-04 11:40:23,847 epoch 4 - iter 12/21 - loss 0.45567288 - samples/sec: 255.56\n",
            "2019-12-04 11:40:24,134 epoch 4 - iter 14/21 - loss 0.45122289 - samples/sec: 245.23\n",
            "2019-12-04 11:40:24,427 epoch 4 - iter 16/21 - loss 0.45512436 - samples/sec: 245.00\n",
            "2019-12-04 11:40:24,733 epoch 4 - iter 18/21 - loss 0.48786411 - samples/sec: 233.29\n",
            "2019-12-04 11:40:24,914 epoch 4 - iter 20/21 - loss 0.48411258 - samples/sec: 411.30\n",
            "2019-12-04 11:40:25,218 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:25,219 EPOCH 4 done: loss 0.4841 - lr 0.1000\n",
            "2019-12-04 11:40:26,317 DEV : loss 0.4573346972465515 - score 0.7901\n",
            "2019-12-04 11:40:26,366 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:40:29,731 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:30,492 epoch 5 - iter 0/21 - loss 0.52805775 - samples/sec: 304.91\n",
            "2019-12-04 11:40:30,812 epoch 5 - iter 2/21 - loss 0.45794585 - samples/sec: 240.42\n",
            "2019-12-04 11:40:31,088 epoch 5 - iter 4/21 - loss 0.44156637 - samples/sec: 258.29\n",
            "2019-12-04 11:40:31,396 epoch 5 - iter 6/21 - loss 0.46465891 - samples/sec: 250.96\n",
            "2019-12-04 11:40:31,722 epoch 5 - iter 8/21 - loss 0.46447887 - samples/sec: 222.31\n",
            "2019-12-04 11:40:31,989 epoch 5 - iter 10/21 - loss 0.45162055 - samples/sec: 286.06\n",
            "2019-12-04 11:40:32,252 epoch 5 - iter 12/21 - loss 0.46156268 - samples/sec: 274.44\n",
            "2019-12-04 11:40:32,484 epoch 5 - iter 14/21 - loss 0.45945522 - samples/sec: 303.97\n",
            "2019-12-04 11:40:32,754 epoch 5 - iter 16/21 - loss 0.45687249 - samples/sec: 269.82\n",
            "2019-12-04 11:40:33,045 epoch 5 - iter 18/21 - loss 0.45102779 - samples/sec: 242.12\n",
            "2019-12-04 11:40:33,206 epoch 5 - iter 20/21 - loss 0.47958723 - samples/sec: 455.15\n",
            "2019-12-04 11:40:33,501 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:33,508 EPOCH 5 done: loss 0.4796 - lr 0.1000\n",
            "2019-12-04 11:40:34,637 DEV : loss 1.2961220741271973 - score 0.5679\n",
            "Epoch     4: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-12-04 11:40:34,683 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:40:34,685 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:35,408 epoch 6 - iter 0/21 - loss 1.17543161 - samples/sec: 261.31\n",
            "2019-12-04 11:40:35,716 epoch 6 - iter 2/21 - loss 0.81295599 - samples/sec: 247.33\n",
            "2019-12-04 11:40:35,992 epoch 6 - iter 4/21 - loss 0.64450258 - samples/sec: 257.55\n",
            "2019-12-04 11:40:36,262 epoch 6 - iter 6/21 - loss 0.56772635 - samples/sec: 262.08\n",
            "2019-12-04 11:40:36,533 epoch 6 - iter 8/21 - loss 0.53750701 - samples/sec: 271.91\n",
            "2019-12-04 11:40:36,790 epoch 6 - iter 10/21 - loss 0.51630706 - samples/sec: 278.20\n",
            "2019-12-04 11:40:37,087 epoch 6 - iter 12/21 - loss 0.48817633 - samples/sec: 232.65\n",
            "2019-12-04 11:40:37,468 epoch 6 - iter 14/21 - loss 0.46912388 - samples/sec: 191.88\n",
            "2019-12-04 11:40:37,775 epoch 6 - iter 16/21 - loss 0.46123918 - samples/sec: 241.22\n",
            "2019-12-04 11:40:38,029 epoch 6 - iter 18/21 - loss 0.46100568 - samples/sec: 285.18\n",
            "2019-12-04 11:40:38,216 epoch 6 - iter 20/21 - loss 0.44457652 - samples/sec: 383.98\n",
            "2019-12-04 11:40:38,518 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:38,521 EPOCH 6 done: loss 0.4446 - lr 0.0500\n",
            "2019-12-04 11:40:39,603 DEV : loss 0.417341411113739 - score 0.8519\n",
            "2019-12-04 11:40:39,655 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:40:42,957 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:43,714 epoch 7 - iter 0/21 - loss 0.46065775 - samples/sec: 287.96\n",
            "2019-12-04 11:40:43,992 epoch 7 - iter 2/21 - loss 0.36267767 - samples/sec: 269.14\n",
            "2019-12-04 11:40:44,340 epoch 7 - iter 4/21 - loss 0.39987513 - samples/sec: 204.01\n",
            "2019-12-04 11:40:44,667 epoch 7 - iter 6/21 - loss 0.42739064 - samples/sec: 228.49\n",
            "2019-12-04 11:40:44,934 epoch 7 - iter 8/21 - loss 0.42930939 - samples/sec: 261.61\n",
            "2019-12-04 11:40:45,206 epoch 7 - iter 10/21 - loss 0.40338657 - samples/sec: 255.21\n",
            "2019-12-04 11:40:45,501 epoch 7 - iter 12/21 - loss 0.40323215 - samples/sec: 244.18\n",
            "2019-12-04 11:40:45,742 epoch 7 - iter 14/21 - loss 0.40633080 - samples/sec: 292.52\n",
            "2019-12-04 11:40:46,005 epoch 7 - iter 16/21 - loss 0.40411257 - samples/sec: 266.21\n",
            "2019-12-04 11:40:46,291 epoch 7 - iter 18/21 - loss 0.40536289 - samples/sec: 251.13\n",
            "2019-12-04 11:40:46,515 epoch 7 - iter 20/21 - loss 0.40548319 - samples/sec: 325.61\n",
            "2019-12-04 11:40:46,827 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:46,830 EPOCH 7 done: loss 0.4055 - lr 0.0500\n",
            "2019-12-04 11:40:47,978 DEV : loss 0.46582287549972534 - score 0.7901\n",
            "2019-12-04 11:40:48,032 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:40:48,036 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:48,741 epoch 8 - iter 0/21 - loss 0.36780158 - samples/sec: 321.63\n",
            "2019-12-04 11:40:49,021 epoch 8 - iter 2/21 - loss 0.35872621 - samples/sec: 258.25\n",
            "2019-12-04 11:40:49,280 epoch 8 - iter 4/21 - loss 0.36562997 - samples/sec: 286.76\n",
            "2019-12-04 11:40:49,632 epoch 8 - iter 6/21 - loss 0.39532557 - samples/sec: 200.53\n",
            "2019-12-04 11:40:49,902 epoch 8 - iter 8/21 - loss 0.39457282 - samples/sec: 271.04\n",
            "2019-12-04 11:40:50,149 epoch 8 - iter 10/21 - loss 0.40079084 - samples/sec: 286.04\n",
            "2019-12-04 11:40:50,453 epoch 8 - iter 12/21 - loss 0.40140554 - samples/sec: 235.26\n",
            "2019-12-04 11:40:50,749 epoch 8 - iter 14/21 - loss 0.40418035 - samples/sec: 247.64\n",
            "2019-12-04 11:40:50,980 epoch 8 - iter 16/21 - loss 0.39566513 - samples/sec: 308.77\n",
            "2019-12-04 11:40:51,212 epoch 8 - iter 18/21 - loss 0.39430781 - samples/sec: 304.87\n",
            "2019-12-04 11:40:51,402 epoch 8 - iter 20/21 - loss 0.38354693 - samples/sec: 383.98\n",
            "2019-12-04 11:40:51,704 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:51,708 EPOCH 8 done: loss 0.3835 - lr 0.0500\n",
            "2019-12-04 11:40:52,763 DEV : loss 0.36890220642089844 - score 0.8395\n",
            "2019-12-04 11:40:52,809 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:40:52,811 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:53,491 epoch 9 - iter 0/21 - loss 0.44066492 - samples/sec: 405.85\n",
            "2019-12-04 11:40:53,792 epoch 9 - iter 2/21 - loss 0.36261499 - samples/sec: 234.34\n",
            "2019-12-04 11:40:54,065 epoch 9 - iter 4/21 - loss 0.35015357 - samples/sec: 278.61\n",
            "2019-12-04 11:40:54,338 epoch 9 - iter 6/21 - loss 0.35397292 - samples/sec: 257.87\n",
            "2019-12-04 11:40:54,576 epoch 9 - iter 8/21 - loss 0.36697400 - samples/sec: 294.57\n",
            "2019-12-04 11:40:54,893 epoch 9 - iter 10/21 - loss 0.36256538 - samples/sec: 228.95\n",
            "2019-12-04 11:40:55,178 epoch 9 - iter 12/21 - loss 0.37313274 - samples/sec: 245.54\n",
            "2019-12-04 11:40:55,488 epoch 9 - iter 14/21 - loss 0.36581546 - samples/sec: 227.33\n",
            "2019-12-04 11:40:55,809 epoch 9 - iter 16/21 - loss 0.38474130 - samples/sec: 224.33\n",
            "2019-12-04 11:40:56,070 epoch 9 - iter 18/21 - loss 0.37299951 - samples/sec: 274.65\n",
            "2019-12-04 11:40:56,281 epoch 9 - iter 20/21 - loss 0.35973344 - samples/sec: 351.97\n",
            "2019-12-04 11:40:56,571 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:56,575 EPOCH 9 done: loss 0.3597 - lr 0.0500\n",
            "2019-12-04 11:40:57,725 DEV : loss 0.359241783618927 - score 0.8395\n",
            "2019-12-04 11:40:57,771 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:40:57,773 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:40:58,510 epoch 10 - iter 0/21 - loss 0.40600294 - samples/sec: 361.55\n",
            "2019-12-04 11:40:58,850 epoch 10 - iter 2/21 - loss 0.41076981 - samples/sec: 205.36\n",
            "2019-12-04 11:40:59,191 epoch 10 - iter 4/21 - loss 0.38814322 - samples/sec: 216.58\n",
            "2019-12-04 11:40:59,552 epoch 10 - iter 6/21 - loss 0.43100759 - samples/sec: 195.91\n",
            "2019-12-04 11:40:59,919 epoch 10 - iter 8/21 - loss 0.40132195 - samples/sec: 188.22\n",
            "2019-12-04 11:41:00,325 epoch 10 - iter 10/21 - loss 0.38902186 - samples/sec: 174.68\n",
            "2019-12-04 11:41:00,716 epoch 10 - iter 12/21 - loss 0.36795360 - samples/sec: 176.41\n",
            "2019-12-04 11:41:01,141 epoch 10 - iter 14/21 - loss 0.36832078 - samples/sec: 165.06\n",
            "2019-12-04 11:41:01,436 epoch 10 - iter 16/21 - loss 0.36856734 - samples/sec: 245.20\n",
            "2019-12-04 11:41:01,762 epoch 10 - iter 18/21 - loss 0.36795729 - samples/sec: 210.31\n",
            "2019-12-04 11:41:01,965 epoch 10 - iter 20/21 - loss 0.38677217 - samples/sec: 361.85\n",
            "2019-12-04 11:41:02,261 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:02,264 EPOCH 10 done: loss 0.3868 - lr 0.0500\n",
            "2019-12-04 11:41:03,440 DEV : loss 0.3496350944042206 - score 0.8395\n",
            "Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-12-04 11:41:03,493 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:41:06,833 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:06,834 Testing using best model ...\n",
            "2019-12-04 11:41:06,836 loading file test_csv/url10/best-model.pt\n",
            "2019-12-04 11:41:08,993 0.8875\t0.8875\t0.8875\n",
            "2019-12-04 11:41:08,999 \n",
            "MICRO_AVG: acc 0.7978 - f1-score 0.8875\n",
            "MACRO_AVG: acc 0.7804 - f1-score 0.8753\n",
            "fake       tp: 23 - fp: 1 - fn: 8 - tn: 48 - precision: 0.9583 - recall: 0.7419 - accuracy: 0.7188 - f1-score: 0.8363\n",
            "real       tp: 48 - fp: 8 - fn: 1 - tn: 23 - precision: 0.8571 - recall: 0.9796 - accuracy: 0.8421 - f1-score: 0.9143\n",
            "2019-12-04 11:41:09,003 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:09,007 loading file ./test_csv/url10/best-model.pt\n",
            "acc:  0.6210526315789474\n",
            "precision:  0.96\n",
            "recall:  0.25263157894736843\n",
            "f1:  0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1M55hjsLV6Z",
        "colab_type": "code",
        "outputId": "8aeb6744-b3f0-48ee-8f84-03476e173095",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_mix = [(x['url'] + ', ' + x['title'], label) for x, label in train_content] \n",
        "test_mix = [(x['url'] + ', ' + x['title'], label) for x, label in test_content]\n",
        "print(len([x for x, label in train_mix if x == '']))\n",
        "print(len([x for x, label in test_mix if x == '']))\n",
        "train_mix = [(x, label) for x, label in train_mix if x != ''] \n",
        "test_mix = [(x, label) for x, label in test_mix if x != '']\n",
        "print(len(train_mix))\n",
        "print(len(test_mix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "844\n",
            "212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNjfDvDhLbkF",
        "colab_type": "code",
        "outputId": "57335da8-2a5b-4e53-bbcc-6d8684bf6784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/mix1'\n",
        "make_test(train_mix, test_mix, path, path, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:13,677 Reading data from test_csv/mix1\n",
            "2019-12-04 11:41:13,680 Train: test_csv/mix1/train.csv\n",
            "2019-12-04 11:41:13,682 Dev: test_csv/mix1/dev.csv\n",
            "2019-12-04 11:41:13,686 Test: test_csv/mix1/test.csv\n",
            "2019-12-04 11:41:13,693 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 675/675 [00:00<00:00, 719.56it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:15,261 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:16,270 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:16,271 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:41:16,273 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:16,274 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
            "2019-12-04 11:41:16,276 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:16,277 Parameters:\n",
            "2019-12-04 11:41:16,279  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:41:16,280  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:41:16,281  - patience: \"3\"\n",
            "2019-12-04 11:41:16,283  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:41:16,284  - max_epochs: \"1\"\n",
            "2019-12-04 11:41:16,285  - shuffle: \"True\"\n",
            "2019-12-04 11:41:16,286  - train_with_dev: \"False\"\n",
            "2019-12-04 11:41:16,288  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:41:16,289 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:16,290 Model training base path: \"test_csv/mix1\"\n",
            "2019-12-04 11:41:16,292 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:16,293 Device: cuda:0\n",
            "2019-12-04 11:41:16,294 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:16,295 Embeddings storage mode: cpu\n",
            "2019-12-04 11:41:16,297 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:17,388 epoch 1 - iter 0/22 - loss 0.67567301 - samples/sec: 197.18\n",
            "2019-12-04 11:41:17,997 epoch 1 - iter 2/22 - loss 0.69546117 - samples/sec: 123.85\n",
            "2019-12-04 11:41:18,572 epoch 1 - iter 4/22 - loss 0.68511080 - samples/sec: 118.44\n",
            "2019-12-04 11:41:19,114 epoch 1 - iter 6/22 - loss 0.68159670 - samples/sec: 126.41\n",
            "2019-12-04 11:41:19,789 epoch 1 - iter 8/22 - loss 0.68817116 - samples/sec: 102.43\n",
            "2019-12-04 11:41:20,542 epoch 1 - iter 10/22 - loss 0.68888190 - samples/sec: 89.85\n",
            "2019-12-04 11:41:21,059 epoch 1 - iter 12/22 - loss 0.66874279 - samples/sec: 140.53\n",
            "2019-12-04 11:41:21,794 epoch 1 - iter 14/22 - loss 0.66519936 - samples/sec: 90.85\n",
            "2019-12-04 11:41:22,281 epoch 1 - iter 16/22 - loss 0.65463858 - samples/sec: 138.84\n",
            "2019-12-04 11:41:22,830 epoch 1 - iter 18/22 - loss 0.63624099 - samples/sec: 123.84\n",
            "2019-12-04 11:41:23,499 epoch 1 - iter 20/22 - loss 0.62074395 - samples/sec: 99.39\n",
            "2019-12-04 11:41:23,893 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:23,895 EPOCH 1 done: loss 0.6028 - lr 0.1000\n",
            "2019-12-04 11:41:25,287 DEV : loss 0.7131989002227783 - score 0.6118\n",
            "2019-12-04 11:41:25,364 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:31,860 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:31,861 Testing using best model ...\n",
            "2019-12-04 11:41:31,862 loading file test_csv/mix1/best-model.pt\n",
            "2019-12-04 11:41:34,886 0.6905\t0.6905\t0.6905\n",
            "2019-12-04 11:41:34,889 \n",
            "MICRO_AVG: acc 0.5273 - f1-score 0.6905\n",
            "MACRO_AVG: acc 0.4161 - f1-score 0.5404\n",
            "fake       tp: 5 - fp: 0 - fn: 26 - tn: 53 - precision: 1.0000 - recall: 0.1613 - accuracy: 0.1613 - f1-score: 0.2778\n",
            "real       tp: 53 - fp: 26 - fn: 0 - tn: 5 - precision: 0.6709 - recall: 1.0000 - accuracy: 0.6709 - f1-score: 0.8030\n",
            "2019-12-04 11:41:34,890 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:34,891 loading file ./test_csv/mix1/best-model.pt\n",
            "acc:  0.5801886792452831\n",
            "precision:  1.0\n",
            "recall:  0.09183673469387756\n",
            "f1:  0.16822429906542058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix7biS9_Ldpu",
        "colab_type": "code",
        "outputId": "ad1b64ba-428c-437f-a8a7-83951ef1be58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/mix10'\n",
        "make_test(train_mix, test_mix, path, path, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:39,780 Reading data from test_csv/mix10\n",
            "2019-12-04 11:41:39,781 Train: test_csv/mix10/train.csv\n",
            "2019-12-04 11:41:39,783 Dev: test_csv/mix10/dev.csv\n",
            "2019-12-04 11:41:39,784 Test: test_csv/mix10/test.csv\n",
            "2019-12-04 11:41:39,791 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 675/675 [00:01<00:00, 666.69it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:41,451 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:43,321 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:43,324 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:41:43,325 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:43,326 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
            "2019-12-04 11:41:43,327 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:43,329 Parameters:\n",
            "2019-12-04 11:41:43,330  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:41:43,331  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:41:43,333  - patience: \"3\"\n",
            "2019-12-04 11:41:43,334  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:41:43,335  - max_epochs: \"10\"\n",
            "2019-12-04 11:41:43,337  - shuffle: \"True\"\n",
            "2019-12-04 11:41:43,338  - train_with_dev: \"False\"\n",
            "2019-12-04 11:41:43,339  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:41:43,340 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:43,341 Model training base path: \"test_csv/mix10\"\n",
            "2019-12-04 11:41:43,342 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:43,367 Device: cuda:0\n",
            "2019-12-04 11:41:43,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:43,370 Embeddings storage mode: cpu\n",
            "2019-12-04 11:41:43,373 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:44,388 epoch 1 - iter 0/22 - loss 0.71623081 - samples/sec: 238.33\n",
            "2019-12-04 11:41:44,949 epoch 1 - iter 2/22 - loss 0.70339088 - samples/sec: 122.67\n",
            "2019-12-04 11:41:45,487 epoch 1 - iter 4/22 - loss 0.70017264 - samples/sec: 125.62\n",
            "2019-12-04 11:41:46,373 epoch 1 - iter 6/22 - loss 0.67535240 - samples/sec: 76.30\n",
            "2019-12-04 11:41:47,284 epoch 1 - iter 8/22 - loss 0.70217791 - samples/sec: 73.10\n",
            "2019-12-04 11:41:47,888 epoch 1 - iter 10/22 - loss 0.69824539 - samples/sec: 113.54\n",
            "2019-12-04 11:41:48,339 epoch 1 - iter 12/22 - loss 0.67155485 - samples/sec: 153.06\n",
            "2019-12-04 11:41:48,836 epoch 1 - iter 14/22 - loss 0.66266346 - samples/sec: 138.11\n",
            "2019-12-04 11:41:49,287 epoch 1 - iter 16/22 - loss 0.64698171 - samples/sec: 152.17\n",
            "2019-12-04 11:41:49,790 epoch 1 - iter 18/22 - loss 0.63056065 - samples/sec: 136.89\n",
            "2019-12-04 11:41:50,237 epoch 1 - iter 20/22 - loss 0.62854086 - samples/sec: 152.29\n",
            "2019-12-04 11:41:50,605 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:50,606 EPOCH 1 done: loss 0.6187 - lr 0.1000\n",
            "2019-12-04 11:41:52,100 DEV : loss 0.6771402359008789 - score 0.5412\n",
            "2019-12-04 11:41:52,182 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:41:55,649 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:41:56,532 epoch 2 - iter 0/22 - loss 0.70023197 - samples/sec: 266.99\n",
            "2019-12-04 11:41:56,942 epoch 2 - iter 2/22 - loss 0.61663314 - samples/sec: 167.88\n",
            "2019-12-04 11:41:57,443 epoch 2 - iter 4/22 - loss 0.57541447 - samples/sec: 142.08\n",
            "2019-12-04 11:41:57,901 epoch 2 - iter 6/22 - loss 0.53374495 - samples/sec: 151.75\n",
            "2019-12-04 11:41:58,357 epoch 2 - iter 8/22 - loss 0.53108068 - samples/sec: 147.78\n",
            "2019-12-04 11:41:58,912 epoch 2 - iter 10/22 - loss 0.52675792 - samples/sec: 134.41\n",
            "2019-12-04 11:41:59,401 epoch 2 - iter 12/22 - loss 0.53958977 - samples/sec: 137.51\n",
            "2019-12-04 11:41:59,871 epoch 2 - iter 14/22 - loss 0.52282524 - samples/sec: 148.49\n",
            "2019-12-04 11:42:00,298 epoch 2 - iter 16/22 - loss 0.52217306 - samples/sec: 159.26\n",
            "2019-12-04 11:42:00,795 epoch 2 - iter 18/22 - loss 0.51712364 - samples/sec: 136.71\n",
            "2019-12-04 11:42:01,272 epoch 2 - iter 20/22 - loss 0.51577981 - samples/sec: 142.19\n",
            "2019-12-04 11:42:01,648 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:01,651 EPOCH 2 done: loss 0.5230 - lr 0.1000\n",
            "2019-12-04 11:42:03,113 DEV : loss 0.9145969152450562 - score 0.5882\n",
            "2019-12-04 11:42:03,190 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:42:06,448 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:07,391 epoch 3 - iter 0/22 - loss 0.86429673 - samples/sec: 158.79\n",
            "2019-12-04 11:42:07,944 epoch 3 - iter 2/22 - loss 0.60738561 - samples/sec: 135.66\n",
            "2019-12-04 11:42:08,335 epoch 3 - iter 4/22 - loss 0.55015098 - samples/sec: 174.90\n",
            "2019-12-04 11:42:08,794 epoch 3 - iter 6/22 - loss 0.49239887 - samples/sec: 147.16\n",
            "2019-12-04 11:42:09,318 epoch 3 - iter 8/22 - loss 0.46040985 - samples/sec: 136.49\n",
            "2019-12-04 11:42:09,859 epoch 3 - iter 10/22 - loss 0.49649116 - samples/sec: 124.89\n",
            "2019-12-04 11:42:10,366 epoch 3 - iter 12/22 - loss 0.47717197 - samples/sec: 139.13\n",
            "2019-12-04 11:42:10,887 epoch 3 - iter 14/22 - loss 0.47791009 - samples/sec: 131.58\n",
            "2019-12-04 11:42:11,307 epoch 3 - iter 16/22 - loss 0.46675981 - samples/sec: 163.06\n",
            "2019-12-04 11:42:11,733 epoch 3 - iter 18/22 - loss 0.48211531 - samples/sec: 164.35\n",
            "2019-12-04 11:42:12,267 epoch 3 - iter 20/22 - loss 0.50202007 - samples/sec: 126.00\n",
            "2019-12-04 11:42:12,622 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:12,625 EPOCH 3 done: loss 0.4842 - lr 0.1000\n",
            "2019-12-04 11:42:13,994 DEV : loss 0.5142746567726135 - score 0.7529\n",
            "2019-12-04 11:42:14,067 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:42:17,379 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:18,301 epoch 4 - iter 0/22 - loss 0.27510929 - samples/sec: 211.24\n",
            "2019-12-04 11:42:18,823 epoch 4 - iter 2/22 - loss 0.30511144 - samples/sec: 130.58\n",
            "2019-12-04 11:42:21,122 epoch 4 - iter 4/22 - loss 0.32222782 - samples/sec: 173.39\n",
            "2019-12-04 11:42:21,536 epoch 4 - iter 6/22 - loss 0.35321886 - samples/sec: 164.51\n",
            "2019-12-04 11:42:21,980 epoch 4 - iter 8/22 - loss 0.37657696 - samples/sec: 153.11\n",
            "2019-12-04 11:42:22,347 epoch 4 - iter 10/22 - loss 0.39121648 - samples/sec: 192.07\n",
            "2019-12-04 11:42:22,758 epoch 4 - iter 12/22 - loss 0.39261516 - samples/sec: 166.29\n",
            "2019-12-04 11:42:23,152 epoch 4 - iter 14/22 - loss 0.38712810 - samples/sec: 178.03\n",
            "2019-12-04 11:42:23,556 epoch 4 - iter 16/22 - loss 0.40332515 - samples/sec: 173.81\n",
            "2019-12-04 11:42:24,031 epoch 4 - iter 18/22 - loss 0.41591752 - samples/sec: 143.23\n",
            "2019-12-04 11:42:24,570 epoch 4 - iter 20/22 - loss 0.43496843 - samples/sec: 127.08\n",
            "2019-12-04 11:42:24,954 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:24,959 EPOCH 4 done: loss 0.4294 - lr 0.1000\n",
            "2019-12-04 11:42:26,342 DEV : loss 0.8779410123825073 - score 0.5294\n",
            "2019-12-04 11:42:26,422 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:42:26,428 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:27,271 epoch 5 - iter 0/22 - loss 1.00400341 - samples/sec: 261.10\n",
            "2019-12-04 11:42:27,808 epoch 5 - iter 2/22 - loss 0.61181367 - samples/sec: 128.66\n",
            "2019-12-04 11:42:28,297 epoch 5 - iter 4/22 - loss 0.55650278 - samples/sec: 146.19\n",
            "2019-12-04 11:42:28,757 epoch 5 - iter 6/22 - loss 0.51986351 - samples/sec: 148.59\n",
            "2019-12-04 11:42:29,287 epoch 5 - iter 8/22 - loss 0.48203838 - samples/sec: 134.49\n",
            "2019-12-04 11:42:29,857 epoch 5 - iter 10/22 - loss 0.45146954 - samples/sec: 126.48\n",
            "2019-12-04 11:42:30,353 epoch 5 - iter 12/22 - loss 0.44108142 - samples/sec: 136.77\n",
            "2019-12-04 11:42:30,823 epoch 5 - iter 14/22 - loss 0.43678954 - samples/sec: 148.04\n",
            "2019-12-04 11:42:31,304 epoch 5 - iter 16/22 - loss 0.43341790 - samples/sec: 147.61\n",
            "2019-12-04 11:42:31,850 epoch 5 - iter 18/22 - loss 0.42856460 - samples/sec: 123.44\n",
            "2019-12-04 11:42:32,376 epoch 5 - iter 20/22 - loss 0.41984284 - samples/sec: 129.89\n",
            "2019-12-04 11:42:32,732 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:32,738 EPOCH 5 done: loss 0.4179 - lr 0.1000\n",
            "2019-12-04 11:42:34,165 DEV : loss 0.40312671661376953 - score 0.8353\n",
            "2019-12-04 11:42:34,246 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:42:37,673 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:38,626 epoch 6 - iter 0/22 - loss 0.25865826 - samples/sec: 200.14\n",
            "2019-12-04 11:42:39,100 epoch 6 - iter 2/22 - loss 0.43730888 - samples/sec: 147.56\n",
            "2019-12-04 11:42:39,579 epoch 6 - iter 4/22 - loss 0.41168277 - samples/sec: 145.50\n",
            "2019-12-04 11:42:40,006 epoch 6 - iter 6/22 - loss 0.39150651 - samples/sec: 165.01\n",
            "2019-12-04 11:42:40,493 epoch 6 - iter 8/22 - loss 0.40332203 - samples/sec: 142.68\n",
            "2019-12-04 11:42:40,940 epoch 6 - iter 10/22 - loss 0.40993459 - samples/sec: 157.89\n",
            "2019-12-04 11:42:41,441 epoch 6 - iter 12/22 - loss 0.38731152 - samples/sec: 139.03\n",
            "2019-12-04 11:42:41,882 epoch 6 - iter 14/22 - loss 0.37534432 - samples/sec: 157.65\n",
            "2019-12-04 11:42:42,293 epoch 6 - iter 16/22 - loss 0.38938693 - samples/sec: 173.75\n",
            "2019-12-04 11:42:42,733 epoch 6 - iter 18/22 - loss 0.39486723 - samples/sec: 153.00\n",
            "2019-12-04 11:42:43,220 epoch 6 - iter 20/22 - loss 0.40179091 - samples/sec: 137.41\n",
            "2019-12-04 11:42:43,586 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:43,590 EPOCH 6 done: loss 0.4084 - lr 0.1000\n",
            "2019-12-04 11:42:44,937 DEV : loss 0.7125296592712402 - score 0.7294\n",
            "2019-12-04 11:42:45,009 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:42:45,011 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:45,920 epoch 7 - iter 0/22 - loss 0.41724029 - samples/sec: 181.94\n",
            "2019-12-04 11:42:46,379 epoch 7 - iter 2/22 - loss 0.34490422 - samples/sec: 165.68\n",
            "2019-12-04 11:42:46,783 epoch 7 - iter 4/22 - loss 0.32666467 - samples/sec: 167.94\n",
            "2019-12-04 11:42:47,307 epoch 7 - iter 6/22 - loss 0.31224025 - samples/sec: 127.54\n",
            "2019-12-04 11:42:47,877 epoch 7 - iter 8/22 - loss 0.31747564 - samples/sec: 127.73\n",
            "2019-12-04 11:42:48,299 epoch 7 - iter 10/22 - loss 0.32769930 - samples/sec: 160.07\n",
            "2019-12-04 11:42:48,796 epoch 7 - iter 12/22 - loss 0.32916114 - samples/sec: 134.93\n",
            "2019-12-04 11:42:49,473 epoch 7 - iter 14/22 - loss 0.32007305 - samples/sec: 99.17\n",
            "2019-12-04 11:42:50,124 epoch 7 - iter 16/22 - loss 0.32310179 - samples/sec: 102.95\n",
            "2019-12-04 11:42:50,684 epoch 7 - iter 18/22 - loss 0.34541969 - samples/sec: 121.03\n",
            "2019-12-04 11:42:51,248 epoch 7 - iter 20/22 - loss 0.35076944 - samples/sec: 119.41\n",
            "2019-12-04 11:42:51,640 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:51,642 EPOCH 7 done: loss 0.3516 - lr 0.1000\n",
            "2019-12-04 11:42:53,267 DEV : loss 0.8059436678886414 - score 0.7294\n",
            "2019-12-04 11:42:53,342 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:42:53,344 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:42:54,304 epoch 8 - iter 0/22 - loss 0.38228914 - samples/sec: 169.01\n",
            "2019-12-04 11:42:54,872 epoch 8 - iter 2/22 - loss 0.37793403 - samples/sec: 121.46\n",
            "2019-12-04 11:42:55,480 epoch 8 - iter 4/22 - loss 0.37220655 - samples/sec: 113.76\n",
            "2019-12-04 11:42:56,078 epoch 8 - iter 6/22 - loss 0.33606647 - samples/sec: 116.01\n",
            "2019-12-04 11:42:58,744 epoch 8 - iter 8/22 - loss 0.35046438 - samples/sec: 24.21\n",
            "2019-12-04 11:42:59,126 epoch 8 - iter 10/22 - loss 0.35584027 - samples/sec: 186.37\n",
            "2019-12-04 11:42:59,574 epoch 8 - iter 12/22 - loss 0.36349380 - samples/sec: 152.86\n",
            "2019-12-04 11:43:00,058 epoch 8 - iter 14/22 - loss 0.35802400 - samples/sec: 144.97\n",
            "2019-12-04 11:43:00,412 epoch 8 - iter 16/22 - loss 0.39003965 - samples/sec: 192.27\n",
            "2019-12-04 11:43:00,832 epoch 8 - iter 18/22 - loss 0.40762819 - samples/sec: 163.60\n",
            "2019-12-04 11:43:01,235 epoch 8 - iter 20/22 - loss 0.40374798 - samples/sec: 171.81\n",
            "2019-12-04 11:43:01,616 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:01,621 EPOCH 8 done: loss 0.3940 - lr 0.1000\n",
            "2019-12-04 11:43:03,069 DEV : loss 0.4459275007247925 - score 0.7882\n",
            "2019-12-04 11:43:03,139 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:43:03,141 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:04,078 epoch 9 - iter 0/22 - loss 0.33194107 - samples/sec: 190.71\n",
            "2019-12-04 11:43:04,690 epoch 9 - iter 2/22 - loss 0.24688419 - samples/sec: 113.51\n",
            "2019-12-04 11:43:05,228 epoch 9 - iter 4/22 - loss 0.31421754 - samples/sec: 127.14\n",
            "2019-12-04 11:43:05,743 epoch 9 - iter 6/22 - loss 0.32771704 - samples/sec: 136.87\n",
            "2019-12-04 11:43:06,251 epoch 9 - iter 8/22 - loss 0.33913444 - samples/sec: 139.61\n",
            "2019-12-04 11:43:06,800 epoch 9 - iter 10/22 - loss 0.31431071 - samples/sec: 133.17\n",
            "2019-12-04 11:43:07,284 epoch 9 - iter 12/22 - loss 0.32302757 - samples/sec: 144.26\n",
            "2019-12-04 11:43:07,840 epoch 9 - iter 14/22 - loss 0.32013969 - samples/sec: 121.33\n",
            "2019-12-04 11:43:08,379 epoch 9 - iter 16/22 - loss 0.31816431 - samples/sec: 125.67\n",
            "2019-12-04 11:43:08,893 epoch 9 - iter 18/22 - loss 0.32525219 - samples/sec: 134.36\n",
            "2019-12-04 11:43:09,344 epoch 9 - iter 20/22 - loss 0.34394862 - samples/sec: 150.95\n",
            "2019-12-04 11:43:09,717 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:09,719 EPOCH 9 done: loss 0.3312 - lr 0.1000\n",
            "2019-12-04 11:43:11,201 DEV : loss 0.3514760434627533 - score 0.8588\n",
            "2019-12-04 11:43:11,291 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:43:14,621 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:15,582 epoch 10 - iter 0/22 - loss 0.20073915 - samples/sec: 176.41\n",
            "2019-12-04 11:43:16,099 epoch 10 - iter 2/22 - loss 0.22857086 - samples/sec: 137.93\n",
            "2019-12-04 11:43:16,638 epoch 10 - iter 4/22 - loss 0.26619911 - samples/sec: 127.36\n",
            "2019-12-04 11:43:17,184 epoch 10 - iter 6/22 - loss 0.29154728 - samples/sec: 127.00\n",
            "2019-12-04 11:43:17,737 epoch 10 - iter 8/22 - loss 0.35239820 - samples/sec: 127.53\n",
            "2019-12-04 11:43:18,165 epoch 10 - iter 10/22 - loss 0.36671737 - samples/sec: 164.30\n",
            "2019-12-04 11:43:18,674 epoch 10 - iter 12/22 - loss 0.33104167 - samples/sec: 139.51\n",
            "2019-12-04 11:43:19,164 epoch 10 - iter 14/22 - loss 0.32489489 - samples/sec: 138.28\n",
            "2019-12-04 11:43:19,746 epoch 10 - iter 16/22 - loss 0.33589288 - samples/sec: 115.33\n",
            "2019-12-04 11:43:20,182 epoch 10 - iter 18/22 - loss 0.32852212 - samples/sec: 161.45\n",
            "2019-12-04 11:43:20,622 epoch 10 - iter 20/22 - loss 0.33721403 - samples/sec: 152.97\n",
            "2019-12-04 11:43:20,990 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:20,992 EPOCH 10 done: loss 0.3497 - lr 0.1000\n",
            "2019-12-04 11:43:22,425 DEV : loss 0.8274669647216797 - score 0.7059\n",
            "2019-12-04 11:43:22,515 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:43:25,818 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:25,819 Testing using best model ...\n",
            "2019-12-04 11:43:25,821 loading file test_csv/mix10/best-model.pt\n",
            "2019-12-04 11:43:28,990 0.8333\t0.8333\t0.8333\n",
            "2019-12-04 11:43:28,997 \n",
            "MICRO_AVG: acc 0.7143 - f1-score 0.8333\n",
            "MACRO_AVG: acc 0.6961 - f1-score 0.8185\n",
            "fake       tp: 23 - fp: 6 - fn: 8 - tn: 47 - precision: 0.7931 - recall: 0.7419 - accuracy: 0.6216 - f1-score: 0.7666\n",
            "real       tp: 47 - fp: 8 - fn: 6 - tn: 23 - precision: 0.8545 - recall: 0.8868 - accuracy: 0.7705 - f1-score: 0.8704\n",
            "2019-12-04 11:43:28,998 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:29,002 loading file ./test_csv/mix10/best-model.pt\n",
            "acc:  0.8113207547169812\n",
            "precision:  0.8085106382978723\n",
            "recall:  0.7755102040816326\n",
            "f1:  0.7916666666666665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQQWX7A0LgwA",
        "colab_type": "code",
        "outputId": "7fafa21e-1ff1-4604-8fd5-b1d786ecbf82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/title50'\n",
        "make_test(train_title, test_title, path, path, 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:43:34,623 Reading data from test_csv/title50\n",
            "2019-12-04 11:43:34,625 Train: test_csv/title50/train.csv\n",
            "2019-12-04 11:43:34,626 Dev: test_csv/title50/dev.csv\n",
            "2019-12-04 11:43:34,627 Test: test_csv/title50/test.csv\n",
            "2019-12-04 11:43:34,634 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 675/675 [00:00<00:00, 808.07it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:43:36,154 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:43:37,223 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:37,225 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:43:37,230 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:37,235 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
            "2019-12-04 11:43:37,239 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:37,242 Parameters:\n",
            "2019-12-04 11:43:37,245  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:43:37,247  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:43:37,248  - patience: \"3\"\n",
            "2019-12-04 11:43:37,251  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:43:37,254  - max_epochs: \"50\"\n",
            "2019-12-04 11:43:37,255  - shuffle: \"True\"\n",
            "2019-12-04 11:43:37,258  - train_with_dev: \"False\"\n",
            "2019-12-04 11:43:37,260  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:43:37,263 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:37,265 Model training base path: \"test_csv/title50\"\n",
            "2019-12-04 11:43:37,267 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:37,268 Device: cuda:0\n",
            "2019-12-04 11:43:37,270 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:37,272 Embeddings storage mode: cpu\n",
            "2019-12-04 11:43:37,275 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:38,066 epoch 1 - iter 0/22 - loss 0.70312560 - samples/sec: 372.46\n",
            "2019-12-04 11:43:38,355 epoch 1 - iter 2/22 - loss 0.71921055 - samples/sec: 252.02\n",
            "2019-12-04 11:43:38,951 epoch 1 - iter 4/22 - loss 0.68663688 - samples/sec: 114.86\n",
            "2019-12-04 11:43:39,297 epoch 1 - iter 6/22 - loss 0.67097557 - samples/sec: 217.19\n",
            "2019-12-04 11:43:39,604 epoch 1 - iter 8/22 - loss 0.65625967 - samples/sec: 230.18\n",
            "2019-12-04 11:43:39,900 epoch 1 - iter 10/22 - loss 0.65860040 - samples/sec: 246.96\n",
            "2019-12-04 11:43:40,224 epoch 1 - iter 12/22 - loss 0.65488865 - samples/sec: 228.39\n",
            "2019-12-04 11:43:40,778 epoch 1 - iter 14/22 - loss 0.65642333 - samples/sec: 122.65\n",
            "2019-12-04 11:43:41,063 epoch 1 - iter 16/22 - loss 0.63809149 - samples/sec: 255.57\n",
            "2019-12-04 11:43:41,335 epoch 1 - iter 18/22 - loss 0.63059462 - samples/sec: 265.51\n",
            "2019-12-04 11:43:41,567 epoch 1 - iter 20/22 - loss 0.61805125 - samples/sec: 306.46\n",
            "2019-12-04 11:43:41,923 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:41,924 EPOCH 1 done: loss 0.6238 - lr 0.1000\n",
            "2019-12-04 11:43:43,104 DEV : loss 0.6054107546806335 - score 0.6941\n",
            "2019-12-04 11:43:43,154 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:43:46,574 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:47,341 epoch 2 - iter 0/22 - loss 0.42676669 - samples/sec: 286.58\n",
            "2019-12-04 11:43:47,716 epoch 2 - iter 2/22 - loss 0.46213836 - samples/sec: 204.57\n",
            "2019-12-04 11:43:47,967 epoch 2 - iter 4/22 - loss 0.49009652 - samples/sec: 288.77\n",
            "2019-12-04 11:43:48,206 epoch 2 - iter 6/22 - loss 0.50464803 - samples/sec: 297.92\n",
            "2019-12-04 11:43:48,450 epoch 2 - iter 8/22 - loss 0.50143387 - samples/sec: 311.71\n",
            "2019-12-04 11:43:48,671 epoch 2 - iter 10/22 - loss 0.51677523 - samples/sec: 323.67\n",
            "2019-12-04 11:43:48,892 epoch 2 - iter 12/22 - loss 0.51237541 - samples/sec: 321.45\n",
            "2019-12-04 11:43:49,093 epoch 2 - iter 14/22 - loss 0.49757318 - samples/sec: 384.27\n",
            "2019-12-04 11:43:49,298 epoch 2 - iter 16/22 - loss 0.48894718 - samples/sec: 352.00\n",
            "2019-12-04 11:43:49,542 epoch 2 - iter 18/22 - loss 0.48483993 - samples/sec: 297.70\n",
            "2019-12-04 11:43:49,822 epoch 2 - iter 20/22 - loss 0.46856905 - samples/sec: 257.91\n",
            "2019-12-04 11:43:50,145 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:50,148 EPOCH 2 done: loss 0.4609 - lr 0.1000\n",
            "2019-12-04 11:43:51,272 DEV : loss 0.4955545663833618 - score 0.7647\n",
            "2019-12-04 11:43:51,334 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:43:54,751 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:55,540 epoch 3 - iter 0/22 - loss 0.39120662 - samples/sec: 288.91\n",
            "2019-12-04 11:43:55,813 epoch 3 - iter 2/22 - loss 0.39757721 - samples/sec: 287.50\n",
            "2019-12-04 11:43:56,043 epoch 3 - iter 4/22 - loss 0.40781687 - samples/sec: 320.54\n",
            "2019-12-04 11:43:56,292 epoch 3 - iter 6/22 - loss 0.46787720 - samples/sec: 297.00\n",
            "2019-12-04 11:43:56,551 epoch 3 - iter 8/22 - loss 0.47363662 - samples/sec: 288.70\n",
            "2019-12-04 11:43:56,779 epoch 3 - iter 10/22 - loss 0.46431175 - samples/sec: 314.03\n",
            "2019-12-04 11:43:56,995 epoch 3 - iter 12/22 - loss 0.43941972 - samples/sec: 329.59\n",
            "2019-12-04 11:43:57,198 epoch 3 - iter 14/22 - loss 0.42833439 - samples/sec: 355.53\n",
            "2019-12-04 11:43:57,432 epoch 3 - iter 16/22 - loss 0.43499056 - samples/sec: 312.66\n",
            "2019-12-04 11:43:57,687 epoch 3 - iter 18/22 - loss 0.42775416 - samples/sec: 275.36\n",
            "2019-12-04 11:43:57,958 epoch 3 - iter 20/22 - loss 0.43124644 - samples/sec: 273.81\n",
            "2019-12-04 11:43:58,253 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:43:58,257 EPOCH 3 done: loss 0.4163 - lr 0.1000\n",
            "2019-12-04 11:43:59,319 DEV : loss 0.5580081343650818 - score 0.7529\n",
            "2019-12-04 11:43:59,368 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:43:59,369 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:00,069 epoch 4 - iter 0/22 - loss 0.37044084 - samples/sec: 374.04\n",
            "2019-12-04 11:44:00,318 epoch 4 - iter 2/22 - loss 0.47350856 - samples/sec: 308.32\n",
            "2019-12-04 11:44:00,582 epoch 4 - iter 4/22 - loss 0.42278374 - samples/sec: 281.01\n",
            "2019-12-04 11:44:00,866 epoch 4 - iter 6/22 - loss 0.39775464 - samples/sec: 246.07\n",
            "2019-12-04 11:44:01,135 epoch 4 - iter 8/22 - loss 0.38557169 - samples/sec: 265.34\n",
            "2019-12-04 11:44:01,390 epoch 4 - iter 10/22 - loss 0.38280271 - samples/sec: 295.22\n",
            "2019-12-04 11:44:01,676 epoch 4 - iter 12/22 - loss 0.40986809 - samples/sec: 247.92\n",
            "2019-12-04 11:44:01,916 epoch 4 - iter 14/22 - loss 0.43967982 - samples/sec: 300.82\n",
            "2019-12-04 11:44:02,192 epoch 4 - iter 16/22 - loss 0.45495051 - samples/sec: 270.76\n",
            "2019-12-04 11:44:02,463 epoch 4 - iter 18/22 - loss 0.44321620 - samples/sec: 261.57\n",
            "2019-12-04 11:44:02,705 epoch 4 - iter 20/22 - loss 0.43950394 - samples/sec: 297.67\n",
            "2019-12-04 11:44:03,033 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:03,038 EPOCH 4 done: loss 0.4390 - lr 0.1000\n",
            "2019-12-04 11:44:04,133 DEV : loss 0.8941941261291504 - score 0.6824\n",
            "2019-12-04 11:44:04,188 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:44:04,191 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:04,884 epoch 5 - iter 0/22 - loss 0.77949822 - samples/sec: 422.39\n",
            "2019-12-04 11:44:05,140 epoch 5 - iter 2/22 - loss 0.50701119 - samples/sec: 293.65\n",
            "2019-12-04 11:44:05,364 epoch 5 - iter 4/22 - loss 0.46662148 - samples/sec: 340.34\n",
            "2019-12-04 11:44:05,640 epoch 5 - iter 6/22 - loss 0.42492322 - samples/sec: 254.46\n",
            "2019-12-04 11:44:05,891 epoch 5 - iter 8/22 - loss 0.41744574 - samples/sec: 286.57\n",
            "2019-12-04 11:44:06,105 epoch 5 - iter 10/22 - loss 0.39972171 - samples/sec: 350.91\n",
            "2019-12-04 11:44:06,344 epoch 5 - iter 12/22 - loss 0.41309379 - samples/sec: 311.34\n",
            "2019-12-04 11:44:06,618 epoch 5 - iter 14/22 - loss 0.40030393 - samples/sec: 263.13\n",
            "2019-12-04 11:44:06,898 epoch 5 - iter 16/22 - loss 0.40842112 - samples/sec: 252.41\n",
            "2019-12-04 11:44:07,170 epoch 5 - iter 18/22 - loss 0.39010840 - samples/sec: 266.43\n",
            "2019-12-04 11:44:08,629 epoch 5 - iter 20/22 - loss 0.38600331 - samples/sec: 44.68\n",
            "2019-12-04 11:44:08,956 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:08,958 EPOCH 5 done: loss 0.4011 - lr 0.1000\n",
            "2019-12-04 11:44:10,103 DEV : loss 0.9547998309135437 - score 0.6471\n",
            "2019-12-04 11:44:10,155 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:44:10,156 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:10,829 epoch 6 - iter 0/22 - loss 0.77780682 - samples/sec: 431.15\n",
            "2019-12-04 11:44:11,071 epoch 6 - iter 2/22 - loss 0.44872463 - samples/sec: 302.85\n",
            "2019-12-04 11:44:11,317 epoch 6 - iter 4/22 - loss 0.45249280 - samples/sec: 299.32\n",
            "2019-12-04 11:44:11,586 epoch 6 - iter 6/22 - loss 0.40918635 - samples/sec: 269.43\n",
            "2019-12-04 11:44:11,854 epoch 6 - iter 8/22 - loss 0.40073078 - samples/sec: 268.16\n",
            "2019-12-04 11:44:12,065 epoch 6 - iter 10/22 - loss 0.38443476 - samples/sec: 354.51\n",
            "2019-12-04 11:44:12,290 epoch 6 - iter 12/22 - loss 0.37483016 - samples/sec: 325.49\n",
            "2019-12-04 11:44:12,537 epoch 6 - iter 14/22 - loss 0.36843848 - samples/sec: 301.38\n",
            "2019-12-04 11:44:12,795 epoch 6 - iter 16/22 - loss 0.35183252 - samples/sec: 272.26\n",
            "2019-12-04 11:44:13,019 epoch 6 - iter 18/22 - loss 0.35511141 - samples/sec: 322.64\n",
            "2019-12-04 11:44:13,218 epoch 6 - iter 20/22 - loss 0.35219007 - samples/sec: 361.13\n",
            "2019-12-04 11:44:13,533 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:13,539 EPOCH 6 done: loss 0.3483 - lr 0.1000\n",
            "2019-12-04 11:44:14,639 DEV : loss 0.4633703827857971 - score 0.8118\n",
            "2019-12-04 11:44:14,689 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:44:18,049 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:18,763 epoch 7 - iter 0/22 - loss 0.16017739 - samples/sec: 294.35\n",
            "2019-12-04 11:44:19,047 epoch 7 - iter 2/22 - loss 0.35473099 - samples/sec: 270.36\n",
            "2019-12-04 11:44:19,348 epoch 7 - iter 4/22 - loss 0.33150429 - samples/sec: 237.96\n",
            "2019-12-04 11:44:19,637 epoch 7 - iter 6/22 - loss 0.35966635 - samples/sec: 251.63\n",
            "2019-12-04 11:44:19,907 epoch 7 - iter 8/22 - loss 0.38135526 - samples/sec: 276.05\n",
            "2019-12-04 11:44:20,224 epoch 7 - iter 10/22 - loss 0.35484895 - samples/sec: 235.95\n",
            "2019-12-04 11:44:20,476 epoch 7 - iter 12/22 - loss 0.36862376 - samples/sec: 284.96\n",
            "2019-12-04 11:44:20,747 epoch 7 - iter 14/22 - loss 0.36649169 - samples/sec: 263.15\n",
            "2019-12-04 11:44:21,010 epoch 7 - iter 16/22 - loss 0.35684311 - samples/sec: 280.10\n",
            "2019-12-04 11:44:21,290 epoch 7 - iter 18/22 - loss 0.34892637 - samples/sec: 253.68\n",
            "2019-12-04 11:44:21,567 epoch 7 - iter 20/22 - loss 0.34372239 - samples/sec: 263.75\n",
            "2019-12-04 11:44:21,895 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:21,899 EPOCH 7 done: loss 0.3372 - lr 0.1000\n",
            "2019-12-04 11:44:22,984 DEV : loss 0.4421626329421997 - score 0.8118\n",
            "2019-12-04 11:44:23,034 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:44:26,430 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:27,154 epoch 8 - iter 0/22 - loss 0.29969680 - samples/sec: 334.37\n",
            "2019-12-04 11:44:27,480 epoch 8 - iter 2/22 - loss 0.35826835 - samples/sec: 230.52\n",
            "2019-12-04 11:44:27,812 epoch 8 - iter 4/22 - loss 0.39621528 - samples/sec: 213.75\n",
            "2019-12-04 11:44:28,020 epoch 8 - iter 6/22 - loss 0.35426851 - samples/sec: 382.38\n",
            "2019-12-04 11:44:28,296 epoch 8 - iter 8/22 - loss 0.35890446 - samples/sec: 255.15\n",
            "2019-12-04 11:44:28,510 epoch 8 - iter 10/22 - loss 0.34676752 - samples/sec: 335.39\n",
            "2019-12-04 11:44:28,743 epoch 8 - iter 12/22 - loss 0.34176960 - samples/sec: 322.29\n",
            "2019-12-04 11:44:28,932 epoch 8 - iter 14/22 - loss 0.34090608 - samples/sec: 384.11\n",
            "2019-12-04 11:44:29,143 epoch 8 - iter 16/22 - loss 0.32191573 - samples/sec: 339.12\n",
            "2019-12-04 11:44:29,456 epoch 8 - iter 18/22 - loss 0.33636886 - samples/sec: 230.47\n",
            "2019-12-04 11:44:29,663 epoch 8 - iter 20/22 - loss 0.34533658 - samples/sec: 346.23\n",
            "2019-12-04 11:44:29,997 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:29,999 EPOCH 8 done: loss 0.3323 - lr 0.1000\n",
            "2019-12-04 11:44:31,074 DEV : loss 0.8691219687461853 - score 0.7059\n",
            "2019-12-04 11:44:31,120 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:44:31,122 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:31,813 epoch 9 - iter 0/22 - loss 0.36569354 - samples/sec: 360.24\n",
            "2019-12-04 11:44:32,065 epoch 9 - iter 2/22 - loss 0.26188299 - samples/sec: 297.62\n",
            "2019-12-04 11:44:32,316 epoch 9 - iter 4/22 - loss 0.27680112 - samples/sec: 302.31\n",
            "2019-12-04 11:44:32,589 epoch 9 - iter 6/22 - loss 0.29013972 - samples/sec: 255.58\n",
            "2019-12-04 11:44:32,854 epoch 9 - iter 8/22 - loss 0.35429008 - samples/sec: 271.05\n",
            "2019-12-04 11:44:33,109 epoch 9 - iter 10/22 - loss 0.33861734 - samples/sec: 297.44\n",
            "2019-12-04 11:44:33,374 epoch 9 - iter 12/22 - loss 0.31110219 - samples/sec: 277.04\n",
            "2019-12-04 11:44:33,614 epoch 9 - iter 14/22 - loss 0.31856311 - samples/sec: 293.03\n",
            "2019-12-04 11:44:33,828 epoch 9 - iter 16/22 - loss 0.31731452 - samples/sec: 339.94\n",
            "2019-12-04 11:44:34,060 epoch 9 - iter 18/22 - loss 0.31120200 - samples/sec: 318.08\n",
            "2019-12-04 11:44:34,319 epoch 9 - iter 20/22 - loss 0.31287270 - samples/sec: 272.64\n",
            "2019-12-04 11:44:34,639 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:34,641 EPOCH 9 done: loss 0.3206 - lr 0.1000\n",
            "2019-12-04 11:44:35,785 DEV : loss 0.7776205539703369 - score 0.7294\n",
            "2019-12-04 11:44:35,827 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:44:35,829 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:36,566 epoch 10 - iter 0/22 - loss 0.66527879 - samples/sec: 309.91\n",
            "2019-12-04 11:44:36,859 epoch 10 - iter 2/22 - loss 0.40903366 - samples/sec: 262.56\n",
            "2019-12-04 11:44:37,160 epoch 10 - iter 4/22 - loss 0.35251010 - samples/sec: 233.98\n",
            "2019-12-04 11:44:37,420 epoch 10 - iter 6/22 - loss 0.32262532 - samples/sec: 275.03\n",
            "2019-12-04 11:44:37,689 epoch 10 - iter 8/22 - loss 0.30698003 - samples/sec: 276.51\n",
            "2019-12-04 11:44:37,955 epoch 10 - iter 10/22 - loss 0.28370882 - samples/sec: 283.52\n",
            "2019-12-04 11:44:38,163 epoch 10 - iter 12/22 - loss 0.29189516 - samples/sec: 344.74\n",
            "2019-12-04 11:44:38,382 epoch 10 - iter 14/22 - loss 0.29870431 - samples/sec: 328.92\n",
            "2019-12-04 11:44:38,611 epoch 10 - iter 16/22 - loss 0.29869646 - samples/sec: 320.05\n",
            "2019-12-04 11:44:38,825 epoch 10 - iter 18/22 - loss 0.29787812 - samples/sec: 330.48\n",
            "2019-12-04 11:44:39,084 epoch 10 - iter 20/22 - loss 0.29475987 - samples/sec: 278.69\n",
            "2019-12-04 11:44:39,402 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:39,405 EPOCH 10 done: loss 0.2850 - lr 0.1000\n",
            "2019-12-04 11:44:40,533 DEV : loss 0.37293970584869385 - score 0.8588\n",
            "2019-12-04 11:44:40,588 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:44:43,937 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:44,745 epoch 11 - iter 0/22 - loss 0.39424220 - samples/sec: 398.68\n",
            "2019-12-04 11:44:44,998 epoch 11 - iter 2/22 - loss 0.27498354 - samples/sec: 285.57\n",
            "2019-12-04 11:44:45,252 epoch 11 - iter 4/22 - loss 0.25035770 - samples/sec: 275.82\n",
            "2019-12-04 11:44:45,560 epoch 11 - iter 6/22 - loss 0.22724648 - samples/sec: 251.06\n",
            "2019-12-04 11:44:45,846 epoch 11 - iter 8/22 - loss 0.23797289 - samples/sec: 248.64\n",
            "2019-12-04 11:44:46,083 epoch 11 - iter 10/22 - loss 0.25747692 - samples/sec: 297.13\n",
            "2019-12-04 11:44:46,303 epoch 11 - iter 12/22 - loss 0.25935198 - samples/sec: 333.72\n",
            "2019-12-04 11:44:46,581 epoch 11 - iter 14/22 - loss 0.36455137 - samples/sec: 251.96\n",
            "2019-12-04 11:44:46,835 epoch 11 - iter 16/22 - loss 0.35731549 - samples/sec: 291.81\n",
            "2019-12-04 11:44:47,067 epoch 11 - iter 18/22 - loss 0.34587143 - samples/sec: 319.62\n",
            "2019-12-04 11:44:47,304 epoch 11 - iter 20/22 - loss 0.33779651 - samples/sec: 307.18\n",
            "2019-12-04 11:44:47,654 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:47,657 EPOCH 11 done: loss 0.3430 - lr 0.1000\n",
            "2019-12-04 11:44:48,712 DEV : loss 0.49296367168426514 - score 0.8\n",
            "2019-12-04 11:44:48,769 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:44:48,771 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:49,486 epoch 12 - iter 0/22 - loss 0.38909122 - samples/sec: 328.70\n",
            "2019-12-04 11:44:49,775 epoch 12 - iter 2/22 - loss 0.33208196 - samples/sec: 259.84\n",
            "2019-12-04 11:44:50,000 epoch 12 - iter 4/22 - loss 0.28858893 - samples/sec: 332.55\n",
            "2019-12-04 11:44:50,254 epoch 12 - iter 6/22 - loss 0.32325271 - samples/sec: 293.13\n",
            "2019-12-04 11:44:50,497 epoch 12 - iter 8/22 - loss 0.30234372 - samples/sec: 289.68\n",
            "2019-12-04 11:44:50,769 epoch 12 - iter 10/22 - loss 0.28114575 - samples/sec: 259.39\n",
            "2019-12-04 11:44:51,004 epoch 12 - iter 12/22 - loss 0.29692678 - samples/sec: 315.73\n",
            "2019-12-04 11:44:51,220 epoch 12 - iter 14/22 - loss 0.29274426 - samples/sec: 328.20\n",
            "2019-12-04 11:44:51,463 epoch 12 - iter 16/22 - loss 0.29513596 - samples/sec: 288.12\n",
            "2019-12-04 11:44:51,744 epoch 12 - iter 18/22 - loss 0.28405505 - samples/sec: 270.84\n",
            "2019-12-04 11:44:51,981 epoch 12 - iter 20/22 - loss 0.28770701 - samples/sec: 307.54\n",
            "2019-12-04 11:44:52,305 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:52,306 EPOCH 12 done: loss 0.2769 - lr 0.1000\n",
            "2019-12-04 11:44:53,371 DEV : loss 0.35305434465408325 - score 0.8471\n",
            "2019-12-04 11:44:53,423 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:44:53,425 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:54,127 epoch 13 - iter 0/22 - loss 0.25423309 - samples/sec: 385.62\n",
            "2019-12-04 11:44:54,339 epoch 13 - iter 2/22 - loss 0.26104290 - samples/sec: 348.07\n",
            "2019-12-04 11:44:54,590 epoch 13 - iter 4/22 - loss 0.25366309 - samples/sec: 311.94\n",
            "2019-12-04 11:44:54,881 epoch 13 - iter 6/22 - loss 0.27191364 - samples/sec: 242.68\n",
            "2019-12-04 11:44:55,144 epoch 13 - iter 8/22 - loss 0.28037646 - samples/sec: 272.56\n",
            "2019-12-04 11:44:55,436 epoch 13 - iter 10/22 - loss 0.26782754 - samples/sec: 251.07\n",
            "2019-12-04 11:44:55,703 epoch 13 - iter 12/22 - loss 0.28091098 - samples/sec: 270.25\n",
            "2019-12-04 11:44:55,983 epoch 13 - iter 14/22 - loss 0.28926408 - samples/sec: 253.75\n",
            "2019-12-04 11:44:56,273 epoch 13 - iter 16/22 - loss 0.30239235 - samples/sec: 256.15\n",
            "2019-12-04 11:44:56,548 epoch 13 - iter 18/22 - loss 0.29750758 - samples/sec: 257.32\n",
            "2019-12-04 11:44:56,800 epoch 13 - iter 20/22 - loss 0.29015548 - samples/sec: 290.35\n",
            "2019-12-04 11:44:57,124 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:57,133 EPOCH 13 done: loss 0.2802 - lr 0.1000\n",
            "2019-12-04 11:44:58,251 DEV : loss 0.4240419566631317 - score 0.8118\n",
            "2019-12-04 11:44:58,304 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:44:58,306 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:44:59,002 epoch 14 - iter 0/22 - loss 0.30097201 - samples/sec: 348.22\n",
            "2019-12-04 11:44:59,286 epoch 14 - iter 2/22 - loss 0.32898029 - samples/sec: 253.70\n",
            "2019-12-04 11:44:59,562 epoch 14 - iter 4/22 - loss 0.29246691 - samples/sec: 279.09\n",
            "2019-12-04 11:44:59,864 epoch 14 - iter 6/22 - loss 0.28048967 - samples/sec: 235.92\n",
            "2019-12-04 11:45:00,095 epoch 14 - iter 8/22 - loss 0.26365275 - samples/sec: 310.83\n",
            "2019-12-04 11:45:00,336 epoch 14 - iter 10/22 - loss 0.26579703 - samples/sec: 329.71\n",
            "2019-12-04 11:45:00,539 epoch 14 - iter 12/22 - loss 0.24897645 - samples/sec: 355.99\n",
            "2019-12-04 11:45:00,763 epoch 14 - iter 14/22 - loss 0.24515216 - samples/sec: 318.98\n",
            "2019-12-04 11:45:01,009 epoch 14 - iter 16/22 - loss 0.24318239 - samples/sec: 288.22\n",
            "2019-12-04 11:45:01,246 epoch 14 - iter 18/22 - loss 0.24929898 - samples/sec: 304.54\n",
            "2019-12-04 11:45:01,560 epoch 14 - iter 20/22 - loss 0.25176152 - samples/sec: 223.49\n",
            "2019-12-04 11:45:01,901 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:01,903 EPOCH 14 done: loss 0.2585 - lr 0.1000\n",
            "2019-12-04 11:45:03,096 DEV : loss 1.001357913017273 - score 0.6353\n",
            "Epoch    13: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-12-04 11:45:03,149 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:45:03,152 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:03,832 epoch 15 - iter 0/22 - loss 0.91437173 - samples/sec: 429.35\n",
            "2019-12-04 11:45:04,072 epoch 15 - iter 2/22 - loss 0.40770817 - samples/sec: 299.53\n",
            "2019-12-04 11:45:04,317 epoch 15 - iter 4/22 - loss 0.32064155 - samples/sec: 296.90\n",
            "2019-12-04 11:45:04,621 epoch 15 - iter 6/22 - loss 0.26856197 - samples/sec: 259.45\n",
            "2019-12-04 11:45:04,900 epoch 15 - iter 8/22 - loss 0.26918656 - samples/sec: 255.09\n",
            "2019-12-04 11:45:05,149 epoch 15 - iter 10/22 - loss 0.25912107 - samples/sec: 289.84\n",
            "2019-12-04 11:45:05,397 epoch 15 - iter 12/22 - loss 0.24838406 - samples/sec: 294.83\n",
            "2019-12-04 11:45:05,705 epoch 15 - iter 14/22 - loss 0.24773570 - samples/sec: 230.26\n",
            "2019-12-04 11:45:05,932 epoch 15 - iter 16/22 - loss 0.25834079 - samples/sec: 321.77\n",
            "2019-12-04 11:45:06,155 epoch 15 - iter 18/22 - loss 0.24622284 - samples/sec: 340.25\n",
            "2019-12-04 11:45:06,424 epoch 15 - iter 20/22 - loss 0.24852986 - samples/sec: 258.75\n",
            "2019-12-04 11:45:06,758 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:06,760 EPOCH 15 done: loss 0.2402 - lr 0.0500\n",
            "2019-12-04 11:45:07,870 DEV : loss 0.37329715490341187 - score 0.8706\n",
            "2019-12-04 11:45:07,918 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:45:11,336 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:12,123 epoch 16 - iter 0/22 - loss 0.30408511 - samples/sec: 398.29\n",
            "2019-12-04 11:45:12,352 epoch 16 - iter 2/22 - loss 0.22685468 - samples/sec: 321.79\n",
            "2019-12-04 11:45:12,575 epoch 16 - iter 4/22 - loss 0.24371760 - samples/sec: 352.25\n",
            "2019-12-04 11:45:12,867 epoch 16 - iter 6/22 - loss 0.24316025 - samples/sec: 250.56\n",
            "2019-12-04 11:45:13,173 epoch 16 - iter 8/22 - loss 0.23802867 - samples/sec: 229.64\n",
            "2019-12-04 11:45:13,425 epoch 16 - iter 10/22 - loss 0.23285344 - samples/sec: 292.05\n",
            "2019-12-04 11:45:13,683 epoch 16 - iter 12/22 - loss 0.22492533 - samples/sec: 273.56\n",
            "2019-12-04 11:45:13,924 epoch 16 - iter 14/22 - loss 0.24293686 - samples/sec: 299.72\n",
            "2019-12-04 11:45:14,127 epoch 16 - iter 16/22 - loss 0.22979603 - samples/sec: 369.16\n",
            "2019-12-04 11:45:14,356 epoch 16 - iter 18/22 - loss 0.21150661 - samples/sec: 310.38\n",
            "2019-12-04 11:45:14,564 epoch 16 - iter 20/22 - loss 0.21390673 - samples/sec: 342.64\n",
            "2019-12-04 11:45:14,873 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:14,878 EPOCH 16 done: loss 0.2416 - lr 0.0500\n",
            "2019-12-04 11:45:18,401 DEV : loss 0.6089092493057251 - score 0.7765\n",
            "2019-12-04 11:45:18,460 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:45:18,462 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:19,216 epoch 17 - iter 0/22 - loss 0.52962381 - samples/sec: 272.34\n",
            "2019-12-04 11:45:19,517 epoch 17 - iter 2/22 - loss 0.28436618 - samples/sec: 251.64\n",
            "2019-12-04 11:45:19,803 epoch 17 - iter 4/22 - loss 0.26975915 - samples/sec: 259.98\n",
            "2019-12-04 11:45:20,039 epoch 17 - iter 6/22 - loss 0.30031005 - samples/sec: 311.70\n",
            "2019-12-04 11:45:20,331 epoch 17 - iter 8/22 - loss 0.28643923 - samples/sec: 247.77\n",
            "2019-12-04 11:45:20,632 epoch 17 - iter 10/22 - loss 0.30037960 - samples/sec: 237.75\n",
            "2019-12-04 11:45:20,877 epoch 17 - iter 12/22 - loss 0.28771951 - samples/sec: 310.96\n",
            "2019-12-04 11:45:21,142 epoch 17 - iter 14/22 - loss 0.27605105 - samples/sec: 274.74\n",
            "2019-12-04 11:45:21,410 epoch 17 - iter 16/22 - loss 0.27130928 - samples/sec: 266.16\n",
            "2019-12-04 11:45:21,681 epoch 17 - iter 18/22 - loss 0.26827050 - samples/sec: 267.80\n",
            "2019-12-04 11:45:21,925 epoch 17 - iter 20/22 - loss 0.26539815 - samples/sec: 299.83\n",
            "2019-12-04 11:45:22,247 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:22,252 EPOCH 17 done: loss 0.2624 - lr 0.0500\n",
            "2019-12-04 11:45:23,377 DEV : loss 0.4622739255428314 - score 0.8\n",
            "2019-12-04 11:45:23,425 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:45:23,426 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:24,157 epoch 18 - iter 0/22 - loss 0.31245163 - samples/sec: 497.41\n",
            "2019-12-04 11:45:24,477 epoch 18 - iter 2/22 - loss 0.22579348 - samples/sec: 218.81\n",
            "2019-12-04 11:45:24,764 epoch 18 - iter 4/22 - loss 0.19044712 - samples/sec: 268.63\n",
            "2019-12-04 11:45:24,999 epoch 18 - iter 6/22 - loss 0.18415366 - samples/sec: 301.78\n",
            "2019-12-04 11:45:25,240 epoch 18 - iter 8/22 - loss 0.20574648 - samples/sec: 298.70\n",
            "2019-12-04 11:45:25,495 epoch 18 - iter 10/22 - loss 0.20301471 - samples/sec: 307.68\n",
            "2019-12-04 11:45:25,746 epoch 18 - iter 12/22 - loss 0.19836907 - samples/sec: 280.89\n",
            "2019-12-04 11:45:25,996 epoch 18 - iter 14/22 - loss 0.19089380 - samples/sec: 281.93\n",
            "2019-12-04 11:45:26,206 epoch 18 - iter 16/22 - loss 0.19476279 - samples/sec: 348.07\n",
            "2019-12-04 11:45:26,436 epoch 18 - iter 18/22 - loss 0.19550087 - samples/sec: 310.69\n",
            "2019-12-04 11:45:26,751 epoch 18 - iter 20/22 - loss 0.20792682 - samples/sec: 228.21\n",
            "2019-12-04 11:45:27,060 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:27,064 EPOCH 18 done: loss 0.1986 - lr 0.0500\n",
            "2019-12-04 11:45:28,230 DEV : loss 0.3436862826347351 - score 0.8824\n",
            "2019-12-04 11:45:28,275 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:45:31,653 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:32,362 epoch 19 - iter 0/22 - loss 0.17490736 - samples/sec: 488.59\n",
            "2019-12-04 11:45:32,608 epoch 19 - iter 2/22 - loss 0.23738870 - samples/sec: 296.69\n",
            "2019-12-04 11:45:32,864 epoch 19 - iter 4/22 - loss 0.25208696 - samples/sec: 302.39\n",
            "2019-12-04 11:45:33,154 epoch 19 - iter 6/22 - loss 0.23876015 - samples/sec: 239.09\n",
            "2019-12-04 11:45:33,371 epoch 19 - iter 8/22 - loss 0.22285538 - samples/sec: 341.59\n",
            "2019-12-04 11:45:33,623 epoch 19 - iter 10/22 - loss 0.21785484 - samples/sec: 305.44\n",
            "2019-12-04 11:45:33,891 epoch 19 - iter 12/22 - loss 0.22080791 - samples/sec: 268.86\n",
            "2019-12-04 11:45:34,170 epoch 19 - iter 14/22 - loss 0.21809344 - samples/sec: 249.09\n",
            "2019-12-04 11:45:34,458 epoch 19 - iter 16/22 - loss 0.21131649 - samples/sec: 247.72\n",
            "2019-12-04 11:45:34,750 epoch 19 - iter 18/22 - loss 0.20691299 - samples/sec: 250.32\n",
            "2019-12-04 11:45:35,005 epoch 19 - iter 20/22 - loss 0.21253652 - samples/sec: 278.96\n",
            "2019-12-04 11:45:35,338 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:35,341 EPOCH 19 done: loss 0.2055 - lr 0.0500\n",
            "2019-12-04 11:45:36,500 DEV : loss 0.34903401136398315 - score 0.8471\n",
            "2019-12-04 11:45:36,553 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:45:36,554 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:37,297 epoch 20 - iter 0/22 - loss 0.21721525 - samples/sec: 277.40\n",
            "2019-12-04 11:45:37,580 epoch 20 - iter 2/22 - loss 0.20088618 - samples/sec: 273.52\n",
            "2019-12-04 11:45:37,848 epoch 20 - iter 4/22 - loss 0.20886076 - samples/sec: 267.17\n",
            "2019-12-04 11:45:38,120 epoch 20 - iter 6/22 - loss 0.21962336 - samples/sec: 269.25\n",
            "2019-12-04 11:45:38,340 epoch 20 - iter 8/22 - loss 0.21375778 - samples/sec: 360.17\n",
            "2019-12-04 11:45:38,582 epoch 20 - iter 10/22 - loss 0.21943585 - samples/sec: 303.10\n",
            "2019-12-04 11:45:38,822 epoch 20 - iter 12/22 - loss 0.22773659 - samples/sec: 294.03\n",
            "2019-12-04 11:45:39,055 epoch 20 - iter 14/22 - loss 0.22078501 - samples/sec: 311.17\n",
            "2019-12-04 11:45:39,363 epoch 20 - iter 16/22 - loss 0.22114977 - samples/sec: 238.96\n",
            "2019-12-04 11:45:39,673 epoch 20 - iter 18/22 - loss 0.21632639 - samples/sec: 226.73\n",
            "2019-12-04 11:45:39,924 epoch 20 - iter 20/22 - loss 0.21253716 - samples/sec: 290.41\n",
            "2019-12-04 11:45:40,248 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:40,253 EPOCH 20 done: loss 0.2032 - lr 0.0500\n",
            "2019-12-04 11:45:41,307 DEV : loss 0.3316185772418976 - score 0.8471\n",
            "2019-12-04 11:45:41,365 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:45:41,367 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:42,063 epoch 21 - iter 0/22 - loss 0.14591110 - samples/sec: 390.70\n",
            "2019-12-04 11:45:42,312 epoch 21 - iter 2/22 - loss 0.21159926 - samples/sec: 300.01\n",
            "2019-12-04 11:45:42,590 epoch 21 - iter 4/22 - loss 0.20610881 - samples/sec: 260.83\n",
            "2019-12-04 11:45:42,902 epoch 21 - iter 6/22 - loss 0.21693737 - samples/sec: 236.94\n",
            "2019-12-04 11:45:43,163 epoch 21 - iter 8/22 - loss 0.21613669 - samples/sec: 273.95\n",
            "2019-12-04 11:45:43,450 epoch 21 - iter 10/22 - loss 0.21172734 - samples/sec: 247.34\n",
            "2019-12-04 11:45:43,778 epoch 21 - iter 12/22 - loss 0.23138188 - samples/sec: 217.93\n",
            "2019-12-04 11:45:43,983 epoch 21 - iter 14/22 - loss 0.23362433 - samples/sec: 373.26\n",
            "2019-12-04 11:45:44,272 epoch 21 - iter 16/22 - loss 0.22205737 - samples/sec: 244.92\n",
            "2019-12-04 11:45:44,472 epoch 21 - iter 18/22 - loss 0.21358574 - samples/sec: 381.44\n",
            "2019-12-04 11:45:44,731 epoch 21 - iter 20/22 - loss 0.21061334 - samples/sec: 273.93\n",
            "2019-12-04 11:45:45,067 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:45,068 EPOCH 21 done: loss 0.2184 - lr 0.0500\n",
            "2019-12-04 11:45:46,203 DEV : loss 0.7845613360404968 - score 0.7294\n",
            "2019-12-04 11:45:46,255 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:45:46,257 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:46,939 epoch 22 - iter 0/22 - loss 0.37012735 - samples/sec: 389.49\n",
            "2019-12-04 11:45:47,181 epoch 22 - iter 2/22 - loss 0.24069701 - samples/sec: 306.34\n",
            "2019-12-04 11:45:47,410 epoch 22 - iter 4/22 - loss 0.20775624 - samples/sec: 322.97\n",
            "2019-12-04 11:45:47,728 epoch 22 - iter 6/22 - loss 0.18800281 - samples/sec: 231.53\n",
            "2019-12-04 11:45:47,979 epoch 22 - iter 8/22 - loss 0.18596461 - samples/sec: 280.15\n",
            "2019-12-04 11:45:48,193 epoch 22 - iter 10/22 - loss 0.18603247 - samples/sec: 343.36\n",
            "2019-12-04 11:45:48,460 epoch 22 - iter 12/22 - loss 0.18642643 - samples/sec: 270.31\n",
            "2019-12-04 11:45:48,705 epoch 22 - iter 14/22 - loss 0.20169473 - samples/sec: 290.35\n",
            "2019-12-04 11:45:48,970 epoch 22 - iter 16/22 - loss 0.20649408 - samples/sec: 266.42\n",
            "2019-12-04 11:45:49,198 epoch 22 - iter 18/22 - loss 0.20745699 - samples/sec: 325.99\n",
            "2019-12-04 11:45:49,421 epoch 22 - iter 20/22 - loss 0.20142621 - samples/sec: 320.08\n",
            "2019-12-04 11:45:49,743 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:49,750 EPOCH 22 done: loss 0.1980 - lr 0.0500\n",
            "2019-12-04 11:45:50,818 DEV : loss 0.39596468210220337 - score 0.8471\n",
            "Epoch    21: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-12-04 11:45:50,873 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:45:50,874 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:51,600 epoch 23 - iter 0/22 - loss 0.19952402 - samples/sec: 307.34\n",
            "2019-12-04 11:45:51,873 epoch 23 - iter 2/22 - loss 0.19821154 - samples/sec: 267.55\n",
            "2019-12-04 11:45:52,157 epoch 23 - iter 4/22 - loss 0.20435233 - samples/sec: 266.24\n",
            "2019-12-04 11:45:52,469 epoch 23 - iter 6/22 - loss 0.20681993 - samples/sec: 231.36\n",
            "2019-12-04 11:45:52,747 epoch 23 - iter 8/22 - loss 0.19214754 - samples/sec: 256.54\n",
            "2019-12-04 11:45:53,021 epoch 23 - iter 10/22 - loss 0.20158533 - samples/sec: 275.44\n",
            "2019-12-04 11:45:53,259 epoch 23 - iter 12/22 - loss 0.21256129 - samples/sec: 312.75\n",
            "2019-12-04 11:45:53,511 epoch 23 - iter 14/22 - loss 0.21624428 - samples/sec: 283.98\n",
            "2019-12-04 11:45:53,729 epoch 23 - iter 16/22 - loss 0.22289665 - samples/sec: 343.56\n",
            "2019-12-04 11:45:53,977 epoch 23 - iter 18/22 - loss 0.23358252 - samples/sec: 287.57\n",
            "2019-12-04 11:45:54,239 epoch 23 - iter 20/22 - loss 0.21987560 - samples/sec: 277.87\n",
            "2019-12-04 11:45:54,592 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:54,596 EPOCH 23 done: loss 0.2104 - lr 0.0250\n",
            "2019-12-04 11:45:55,720 DEV : loss 0.37357959151268005 - score 0.8588\n",
            "2019-12-04 11:45:55,770 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:45:55,772 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:56,498 epoch 24 - iter 0/22 - loss 0.37070686 - samples/sec: 413.50\n",
            "2019-12-04 11:45:56,777 epoch 24 - iter 2/22 - loss 0.32346195 - samples/sec: 259.11\n",
            "2019-12-04 11:45:57,013 epoch 24 - iter 4/22 - loss 0.29658762 - samples/sec: 328.31\n",
            "2019-12-04 11:45:57,233 epoch 24 - iter 6/22 - loss 0.24449462 - samples/sec: 327.67\n",
            "2019-12-04 11:45:57,517 epoch 24 - iter 8/22 - loss 0.23183475 - samples/sec: 250.23\n",
            "2019-12-04 11:45:57,820 epoch 24 - iter 10/22 - loss 0.22850644 - samples/sec: 247.68\n",
            "2019-12-04 11:45:58,096 epoch 24 - iter 12/22 - loss 0.22386104 - samples/sec: 269.71\n",
            "2019-12-04 11:45:58,357 epoch 24 - iter 14/22 - loss 0.21583975 - samples/sec: 268.41\n",
            "2019-12-04 11:45:58,651 epoch 24 - iter 16/22 - loss 0.20265859 - samples/sec: 242.44\n",
            "2019-12-04 11:45:58,909 epoch 24 - iter 18/22 - loss 0.19395350 - samples/sec: 280.36\n",
            "2019-12-04 11:45:59,155 epoch 24 - iter 20/22 - loss 0.19430146 - samples/sec: 285.76\n",
            "2019-12-04 11:45:59,503 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:45:59,508 EPOCH 24 done: loss 0.1887 - lr 0.0250\n",
            "2019-12-04 11:46:00,614 DEV : loss 0.34057438373565674 - score 0.8471\n",
            "2019-12-04 11:46:00,663 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:46:00,666 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:01,344 epoch 25 - iter 0/22 - loss 0.30587530 - samples/sec: 381.43\n",
            "2019-12-04 11:46:01,628 epoch 25 - iter 2/22 - loss 0.24762583 - samples/sec: 252.32\n",
            "2019-12-04 11:46:01,924 epoch 25 - iter 4/22 - loss 0.20072664 - samples/sec: 253.42\n",
            "2019-12-04 11:46:02,149 epoch 25 - iter 6/22 - loss 0.18697544 - samples/sec: 317.86\n",
            "2019-12-04 11:46:02,415 epoch 25 - iter 8/22 - loss 0.17778858 - samples/sec: 264.62\n",
            "2019-12-04 11:46:02,704 epoch 25 - iter 10/22 - loss 0.17895983 - samples/sec: 267.24\n",
            "2019-12-04 11:46:02,925 epoch 25 - iter 12/22 - loss 0.16698418 - samples/sec: 320.25\n",
            "2019-12-04 11:46:03,158 epoch 25 - iter 14/22 - loss 0.19582579 - samples/sec: 310.63\n",
            "2019-12-04 11:46:03,392 epoch 25 - iter 16/22 - loss 0.20188800 - samples/sec: 312.89\n",
            "2019-12-04 11:46:03,677 epoch 25 - iter 18/22 - loss 0.20351919 - samples/sec: 249.11\n",
            "2019-12-04 11:46:03,919 epoch 25 - iter 20/22 - loss 0.19952618 - samples/sec: 299.92\n",
            "2019-12-04 11:46:04,246 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:04,249 EPOCH 25 done: loss 0.1916 - lr 0.0250\n",
            "2019-12-04 11:46:05,347 DEV : loss 0.3281504511833191 - score 0.8706\n",
            "2019-12-04 11:46:05,401 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:46:05,403 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:06,086 epoch 26 - iter 0/22 - loss 0.11470618 - samples/sec: 406.16\n",
            "2019-12-04 11:46:06,373 epoch 26 - iter 2/22 - loss 0.16868025 - samples/sec: 269.34\n",
            "2019-12-04 11:46:06,628 epoch 26 - iter 4/22 - loss 0.14877415 - samples/sec: 275.61\n",
            "2019-12-04 11:46:06,886 epoch 26 - iter 6/22 - loss 0.16625279 - samples/sec: 270.82\n",
            "2019-12-04 11:46:07,202 epoch 26 - iter 8/22 - loss 0.17610150 - samples/sec: 225.39\n",
            "2019-12-04 11:46:07,487 epoch 26 - iter 10/22 - loss 0.17634948 - samples/sec: 250.91\n",
            "2019-12-04 11:46:07,729 epoch 26 - iter 12/22 - loss 0.16875086 - samples/sec: 307.00\n",
            "2019-12-04 11:46:07,967 epoch 26 - iter 14/22 - loss 0.17983742 - samples/sec: 305.71\n",
            "2019-12-04 11:46:08,178 epoch 26 - iter 16/22 - loss 0.18031060 - samples/sec: 345.97\n",
            "2019-12-04 11:46:08,373 epoch 26 - iter 18/22 - loss 0.19574365 - samples/sec: 374.75\n",
            "2019-12-04 11:46:08,597 epoch 26 - iter 20/22 - loss 0.20475900 - samples/sec: 322.43\n",
            "2019-12-04 11:46:08,916 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:08,921 EPOCH 26 done: loss 0.1960 - lr 0.0250\n",
            "2019-12-04 11:46:10,069 DEV : loss 0.32208454608917236 - score 0.8706\n",
            "Epoch    25: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-12-04 11:46:10,120 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:46:10,121 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:10,802 epoch 27 - iter 0/22 - loss 0.16016363 - samples/sec: 407.90\n",
            "2019-12-04 11:46:11,051 epoch 27 - iter 2/22 - loss 0.15453845 - samples/sec: 291.10\n",
            "2019-12-04 11:46:11,281 epoch 27 - iter 4/22 - loss 0.14381131 - samples/sec: 341.34\n",
            "2019-12-04 11:46:11,511 epoch 27 - iter 6/22 - loss 0.12963917 - samples/sec: 343.21\n",
            "2019-12-04 11:46:11,715 epoch 27 - iter 8/22 - loss 0.14674878 - samples/sec: 352.36\n",
            "2019-12-04 11:46:11,988 epoch 27 - iter 10/22 - loss 0.17011482 - samples/sec: 254.77\n",
            "2019-12-04 11:46:12,250 epoch 27 - iter 12/22 - loss 0.17721915 - samples/sec: 281.49\n",
            "2019-12-04 11:46:12,506 epoch 27 - iter 14/22 - loss 0.18643394 - samples/sec: 273.59\n",
            "2019-12-04 11:46:12,724 epoch 27 - iter 16/22 - loss 0.17933561 - samples/sec: 324.80\n",
            "2019-12-04 11:46:12,947 epoch 27 - iter 18/22 - loss 0.17910421 - samples/sec: 328.79\n",
            "2019-12-04 11:46:13,195 epoch 27 - iter 20/22 - loss 0.17411077 - samples/sec: 282.99\n",
            "2019-12-04 11:46:13,537 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:13,538 EPOCH 27 done: loss 0.1778 - lr 0.0125\n",
            "2019-12-04 11:46:14,603 DEV : loss 0.3371705412864685 - score 0.8353\n",
            "2019-12-04 11:46:14,652 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:46:14,653 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:15,374 epoch 28 - iter 0/22 - loss 0.16580683 - samples/sec: 327.24\n",
            "2019-12-04 11:46:15,649 epoch 28 - iter 2/22 - loss 0.20868776 - samples/sec: 273.46\n",
            "2019-12-04 11:46:15,900 epoch 28 - iter 4/22 - loss 0.23280472 - samples/sec: 337.04\n",
            "2019-12-04 11:46:16,206 epoch 28 - iter 6/22 - loss 0.20364903 - samples/sec: 224.69\n",
            "2019-12-04 11:46:16,468 epoch 28 - iter 8/22 - loss 0.19583303 - samples/sec: 273.73\n",
            "2019-12-04 11:46:16,759 epoch 28 - iter 10/22 - loss 0.20928904 - samples/sec: 264.16\n",
            "2019-12-04 11:46:17,033 epoch 28 - iter 12/22 - loss 0.21590258 - samples/sec: 256.26\n",
            "2019-12-04 11:46:19,501 epoch 28 - iter 14/22 - loss 0.21182590 - samples/sec: 26.23\n",
            "2019-12-04 11:46:19,728 epoch 28 - iter 16/22 - loss 0.19605340 - samples/sec: 333.79\n",
            "2019-12-04 11:46:19,954 epoch 28 - iter 18/22 - loss 0.20617315 - samples/sec: 313.76\n",
            "2019-12-04 11:46:20,196 epoch 28 - iter 20/22 - loss 0.19495485 - samples/sec: 293.92\n",
            "2019-12-04 11:46:20,544 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:20,547 EPOCH 28 done: loss 0.1889 - lr 0.0125\n",
            "2019-12-04 11:46:21,625 DEV : loss 0.3203727900981903 - score 0.8824\n",
            "2019-12-04 11:46:21,675 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:46:25,011 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:25,783 epoch 29 - iter 0/22 - loss 0.20233214 - samples/sec: 354.36\n",
            "2019-12-04 11:46:26,056 epoch 29 - iter 2/22 - loss 0.21392375 - samples/sec: 271.95\n",
            "2019-12-04 11:46:26,292 epoch 29 - iter 4/22 - loss 0.22608528 - samples/sec: 320.22\n",
            "2019-12-04 11:46:26,562 epoch 29 - iter 6/22 - loss 0.21179911 - samples/sec: 261.23\n",
            "2019-12-04 11:46:26,802 epoch 29 - iter 8/22 - loss 0.21303506 - samples/sec: 307.26\n",
            "2019-12-04 11:46:27,039 epoch 29 - iter 10/22 - loss 0.21685674 - samples/sec: 312.13\n",
            "2019-12-04 11:46:27,275 epoch 29 - iter 12/22 - loss 0.20487735 - samples/sec: 300.81\n",
            "2019-12-04 11:46:27,520 epoch 29 - iter 14/22 - loss 0.19188853 - samples/sec: 303.27\n",
            "2019-12-04 11:46:27,773 epoch 29 - iter 16/22 - loss 0.19225878 - samples/sec: 285.31\n",
            "2019-12-04 11:46:28,023 epoch 29 - iter 18/22 - loss 0.19803933 - samples/sec: 288.76\n",
            "2019-12-04 11:46:28,241 epoch 29 - iter 20/22 - loss 0.19213859 - samples/sec: 326.33\n",
            "2019-12-04 11:46:28,552 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:28,554 EPOCH 29 done: loss 0.1921 - lr 0.0125\n",
            "2019-12-04 11:46:29,688 DEV : loss 0.3632960915565491 - score 0.8824\n",
            "2019-12-04 11:46:29,742 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:46:33,091 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:33,817 epoch 30 - iter 0/22 - loss 0.07934348 - samples/sec: 314.31\n",
            "2019-12-04 11:46:34,094 epoch 30 - iter 2/22 - loss 0.18069482 - samples/sec: 278.02\n",
            "2019-12-04 11:46:34,355 epoch 30 - iter 4/22 - loss 0.16596051 - samples/sec: 279.56\n",
            "2019-12-04 11:46:34,664 epoch 30 - iter 6/22 - loss 0.17392375 - samples/sec: 231.37\n",
            "2019-12-04 11:46:34,907 epoch 30 - iter 8/22 - loss 0.17098303 - samples/sec: 296.74\n",
            "2019-12-04 11:46:35,182 epoch 30 - iter 10/22 - loss 0.17804888 - samples/sec: 277.63\n",
            "2019-12-04 11:46:35,418 epoch 30 - iter 12/22 - loss 0.20563641 - samples/sec: 312.88\n",
            "2019-12-04 11:46:35,694 epoch 30 - iter 14/22 - loss 0.19191652 - samples/sec: 258.52\n",
            "2019-12-04 11:46:35,983 epoch 30 - iter 16/22 - loss 0.19986314 - samples/sec: 253.83\n",
            "2019-12-04 11:46:36,219 epoch 30 - iter 18/22 - loss 0.19872349 - samples/sec: 304.12\n",
            "2019-12-04 11:46:36,507 epoch 30 - iter 20/22 - loss 0.19855082 - samples/sec: 245.07\n",
            "2019-12-04 11:46:36,842 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:36,844 EPOCH 30 done: loss 0.1901 - lr 0.0125\n",
            "2019-12-04 11:46:38,000 DEV : loss 0.3294316530227661 - score 0.8706\n",
            "Epoch    29: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-12-04 11:46:38,061 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:46:38,063 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:38,777 epoch 31 - iter 0/22 - loss 0.17418708 - samples/sec: 360.28\n",
            "2019-12-04 11:46:39,039 epoch 31 - iter 2/22 - loss 0.20088848 - samples/sec: 275.84\n",
            "2019-12-04 11:46:39,317 epoch 31 - iter 4/22 - loss 0.18034515 - samples/sec: 278.13\n",
            "2019-12-04 11:46:39,586 epoch 31 - iter 6/22 - loss 0.21366462 - samples/sec: 266.73\n",
            "2019-12-04 11:46:39,845 epoch 31 - iter 8/22 - loss 0.20049524 - samples/sec: 277.72\n",
            "2019-12-04 11:46:40,063 epoch 31 - iter 10/22 - loss 0.21112411 - samples/sec: 341.52\n",
            "2019-12-04 11:46:40,324 epoch 31 - iter 12/22 - loss 0.20475451 - samples/sec: 299.95\n",
            "2019-12-04 11:46:40,575 epoch 31 - iter 14/22 - loss 0.19904223 - samples/sec: 286.93\n",
            "2019-12-04 11:46:40,817 epoch 31 - iter 16/22 - loss 0.19214963 - samples/sec: 302.10\n",
            "2019-12-04 11:46:41,130 epoch 31 - iter 18/22 - loss 0.19567175 - samples/sec: 223.33\n",
            "2019-12-04 11:46:41,390 epoch 31 - iter 20/22 - loss 0.19230076 - samples/sec: 275.15\n",
            "2019-12-04 11:46:41,715 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:41,718 EPOCH 31 done: loss 0.1844 - lr 0.0063\n",
            "2019-12-04 11:46:42,766 DEV : loss 0.3235856294631958 - score 0.8824\n",
            "2019-12-04 11:46:42,817 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:46:46,119 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:46,843 epoch 32 - iter 0/22 - loss 0.08171705 - samples/sec: 337.20\n",
            "2019-12-04 11:46:47,108 epoch 32 - iter 2/22 - loss 0.10028217 - samples/sec: 297.61\n",
            "2019-12-04 11:46:47,321 epoch 32 - iter 4/22 - loss 0.12723541 - samples/sec: 338.62\n",
            "2019-12-04 11:46:47,569 epoch 32 - iter 6/22 - loss 0.14710645 - samples/sec: 296.57\n",
            "2019-12-04 11:46:47,802 epoch 32 - iter 8/22 - loss 0.13792176 - samples/sec: 314.67\n",
            "2019-12-04 11:46:48,075 epoch 32 - iter 10/22 - loss 0.15347974 - samples/sec: 261.51\n",
            "2019-12-04 11:46:48,273 epoch 32 - iter 12/22 - loss 0.15496556 - samples/sec: 392.27\n",
            "2019-12-04 11:46:48,482 epoch 32 - iter 14/22 - loss 0.16848968 - samples/sec: 341.94\n",
            "2019-12-04 11:46:48,704 epoch 32 - iter 16/22 - loss 0.17343964 - samples/sec: 318.60\n",
            "2019-12-04 11:46:48,933 epoch 32 - iter 18/22 - loss 0.16465224 - samples/sec: 315.83\n",
            "2019-12-04 11:46:49,164 epoch 32 - iter 20/22 - loss 0.16510287 - samples/sec: 308.46\n",
            "2019-12-04 11:46:49,509 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:49,516 EPOCH 32 done: loss 0.1585 - lr 0.0063\n",
            "2019-12-04 11:46:50,629 DEV : loss 0.32335007190704346 - score 0.8706\n",
            "2019-12-04 11:46:50,679 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:46:50,680 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:51,395 epoch 33 - iter 0/22 - loss 0.19237036 - samples/sec: 327.39\n",
            "2019-12-04 11:46:51,675 epoch 33 - iter 2/22 - loss 0.18581670 - samples/sec: 272.26\n",
            "2019-12-04 11:46:51,914 epoch 33 - iter 4/22 - loss 0.17193610 - samples/sec: 321.33\n",
            "2019-12-04 11:46:52,176 epoch 33 - iter 6/22 - loss 0.18173693 - samples/sec: 285.19\n",
            "2019-12-04 11:46:52,496 epoch 33 - iter 8/22 - loss 0.18065546 - samples/sec: 226.34\n",
            "2019-12-04 11:46:52,784 epoch 33 - iter 10/22 - loss 0.17196025 - samples/sec: 249.66\n",
            "2019-12-04 11:46:53,030 epoch 33 - iter 12/22 - loss 0.16379650 - samples/sec: 287.65\n",
            "2019-12-04 11:46:53,323 epoch 33 - iter 14/22 - loss 0.16600828 - samples/sec: 248.43\n",
            "2019-12-04 11:46:53,605 epoch 33 - iter 16/22 - loss 0.17184988 - samples/sec: 254.10\n",
            "2019-12-04 11:46:53,869 epoch 33 - iter 18/22 - loss 0.18926428 - samples/sec: 273.15\n",
            "2019-12-04 11:46:54,094 epoch 33 - iter 20/22 - loss 0.18730063 - samples/sec: 319.78\n",
            "2019-12-04 11:46:54,409 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:54,411 EPOCH 33 done: loss 0.1801 - lr 0.0063\n",
            "2019-12-04 11:46:55,488 DEV : loss 0.32108354568481445 - score 0.8706\n",
            "2019-12-04 11:46:55,547 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:46:55,549 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:56,279 epoch 34 - iter 0/22 - loss 0.12761980 - samples/sec: 324.39\n",
            "2019-12-04 11:46:56,526 epoch 34 - iter 2/22 - loss 0.14623804 - samples/sec: 308.94\n",
            "2019-12-04 11:46:56,754 epoch 34 - iter 4/22 - loss 0.15671508 - samples/sec: 349.15\n",
            "2019-12-04 11:46:57,029 epoch 34 - iter 6/22 - loss 0.17139681 - samples/sec: 252.33\n",
            "2019-12-04 11:46:57,352 epoch 34 - iter 8/22 - loss 0.17748315 - samples/sec: 216.90\n",
            "2019-12-04 11:46:57,638 epoch 34 - iter 10/22 - loss 0.18025536 - samples/sec: 254.28\n",
            "2019-12-04 11:46:57,868 epoch 34 - iter 12/22 - loss 0.18332428 - samples/sec: 316.67\n",
            "2019-12-04 11:46:58,124 epoch 34 - iter 14/22 - loss 0.18125687 - samples/sec: 273.40\n",
            "2019-12-04 11:46:58,421 epoch 34 - iter 16/22 - loss 0.17860131 - samples/sec: 247.50\n",
            "2019-12-04 11:46:58,662 epoch 34 - iter 18/22 - loss 0.17480279 - samples/sec: 299.58\n",
            "2019-12-04 11:46:58,922 epoch 34 - iter 20/22 - loss 0.17261362 - samples/sec: 275.05\n",
            "2019-12-04 11:46:59,234 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:46:59,236 EPOCH 34 done: loss 0.2207 - lr 0.0063\n",
            "2019-12-04 11:47:00,321 DEV : loss 0.3198857009410858 - score 0.8706\n",
            "Epoch    33: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-12-04 11:47:00,371 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:47:00,373 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:01,090 epoch 35 - iter 0/22 - loss 0.13702486 - samples/sec: 371.30\n",
            "2019-12-04 11:47:01,322 epoch 35 - iter 2/22 - loss 0.15574384 - samples/sec: 337.89\n",
            "2019-12-04 11:47:01,622 epoch 35 - iter 4/22 - loss 0.20263686 - samples/sec: 229.07\n",
            "2019-12-04 11:47:01,868 epoch 35 - iter 6/22 - loss 0.18450033 - samples/sec: 298.62\n",
            "2019-12-04 11:47:02,099 epoch 35 - iter 8/22 - loss 0.18913977 - samples/sec: 321.40\n",
            "2019-12-04 11:47:02,321 epoch 35 - iter 10/22 - loss 0.17790637 - samples/sec: 320.52\n",
            "2019-12-04 11:47:02,540 epoch 35 - iter 12/22 - loss 0.18208375 - samples/sec: 328.77\n",
            "2019-12-04 11:47:02,781 epoch 35 - iter 14/22 - loss 0.18118298 - samples/sec: 317.17\n",
            "2019-12-04 11:47:02,998 epoch 35 - iter 16/22 - loss 0.20057363 - samples/sec: 328.98\n",
            "2019-12-04 11:47:03,197 epoch 35 - iter 18/22 - loss 0.19239055 - samples/sec: 366.83\n",
            "2019-12-04 11:47:03,424 epoch 35 - iter 20/22 - loss 0.18261104 - samples/sec: 314.82\n",
            "2019-12-04 11:47:03,733 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:03,736 EPOCH 35 done: loss 0.1794 - lr 0.0031\n",
            "2019-12-04 11:47:04,792 DEV : loss 0.32015275955200195 - score 0.8706\n",
            "2019-12-04 11:47:04,846 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:47:04,847 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:05,549 epoch 36 - iter 0/22 - loss 0.22864440 - samples/sec: 380.31\n",
            "2019-12-04 11:47:05,799 epoch 36 - iter 2/22 - loss 0.19548261 - samples/sec: 320.86\n",
            "2019-12-04 11:47:06,019 epoch 36 - iter 4/22 - loss 0.17404588 - samples/sec: 321.73\n",
            "2019-12-04 11:47:06,285 epoch 36 - iter 6/22 - loss 0.15663212 - samples/sec: 277.20\n",
            "2019-12-04 11:47:06,489 epoch 36 - iter 8/22 - loss 0.16148107 - samples/sec: 362.49\n",
            "2019-12-04 11:47:06,671 epoch 36 - iter 10/22 - loss 0.16059081 - samples/sec: 398.44\n",
            "2019-12-04 11:47:06,978 epoch 36 - iter 12/22 - loss 0.16549144 - samples/sec: 231.30\n",
            "2019-12-04 11:47:07,246 epoch 36 - iter 14/22 - loss 0.16466739 - samples/sec: 270.85\n",
            "2019-12-04 11:47:07,527 epoch 36 - iter 16/22 - loss 0.18089695 - samples/sec: 259.78\n",
            "2019-12-04 11:47:07,782 epoch 36 - iter 18/22 - loss 0.17144705 - samples/sec: 284.75\n",
            "2019-12-04 11:47:07,992 epoch 36 - iter 20/22 - loss 0.16253044 - samples/sec: 343.57\n",
            "2019-12-04 11:47:08,309 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:08,313 EPOCH 36 done: loss 0.1580 - lr 0.0031\n",
            "2019-12-04 11:47:09,416 DEV : loss 0.32478007674217224 - score 0.8824\n",
            "2019-12-04 11:47:09,472 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:47:12,756 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:13,517 epoch 37 - iter 0/22 - loss 0.32990870 - samples/sec: 325.08\n",
            "2019-12-04 11:47:13,825 epoch 37 - iter 2/22 - loss 0.24651788 - samples/sec: 238.71\n",
            "2019-12-04 11:47:14,071 epoch 37 - iter 4/22 - loss 0.19774858 - samples/sec: 315.68\n",
            "2019-12-04 11:47:14,297 epoch 37 - iter 6/22 - loss 0.19342563 - samples/sec: 318.84\n",
            "2019-12-04 11:47:14,581 epoch 37 - iter 8/22 - loss 0.17607554 - samples/sec: 244.44\n",
            "2019-12-04 11:47:14,861 epoch 37 - iter 10/22 - loss 0.16366770 - samples/sec: 285.54\n",
            "2019-12-04 11:47:15,074 epoch 37 - iter 12/22 - loss 0.17557195 - samples/sec: 337.59\n",
            "2019-12-04 11:47:15,351 epoch 37 - iter 14/22 - loss 0.17295839 - samples/sec: 251.77\n",
            "2019-12-04 11:47:15,617 epoch 37 - iter 16/22 - loss 0.16802435 - samples/sec: 273.44\n",
            "2019-12-04 11:47:15,810 epoch 37 - iter 18/22 - loss 0.17088176 - samples/sec: 376.19\n",
            "2019-12-04 11:47:16,018 epoch 37 - iter 20/22 - loss 0.16805491 - samples/sec: 343.60\n",
            "2019-12-04 11:47:16,352 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:16,354 EPOCH 37 done: loss 0.1605 - lr 0.0031\n",
            "2019-12-04 11:47:17,415 DEV : loss 0.32426661252975464 - score 0.8706\n",
            "2019-12-04 11:47:17,470 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:47:17,473 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:18,173 epoch 38 - iter 0/22 - loss 0.10843874 - samples/sec: 430.16\n",
            "2019-12-04 11:47:18,463 epoch 38 - iter 2/22 - loss 0.16228465 - samples/sec: 250.76\n",
            "2019-12-04 11:47:18,721 epoch 38 - iter 4/22 - loss 0.13063640 - samples/sec: 282.08\n",
            "2019-12-04 11:47:18,970 epoch 38 - iter 6/22 - loss 0.15074494 - samples/sec: 290.22\n",
            "2019-12-04 11:47:19,313 epoch 38 - iter 8/22 - loss 0.14007194 - samples/sec: 213.48\n",
            "2019-12-04 11:47:19,540 epoch 38 - iter 10/22 - loss 0.14691336 - samples/sec: 320.79\n",
            "2019-12-04 11:47:19,750 epoch 38 - iter 12/22 - loss 0.15514378 - samples/sec: 340.24\n",
            "2019-12-04 11:47:19,937 epoch 38 - iter 14/22 - loss 0.15997643 - samples/sec: 398.98\n",
            "2019-12-04 11:47:20,200 epoch 38 - iter 16/22 - loss 0.16790528 - samples/sec: 272.92\n",
            "2019-12-04 11:47:20,525 epoch 38 - iter 18/22 - loss 0.16849492 - samples/sec: 214.38\n",
            "2019-12-04 11:47:20,793 epoch 38 - iter 20/22 - loss 0.17531447 - samples/sec: 276.30\n",
            "2019-12-04 11:47:21,095 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:21,104 EPOCH 38 done: loss 0.1937 - lr 0.0031\n",
            "2019-12-04 11:47:22,167 DEV : loss 0.3235536217689514 - score 0.8706\n",
            "Epoch    37: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2019-12-04 11:47:22,217 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:47:22,219 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:22,931 epoch 39 - iter 0/22 - loss 0.19590338 - samples/sec: 368.26\n",
            "2019-12-04 11:47:23,237 epoch 39 - iter 2/22 - loss 0.22079620 - samples/sec: 235.91\n",
            "2019-12-04 11:47:23,496 epoch 39 - iter 4/22 - loss 0.18266446 - samples/sec: 289.36\n",
            "2019-12-04 11:47:23,748 epoch 39 - iter 6/22 - loss 0.18094347 - samples/sec: 279.16\n",
            "2019-12-04 11:47:23,999 epoch 39 - iter 8/22 - loss 0.18387154 - samples/sec: 293.51\n",
            "2019-12-04 11:47:24,239 epoch 39 - iter 10/22 - loss 0.18013468 - samples/sec: 312.50\n",
            "2019-12-04 11:47:24,464 epoch 39 - iter 12/22 - loss 0.17386611 - samples/sec: 317.34\n",
            "2019-12-04 11:47:24,650 epoch 39 - iter 14/22 - loss 0.16836350 - samples/sec: 388.90\n",
            "2019-12-04 11:47:24,893 epoch 39 - iter 16/22 - loss 0.15974111 - samples/sec: 303.29\n",
            "2019-12-04 11:47:25,103 epoch 39 - iter 18/22 - loss 0.16289648 - samples/sec: 347.03\n",
            "2019-12-04 11:47:25,291 epoch 39 - iter 20/22 - loss 0.16649826 - samples/sec: 386.94\n",
            "2019-12-04 11:47:25,598 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:25,599 EPOCH 39 done: loss 0.1689 - lr 0.0016\n",
            "2019-12-04 11:47:26,747 DEV : loss 0.32610225677490234 - score 0.8706\n",
            "2019-12-04 11:47:26,792 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:47:26,794 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:27,485 epoch 40 - iter 0/22 - loss 0.16035627 - samples/sec: 394.40\n",
            "2019-12-04 11:47:27,697 epoch 40 - iter 2/22 - loss 0.13003574 - samples/sec: 350.25\n",
            "2019-12-04 11:47:27,967 epoch 40 - iter 4/22 - loss 0.14767549 - samples/sec: 280.72\n",
            "2019-12-04 11:47:30,397 epoch 40 - iter 6/22 - loss 0.16587996 - samples/sec: 239.19\n",
            "2019-12-04 11:47:30,718 epoch 40 - iter 8/22 - loss 0.17450276 - samples/sec: 227.88\n",
            "2019-12-04 11:47:30,944 epoch 40 - iter 10/22 - loss 0.16874917 - samples/sec: 338.95\n",
            "2019-12-04 11:47:31,180 epoch 40 - iter 12/22 - loss 0.16232537 - samples/sec: 298.35\n",
            "2019-12-04 11:47:31,373 epoch 40 - iter 14/22 - loss 0.16142595 - samples/sec: 388.51\n",
            "2019-12-04 11:47:31,584 epoch 40 - iter 16/22 - loss 0.16888891 - samples/sec: 345.35\n",
            "2019-12-04 11:47:31,812 epoch 40 - iter 18/22 - loss 0.16879834 - samples/sec: 312.34\n",
            "2019-12-04 11:47:32,013 epoch 40 - iter 20/22 - loss 0.16859012 - samples/sec: 379.68\n",
            "2019-12-04 11:47:32,352 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:32,357 EPOCH 40 done: loss 0.1611 - lr 0.0016\n",
            "2019-12-04 11:47:33,409 DEV : loss 0.32515811920166016 - score 0.8706\n",
            "2019-12-04 11:47:33,454 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:47:33,455 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:34,140 epoch 41 - iter 0/22 - loss 0.07830114 - samples/sec: 439.03\n",
            "2019-12-04 11:47:34,468 epoch 41 - iter 2/22 - loss 0.15934733 - samples/sec: 218.98\n",
            "2019-12-04 11:47:34,775 epoch 41 - iter 4/22 - loss 0.18115451 - samples/sec: 242.09\n",
            "2019-12-04 11:47:34,998 epoch 41 - iter 6/22 - loss 0.18298721 - samples/sec: 322.65\n",
            "2019-12-04 11:47:35,249 epoch 41 - iter 8/22 - loss 0.19826700 - samples/sec: 284.31\n",
            "2019-12-04 11:47:35,530 epoch 41 - iter 10/22 - loss 0.18614657 - samples/sec: 269.49\n",
            "2019-12-04 11:47:35,790 epoch 41 - iter 12/22 - loss 0.19174231 - samples/sec: 283.68\n",
            "2019-12-04 11:47:36,054 epoch 41 - iter 14/22 - loss 0.20625638 - samples/sec: 272.76\n",
            "2019-12-04 11:47:36,304 epoch 41 - iter 16/22 - loss 0.19543860 - samples/sec: 300.99\n",
            "2019-12-04 11:47:36,580 epoch 41 - iter 18/22 - loss 0.19055578 - samples/sec: 258.60\n",
            "2019-12-04 11:47:36,826 epoch 41 - iter 20/22 - loss 0.18423672 - samples/sec: 294.88\n",
            "2019-12-04 11:47:37,153 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:37,156 EPOCH 41 done: loss 0.1778 - lr 0.0016\n",
            "2019-12-04 11:47:38,271 DEV : loss 0.3256664276123047 - score 0.8706\n",
            "2019-12-04 11:47:38,318 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:47:38,319 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:38,996 epoch 42 - iter 0/22 - loss 0.13151611 - samples/sec: 456.82\n",
            "2019-12-04 11:47:39,273 epoch 42 - iter 2/22 - loss 0.15394526 - samples/sec: 257.68\n",
            "2019-12-04 11:47:39,583 epoch 42 - iter 4/22 - loss 0.14418481 - samples/sec: 230.64\n",
            "2019-12-04 11:47:39,841 epoch 42 - iter 6/22 - loss 0.14658440 - samples/sec: 296.99\n",
            "2019-12-04 11:47:40,138 epoch 42 - iter 8/22 - loss 0.18099223 - samples/sec: 250.88\n",
            "2019-12-04 11:47:40,382 epoch 42 - iter 10/22 - loss 0.19475753 - samples/sec: 289.61\n",
            "2019-12-04 11:47:40,629 epoch 42 - iter 12/22 - loss 0.18385138 - samples/sec: 288.08\n",
            "2019-12-04 11:47:40,854 epoch 42 - iter 14/22 - loss 0.17083514 - samples/sec: 328.86\n",
            "2019-12-04 11:47:41,134 epoch 42 - iter 16/22 - loss 0.16935473 - samples/sec: 257.42\n",
            "2019-12-04 11:47:41,401 epoch 42 - iter 18/22 - loss 0.17824644 - samples/sec: 277.79\n",
            "2019-12-04 11:47:41,690 epoch 42 - iter 20/22 - loss 0.17468907 - samples/sec: 246.79\n",
            "2019-12-04 11:47:41,982 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:41,987 EPOCH 42 done: loss 0.1683 - lr 0.0016\n",
            "2019-12-04 11:47:43,038 DEV : loss 0.3263118267059326 - score 0.8706\n",
            "Epoch    41: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2019-12-04 11:47:43,089 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:47:43,090 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:43,802 epoch 43 - iter 0/22 - loss 0.07736120 - samples/sec: 489.38\n",
            "2019-12-04 11:47:44,032 epoch 43 - iter 2/22 - loss 0.10234586 - samples/sec: 313.65\n",
            "2019-12-04 11:47:44,297 epoch 43 - iter 4/22 - loss 0.13247142 - samples/sec: 280.01\n",
            "2019-12-04 11:47:44,513 epoch 43 - iter 6/22 - loss 0.13717195 - samples/sec: 330.81\n",
            "2019-12-04 11:47:44,743 epoch 43 - iter 8/22 - loss 0.15574925 - samples/sec: 307.25\n",
            "2019-12-04 11:47:44,989 epoch 43 - iter 10/22 - loss 0.15227730 - samples/sec: 309.94\n",
            "2019-12-04 11:47:45,270 epoch 43 - iter 12/22 - loss 0.15697038 - samples/sec: 252.24\n",
            "2019-12-04 11:47:45,610 epoch 43 - iter 14/22 - loss 0.15976986 - samples/sec: 207.97\n",
            "2019-12-04 11:47:45,884 epoch 43 - iter 16/22 - loss 0.16741279 - samples/sec: 277.70\n",
            "2019-12-04 11:47:46,152 epoch 43 - iter 18/22 - loss 0.16783984 - samples/sec: 260.86\n",
            "2019-12-04 11:47:46,453 epoch 43 - iter 20/22 - loss 0.16394829 - samples/sec: 234.63\n",
            "2019-12-04 11:47:46,757 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:46,758 EPOCH 43 done: loss 0.1583 - lr 0.0008\n",
            "2019-12-04 11:47:47,897 DEV : loss 0.32647401094436646 - score 0.8706\n",
            "2019-12-04 11:47:47,950 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:47:47,952 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:48,617 epoch 44 - iter 0/22 - loss 0.20783491 - samples/sec: 476.78\n",
            "2019-12-04 11:47:48,873 epoch 44 - iter 2/22 - loss 0.16577282 - samples/sec: 287.12\n",
            "2019-12-04 11:47:49,136 epoch 44 - iter 4/22 - loss 0.16408959 - samples/sec: 278.37\n",
            "2019-12-04 11:47:49,463 epoch 44 - iter 6/22 - loss 0.19812509 - samples/sec: 214.67\n",
            "2019-12-04 11:47:49,744 epoch 44 - iter 8/22 - loss 0.20226539 - samples/sec: 252.65\n",
            "2019-12-04 11:47:49,998 epoch 44 - iter 10/22 - loss 0.19560625 - samples/sec: 318.21\n",
            "2019-12-04 11:47:50,256 epoch 44 - iter 12/22 - loss 0.19159817 - samples/sec: 271.51\n",
            "2019-12-04 11:47:50,530 epoch 44 - iter 14/22 - loss 0.19145584 - samples/sec: 260.21\n",
            "2019-12-04 11:47:50,848 epoch 44 - iter 16/22 - loss 0.18122823 - samples/sec: 234.94\n",
            "2019-12-04 11:47:51,094 epoch 44 - iter 18/22 - loss 0.17606827 - samples/sec: 292.31\n",
            "2019-12-04 11:47:51,345 epoch 44 - iter 20/22 - loss 0.17250313 - samples/sec: 287.18\n",
            "2019-12-04 11:47:51,687 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:51,694 EPOCH 44 done: loss 0.1978 - lr 0.0008\n",
            "2019-12-04 11:47:52,788 DEV : loss 0.32535314559936523 - score 0.8706\n",
            "2019-12-04 11:47:52,832 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:47:52,834 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:53,537 epoch 45 - iter 0/22 - loss 0.18266921 - samples/sec: 328.78\n",
            "2019-12-04 11:47:53,826 epoch 45 - iter 2/22 - loss 0.16113497 - samples/sec: 253.63\n",
            "2019-12-04 11:47:54,073 epoch 45 - iter 4/22 - loss 0.14461973 - samples/sec: 317.62\n",
            "2019-12-04 11:47:54,282 epoch 45 - iter 6/22 - loss 0.13619254 - samples/sec: 344.03\n",
            "2019-12-04 11:47:54,568 epoch 45 - iter 8/22 - loss 0.13389350 - samples/sec: 250.63\n",
            "2019-12-04 11:47:54,865 epoch 45 - iter 10/22 - loss 0.15902367 - samples/sec: 249.33\n",
            "2019-12-04 11:47:55,173 epoch 45 - iter 12/22 - loss 0.16581376 - samples/sec: 242.65\n",
            "2019-12-04 11:47:55,415 epoch 45 - iter 14/22 - loss 0.17001738 - samples/sec: 298.91\n",
            "2019-12-04 11:47:55,651 epoch 45 - iter 16/22 - loss 0.17157046 - samples/sec: 301.15\n",
            "2019-12-04 11:47:55,906 epoch 45 - iter 18/22 - loss 0.16941069 - samples/sec: 288.22\n",
            "2019-12-04 11:47:56,143 epoch 45 - iter 20/22 - loss 0.17312913 - samples/sec: 301.34\n",
            "2019-12-04 11:47:56,450 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:56,452 EPOCH 45 done: loss 0.1670 - lr 0.0008\n",
            "2019-12-04 11:47:57,507 DEV : loss 0.3251957595348358 - score 0.8706\n",
            "2019-12-04 11:47:57,561 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:47:57,562 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:47:58,275 epoch 46 - iter 0/22 - loss 0.19332278 - samples/sec: 366.45\n",
            "2019-12-04 11:47:58,512 epoch 46 - iter 2/22 - loss 0.13572356 - samples/sec: 300.78\n",
            "2019-12-04 11:47:58,780 epoch 46 - iter 4/22 - loss 0.12222507 - samples/sec: 287.65\n",
            "2019-12-04 11:47:59,031 epoch 46 - iter 6/22 - loss 0.13326100 - samples/sec: 286.85\n",
            "2019-12-04 11:47:59,251 epoch 46 - iter 8/22 - loss 0.13881312 - samples/sec: 325.53\n",
            "2019-12-04 11:47:59,498 epoch 46 - iter 10/22 - loss 0.14729347 - samples/sec: 303.03\n",
            "2019-12-04 11:47:59,756 epoch 46 - iter 12/22 - loss 0.15573612 - samples/sec: 279.06\n",
            "2019-12-04 11:47:59,963 epoch 46 - iter 14/22 - loss 0.16170647 - samples/sec: 352.33\n",
            "2019-12-04 11:48:00,220 epoch 46 - iter 16/22 - loss 0.16903019 - samples/sec: 289.99\n",
            "2019-12-04 11:48:00,451 epoch 46 - iter 18/22 - loss 0.17108457 - samples/sec: 305.96\n",
            "2019-12-04 11:48:00,677 epoch 46 - iter 20/22 - loss 0.16938575 - samples/sec: 313.30\n",
            "2019-12-04 11:48:00,985 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:00,992 EPOCH 46 done: loss 0.1627 - lr 0.0008\n",
            "2019-12-04 11:48:02,075 DEV : loss 0.3256889879703522 - score 0.8706\n",
            "Epoch    45: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2019-12-04 11:48:02,124 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:48:02,125 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:02,773 epoch 47 - iter 0/22 - loss 0.17473112 - samples/sec: 406.63\n",
            "2019-12-04 11:48:03,039 epoch 47 - iter 2/22 - loss 0.15913319 - samples/sec: 290.75\n",
            "2019-12-04 11:48:03,299 epoch 47 - iter 4/22 - loss 0.16370630 - samples/sec: 276.74\n",
            "2019-12-04 11:48:03,509 epoch 47 - iter 6/22 - loss 0.17228544 - samples/sec: 341.56\n",
            "2019-12-04 11:48:03,764 epoch 47 - iter 8/22 - loss 0.16805405 - samples/sec: 278.99\n",
            "2019-12-04 11:48:04,006 epoch 47 - iter 10/22 - loss 0.16786510 - samples/sec: 320.35\n",
            "2019-12-04 11:48:04,216 epoch 47 - iter 12/22 - loss 0.15741761 - samples/sec: 339.17\n",
            "2019-12-04 11:48:04,423 epoch 47 - iter 14/22 - loss 0.15828581 - samples/sec: 372.69\n",
            "2019-12-04 11:48:04,648 epoch 47 - iter 16/22 - loss 0.15361326 - samples/sec: 317.35\n",
            "2019-12-04 11:48:04,889 epoch 47 - iter 18/22 - loss 0.15571324 - samples/sec: 294.49\n",
            "2019-12-04 11:48:05,134 epoch 47 - iter 20/22 - loss 0.16528057 - samples/sec: 289.60\n",
            "2019-12-04 11:48:05,454 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:05,457 EPOCH 47 done: loss 0.1619 - lr 0.0004\n",
            "2019-12-04 11:48:06,576 DEV : loss 0.32628822326660156 - score 0.8706\n",
            "2019-12-04 11:48:06,629 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:48:06,630 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:07,332 epoch 48 - iter 0/22 - loss 0.18187612 - samples/sec: 411.50\n",
            "2019-12-04 11:48:07,635 epoch 48 - iter 2/22 - loss 0.21190673 - samples/sec: 235.83\n",
            "2019-12-04 11:48:07,881 epoch 48 - iter 4/22 - loss 0.17525662 - samples/sec: 318.71\n",
            "2019-12-04 11:48:08,146 epoch 48 - iter 6/22 - loss 0.15619301 - samples/sec: 290.43\n",
            "2019-12-04 11:48:08,452 epoch 48 - iter 8/22 - loss 0.15947304 - samples/sec: 230.45\n",
            "2019-12-04 11:48:08,717 epoch 48 - iter 10/22 - loss 0.14843223 - samples/sec: 272.16\n",
            "2019-12-04 11:48:08,927 epoch 48 - iter 12/22 - loss 0.14446292 - samples/sec: 371.09\n",
            "2019-12-04 11:48:09,195 epoch 48 - iter 14/22 - loss 0.16038929 - samples/sec: 260.29\n",
            "2019-12-04 11:48:09,435 epoch 48 - iter 16/22 - loss 0.16494361 - samples/sec: 302.71\n",
            "2019-12-04 11:48:09,744 epoch 48 - iter 18/22 - loss 0.16458738 - samples/sec: 232.60\n",
            "2019-12-04 11:48:09,982 epoch 48 - iter 20/22 - loss 0.16705215 - samples/sec: 305.69\n",
            "2019-12-04 11:48:10,310 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:10,312 EPOCH 48 done: loss 0.1599 - lr 0.0004\n",
            "2019-12-04 11:48:11,382 DEV : loss 0.3266650140285492 - score 0.8706\n",
            "2019-12-04 11:48:11,437 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:48:11,439 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:12,145 epoch 49 - iter 0/22 - loss 0.16892488 - samples/sec: 399.75\n",
            "2019-12-04 11:48:12,438 epoch 49 - iter 2/22 - loss 0.23772040 - samples/sec: 246.42\n",
            "2019-12-04 11:48:12,732 epoch 49 - iter 4/22 - loss 0.20366806 - samples/sec: 240.68\n",
            "2019-12-04 11:48:12,957 epoch 49 - iter 6/22 - loss 0.21316320 - samples/sec: 325.74\n",
            "2019-12-04 11:48:13,219 epoch 49 - iter 8/22 - loss 0.21850938 - samples/sec: 277.95\n",
            "2019-12-04 11:48:13,468 epoch 49 - iter 10/22 - loss 0.20418643 - samples/sec: 280.90\n",
            "2019-12-04 11:48:13,680 epoch 49 - iter 12/22 - loss 0.18546003 - samples/sec: 350.55\n",
            "2019-12-04 11:48:13,920 epoch 49 - iter 14/22 - loss 0.17528196 - samples/sec: 313.04\n",
            "2019-12-04 11:48:14,140 epoch 49 - iter 16/22 - loss 0.18207263 - samples/sec: 328.36\n",
            "2019-12-04 11:48:14,359 epoch 49 - iter 18/22 - loss 0.18382309 - samples/sec: 333.94\n",
            "2019-12-04 11:48:14,607 epoch 49 - iter 20/22 - loss 0.17861876 - samples/sec: 294.07\n",
            "2019-12-04 11:48:14,920 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:14,922 EPOCH 49 done: loss 0.1857 - lr 0.0004\n",
            "2019-12-04 11:48:15,947 DEV : loss 0.3270401358604431 - score 0.8706\n",
            "2019-12-04 11:48:15,997 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:48:15,999 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:16,717 epoch 50 - iter 0/22 - loss 0.11005497 - samples/sec: 371.45\n",
            "2019-12-04 11:48:16,963 epoch 50 - iter 2/22 - loss 0.10977347 - samples/sec: 289.15\n",
            "2019-12-04 11:48:17,183 epoch 50 - iter 4/22 - loss 0.16591024 - samples/sec: 351.42\n",
            "2019-12-04 11:48:17,437 epoch 50 - iter 6/22 - loss 0.15045320 - samples/sec: 278.87\n",
            "2019-12-04 11:48:17,654 epoch 50 - iter 8/22 - loss 0.16089302 - samples/sec: 342.14\n",
            "2019-12-04 11:48:17,893 epoch 50 - iter 10/22 - loss 0.15301540 - samples/sec: 294.47\n",
            "2019-12-04 11:48:18,111 epoch 50 - iter 12/22 - loss 0.15615156 - samples/sec: 336.29\n",
            "2019-12-04 11:48:18,307 epoch 50 - iter 14/22 - loss 0.16330183 - samples/sec: 386.30\n",
            "2019-12-04 11:48:18,547 epoch 50 - iter 16/22 - loss 0.16958031 - samples/sec: 293.15\n",
            "2019-12-04 11:48:18,817 epoch 50 - iter 18/22 - loss 0.17080953 - samples/sec: 260.08\n",
            "2019-12-04 11:48:19,077 epoch 50 - iter 20/22 - loss 0.16265499 - samples/sec: 285.00\n",
            "2019-12-04 11:48:19,385 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:19,388 EPOCH 50 done: loss 0.1683 - lr 0.0004\n",
            "2019-12-04 11:48:20,409 DEV : loss 0.32683348655700684 - score 0.8706\n",
            "Epoch    49: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2019-12-04 11:48:20,457 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:48:23,930 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:23,935 Testing using best model ...\n",
            "2019-12-04 11:48:23,937 loading file test_csv/title50/best-model.pt\n",
            "2019-12-04 11:48:27,269 0.8452\t0.8452\t0.8452\n",
            "2019-12-04 11:48:27,273 \n",
            "MICRO_AVG: acc 0.732 - f1-score 0.8452\n",
            "MACRO_AVG: acc 0.7188 - f1-score 0.8349\n",
            "fake       tp: 25 - fp: 7 - fn: 6 - tn: 46 - precision: 0.7812 - recall: 0.8065 - accuracy: 0.6579 - f1-score: 0.7936\n",
            "real       tp: 46 - fp: 6 - fn: 7 - tn: 25 - precision: 0.8846 - recall: 0.8679 - accuracy: 0.7797 - f1-score: 0.8762\n",
            "2019-12-04 11:48:27,275 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:27,280 loading file ./test_csv/title50/best-model.pt\n",
            "acc:  0.8066037735849056\n",
            "precision:  0.7878787878787878\n",
            "recall:  0.7959183673469388\n",
            "f1:  0.7918781725888324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB8BpwNcLtlD",
        "colab_type": "code",
        "outputId": "b173d9fc-4422-404a-c424-28ba5496d860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/url50'\n",
        "make_test(train_url, test_url, path, path, 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:48:30,920 Reading data from test_csv/url50\n",
            "2019-12-04 11:48:30,921 Train: test_csv/url50/train.csv\n",
            "2019-12-04 11:48:30,923 Dev: test_csv/url50/dev.csv\n",
            "2019-12-04 11:48:30,924 Test: test_csv/url50/test.csv\n",
            "2019-12-04 11:48:30,932 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 644/644 [00:00<00:00, 817.20it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:48:32,383 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:48:34,270 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:34,272 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:48:34,274 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:34,276 Corpus: \"Corpus: 644 train + 81 dev + 80 test sentences\"\n",
            "2019-12-04 11:48:34,278 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:34,279 Parameters:\n",
            "2019-12-04 11:48:34,281  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:48:34,284  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:48:34,286  - patience: \"3\"\n",
            "2019-12-04 11:48:34,288  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:48:34,289  - max_epochs: \"50\"\n",
            "2019-12-04 11:48:34,291  - shuffle: \"True\"\n",
            "2019-12-04 11:48:34,294  - train_with_dev: \"False\"\n",
            "2019-12-04 11:48:34,314  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:48:34,316 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:34,318 Model training base path: \"test_csv/url50\"\n",
            "2019-12-04 11:48:34,320 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:34,322 Device: cuda:0\n",
            "2019-12-04 11:48:34,324 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:34,326 Embeddings storage mode: cpu\n",
            "2019-12-04 11:48:34,330 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:35,206 epoch 1 - iter 0/21 - loss 0.66281104 - samples/sec: 267.65\n",
            "2019-12-04 11:48:35,542 epoch 1 - iter 2/21 - loss 0.69042097 - samples/sec: 214.63\n",
            "2019-12-04 11:48:35,962 epoch 1 - iter 4/21 - loss 0.66489724 - samples/sec: 178.64\n",
            "2019-12-04 11:48:36,331 epoch 1 - iter 6/21 - loss 0.63500234 - samples/sec: 195.71\n",
            "2019-12-04 11:48:36,664 epoch 1 - iter 8/21 - loss 0.62935825 - samples/sec: 206.04\n",
            "2019-12-04 11:48:37,074 epoch 1 - iter 10/21 - loss 0.61164180 - samples/sec: 177.56\n",
            "2019-12-04 11:48:37,424 epoch 1 - iter 12/21 - loss 0.61585557 - samples/sec: 207.99\n",
            "2019-12-04 11:48:37,760 epoch 1 - iter 14/21 - loss 0.59855679 - samples/sec: 220.36\n",
            "2019-12-04 11:48:38,056 epoch 1 - iter 16/21 - loss 0.59284088 - samples/sec: 242.07\n",
            "2019-12-04 11:48:38,361 epoch 1 - iter 18/21 - loss 0.58661509 - samples/sec: 239.31\n",
            "2019-12-04 11:48:38,570 epoch 1 - iter 20/21 - loss 0.58011274 - samples/sec: 347.85\n",
            "2019-12-04 11:48:38,873 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:38,875 EPOCH 1 done: loss 0.5801 - lr 0.1000\n",
            "2019-12-04 11:48:40,174 DEV : loss 0.8708503246307373 - score 0.5679\n",
            "2019-12-04 11:48:40,244 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:48:43,592 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:44,527 epoch 2 - iter 0/21 - loss 1.04485035 - samples/sec: 391.85\n",
            "2019-12-04 11:48:44,839 epoch 2 - iter 2/21 - loss 0.63812202 - samples/sec: 224.57\n",
            "2019-12-04 11:48:45,193 epoch 2 - iter 4/21 - loss 0.56177261 - samples/sec: 196.61\n",
            "2019-12-04 11:48:45,546 epoch 2 - iter 6/21 - loss 0.52640999 - samples/sec: 202.57\n",
            "2019-12-04 11:48:45,911 epoch 2 - iter 8/21 - loss 0.52671319 - samples/sec: 190.18\n",
            "2019-12-04 11:48:46,224 epoch 2 - iter 10/21 - loss 0.54110088 - samples/sec: 230.73\n",
            "2019-12-04 11:48:46,563 epoch 2 - iter 12/21 - loss 0.54232086 - samples/sec: 207.22\n",
            "2019-12-04 11:48:46,872 epoch 2 - iter 14/21 - loss 0.54985793 - samples/sec: 241.01\n",
            "2019-12-04 11:48:47,188 epoch 2 - iter 16/21 - loss 0.54271087 - samples/sec: 241.24\n",
            "2019-12-04 11:48:47,492 epoch 2 - iter 18/21 - loss 0.54659438 - samples/sec: 231.60\n",
            "2019-12-04 11:48:47,676 epoch 2 - iter 20/21 - loss 0.53996515 - samples/sec: 397.71\n",
            "2019-12-04 11:48:47,996 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:48,000 EPOCH 2 done: loss 0.5400 - lr 0.1000\n",
            "2019-12-04 11:48:49,195 DEV : loss 0.8336654901504517 - score 0.5679\n",
            "2019-12-04 11:48:49,248 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:48:52,618 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:53,459 epoch 3 - iter 0/21 - loss 0.86698776 - samples/sec: 386.69\n",
            "2019-12-04 11:48:53,843 epoch 3 - iter 2/21 - loss 0.57531772 - samples/sec: 198.19\n",
            "2019-12-04 11:48:54,151 epoch 3 - iter 4/21 - loss 0.53531306 - samples/sec: 233.07\n",
            "2019-12-04 11:48:54,396 epoch 3 - iter 6/21 - loss 0.49255846 - samples/sec: 286.70\n",
            "2019-12-04 11:48:54,810 epoch 3 - iter 8/21 - loss 0.52464475 - samples/sec: 188.04\n",
            "2019-12-04 11:48:55,154 epoch 3 - iter 10/21 - loss 0.52792429 - samples/sec: 202.83\n",
            "2019-12-04 11:48:55,459 epoch 3 - iter 12/21 - loss 0.51923082 - samples/sec: 230.77\n",
            "2019-12-04 11:48:55,777 epoch 3 - iter 14/21 - loss 0.50788583 - samples/sec: 227.73\n",
            "2019-12-04 11:48:56,052 epoch 3 - iter 16/21 - loss 0.51395539 - samples/sec: 256.37\n",
            "2019-12-04 11:48:56,290 epoch 3 - iter 18/21 - loss 0.51167908 - samples/sec: 298.16\n",
            "2019-12-04 11:48:56,491 epoch 3 - iter 20/21 - loss 0.50733983 - samples/sec: 359.76\n",
            "2019-12-04 11:48:56,805 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:48:56,807 EPOCH 3 done: loss 0.5073 - lr 0.1000\n",
            "2019-12-04 11:48:57,931 DEV : loss 0.6138762831687927 - score 0.642\n",
            "2019-12-04 11:48:57,979 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:49:01,383 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:02,227 epoch 4 - iter 0/21 - loss 0.61668652 - samples/sec: 240.15\n",
            "2019-12-04 11:49:02,615 epoch 4 - iter 2/21 - loss 0.48640058 - samples/sec: 195.27\n",
            "2019-12-04 11:49:02,925 epoch 4 - iter 4/21 - loss 0.42574921 - samples/sec: 238.93\n",
            "2019-12-04 11:49:03,232 epoch 4 - iter 6/21 - loss 0.41237354 - samples/sec: 233.18\n",
            "2019-12-04 11:49:03,555 epoch 4 - iter 8/21 - loss 0.41530544 - samples/sec: 232.58\n",
            "2019-12-04 11:49:03,853 epoch 4 - iter 10/21 - loss 0.41717428 - samples/sec: 240.07\n",
            "2019-12-04 11:49:04,183 epoch 4 - iter 12/21 - loss 0.43879027 - samples/sec: 219.50\n",
            "2019-12-04 11:49:04,492 epoch 4 - iter 14/21 - loss 0.44129054 - samples/sec: 226.58\n",
            "2019-12-04 11:49:04,793 epoch 4 - iter 16/21 - loss 0.44382503 - samples/sec: 236.04\n",
            "2019-12-04 11:49:05,073 epoch 4 - iter 18/21 - loss 0.44592956 - samples/sec: 251.91\n",
            "2019-12-04 11:49:05,250 epoch 4 - iter 20/21 - loss 0.44655409 - samples/sec: 417.38\n",
            "2019-12-04 11:49:05,576 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:05,578 EPOCH 4 done: loss 0.4466 - lr 0.1000\n",
            "2019-12-04 11:49:06,782 DEV : loss 0.6419264078140259 - score 0.6173\n",
            "2019-12-04 11:49:06,838 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:49:06,841 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:07,593 epoch 5 - iter 0/21 - loss 0.63994426 - samples/sec: 307.98\n",
            "2019-12-04 11:49:07,898 epoch 5 - iter 2/21 - loss 0.48205878 - samples/sec: 235.42\n",
            "2019-12-04 11:49:08,210 epoch 5 - iter 4/21 - loss 0.45752970 - samples/sec: 241.87\n",
            "2019-12-04 11:49:08,528 epoch 5 - iter 6/21 - loss 0.44601167 - samples/sec: 216.17\n",
            "2019-12-04 11:49:08,861 epoch 5 - iter 8/21 - loss 0.44006928 - samples/sec: 208.26\n",
            "2019-12-04 11:49:09,161 epoch 5 - iter 10/21 - loss 0.43316097 - samples/sec: 245.51\n",
            "2019-12-04 11:49:09,429 epoch 5 - iter 12/21 - loss 0.43051534 - samples/sec: 267.89\n",
            "2019-12-04 11:49:09,776 epoch 5 - iter 14/21 - loss 0.44468734 - samples/sec: 205.94\n",
            "2019-12-04 11:49:10,042 epoch 5 - iter 16/21 - loss 0.45298969 - samples/sec: 270.67\n",
            "2019-12-04 11:49:10,306 epoch 5 - iter 18/21 - loss 0.45579914 - samples/sec: 265.09\n",
            "2019-12-04 11:49:10,537 epoch 5 - iter 20/21 - loss 0.46117570 - samples/sec: 305.23\n",
            "2019-12-04 11:49:10,825 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:10,829 EPOCH 5 done: loss 0.4612 - lr 0.1000\n",
            "2019-12-04 11:49:11,963 DEV : loss 0.5704542994499207 - score 0.6543\n",
            "2019-12-04 11:49:12,010 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:49:15,425 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:16,223 epoch 6 - iter 0/21 - loss 0.39084041 - samples/sec: 342.79\n",
            "2019-12-04 11:49:16,500 epoch 6 - iter 2/21 - loss 0.41567744 - samples/sec: 265.92\n",
            "2019-12-04 11:49:16,808 epoch 6 - iter 4/21 - loss 0.41497056 - samples/sec: 225.34\n",
            "2019-12-04 11:49:17,114 epoch 6 - iter 6/21 - loss 0.39405572 - samples/sec: 236.22\n",
            "2019-12-04 11:49:17,458 epoch 6 - iter 8/21 - loss 0.38275710 - samples/sec: 208.32\n",
            "2019-12-04 11:49:17,796 epoch 6 - iter 10/21 - loss 0.38811697 - samples/sec: 209.27\n",
            "2019-12-04 11:49:18,087 epoch 6 - iter 12/21 - loss 0.39763683 - samples/sec: 248.47\n",
            "2019-12-04 11:49:18,371 epoch 6 - iter 14/21 - loss 0.40995415 - samples/sec: 258.74\n",
            "2019-12-04 11:49:18,689 epoch 6 - iter 16/21 - loss 0.40772243 - samples/sec: 223.97\n",
            "2019-12-04 11:49:19,000 epoch 6 - iter 18/21 - loss 0.42051547 - samples/sec: 227.14\n",
            "2019-12-04 11:49:19,208 epoch 6 - iter 20/21 - loss 0.44098465 - samples/sec: 357.43\n",
            "2019-12-04 11:49:19,535 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:19,538 EPOCH 6 done: loss 0.4410 - lr 0.1000\n",
            "2019-12-04 11:49:20,704 DEV : loss 0.7719566226005554 - score 0.642\n",
            "2019-12-04 11:49:20,751 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:49:20,752 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:21,556 epoch 7 - iter 0/21 - loss 0.69279075 - samples/sec: 268.64\n",
            "2019-12-04 11:49:21,881 epoch 7 - iter 2/21 - loss 0.50333782 - samples/sec: 232.63\n",
            "2019-12-04 11:49:22,206 epoch 7 - iter 4/21 - loss 0.47341848 - samples/sec: 210.86\n",
            "2019-12-04 11:49:22,530 epoch 7 - iter 6/21 - loss 0.45948689 - samples/sec: 218.40\n",
            "2019-12-04 11:49:22,830 epoch 7 - iter 8/21 - loss 0.46464909 - samples/sec: 250.11\n",
            "2019-12-04 11:49:23,087 epoch 7 - iter 10/21 - loss 0.46830845 - samples/sec: 273.73\n",
            "2019-12-04 11:49:23,345 epoch 7 - iter 12/21 - loss 0.45800543 - samples/sec: 286.21\n",
            "2019-12-04 11:49:23,629 epoch 7 - iter 14/21 - loss 0.44484453 - samples/sec: 256.37\n",
            "2019-12-04 11:49:23,977 epoch 7 - iter 16/21 - loss 0.44153628 - samples/sec: 196.29\n",
            "2019-12-04 11:49:24,300 epoch 7 - iter 18/21 - loss 0.43206293 - samples/sec: 221.49\n",
            "2019-12-04 11:49:24,541 epoch 7 - iter 20/21 - loss 0.42764993 - samples/sec: 300.28\n",
            "2019-12-04 11:49:24,870 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:24,872 EPOCH 7 done: loss 0.4276 - lr 0.1000\n",
            "2019-12-04 11:49:26,083 DEV : loss 0.6060523986816406 - score 0.679\n",
            "2019-12-04 11:49:26,129 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:49:29,511 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:30,375 epoch 8 - iter 0/21 - loss 0.71618623 - samples/sec: 341.45\n",
            "2019-12-04 11:49:30,729 epoch 8 - iter 2/21 - loss 0.50492662 - samples/sec: 218.67\n",
            "2019-12-04 11:49:31,019 epoch 8 - iter 4/21 - loss 0.47268273 - samples/sec: 244.66\n",
            "2019-12-04 11:49:31,313 epoch 8 - iter 6/21 - loss 0.46013990 - samples/sec: 235.02\n",
            "2019-12-04 11:49:31,613 epoch 8 - iter 8/21 - loss 0.43873672 - samples/sec: 235.12\n",
            "2019-12-04 11:49:31,938 epoch 8 - iter 10/21 - loss 0.42135372 - samples/sec: 214.53\n",
            "2019-12-04 11:49:32,209 epoch 8 - iter 12/21 - loss 0.41085938 - samples/sec: 257.77\n",
            "2019-12-04 11:49:32,471 epoch 8 - iter 14/21 - loss 0.42223586 - samples/sec: 269.55\n",
            "2019-12-04 11:49:32,792 epoch 8 - iter 16/21 - loss 0.42295142 - samples/sec: 222.17\n",
            "2019-12-04 11:49:33,056 epoch 8 - iter 18/21 - loss 0.41278608 - samples/sec: 269.63\n",
            "2019-12-04 11:49:33,237 epoch 8 - iter 20/21 - loss 0.40414505 - samples/sec: 407.75\n",
            "2019-12-04 11:49:33,549 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:33,550 EPOCH 8 done: loss 0.4041 - lr 0.1000\n",
            "2019-12-04 11:49:34,673 DEV : loss 0.37387630343437195 - score 0.7778\n",
            "2019-12-04 11:49:34,725 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:49:38,244 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:39,057 epoch 9 - iter 0/21 - loss 0.34334320 - samples/sec: 287.90\n",
            "2019-12-04 11:49:39,421 epoch 9 - iter 2/21 - loss 0.29931597 - samples/sec: 203.63\n",
            "2019-12-04 11:49:39,758 epoch 9 - iter 4/21 - loss 0.33931226 - samples/sec: 214.74\n",
            "2019-12-04 11:49:40,096 epoch 9 - iter 6/21 - loss 0.36864229 - samples/sec: 212.81\n",
            "2019-12-04 11:49:40,442 epoch 9 - iter 8/21 - loss 0.36726526 - samples/sec: 210.12\n",
            "2019-12-04 11:49:40,757 epoch 9 - iter 10/21 - loss 0.35992135 - samples/sec: 225.00\n",
            "2019-12-04 11:49:41,033 epoch 9 - iter 12/21 - loss 0.38504084 - samples/sec: 258.54\n",
            "2019-12-04 11:49:41,407 epoch 9 - iter 14/21 - loss 0.39699095 - samples/sec: 189.36\n",
            "2019-12-04 11:49:41,711 epoch 9 - iter 16/21 - loss 0.39334816 - samples/sec: 235.55\n",
            "2019-12-04 11:49:41,993 epoch 9 - iter 18/21 - loss 0.40452989 - samples/sec: 249.37\n",
            "2019-12-04 11:49:42,198 epoch 9 - iter 20/21 - loss 0.40298295 - samples/sec: 351.98\n",
            "2019-12-04 11:49:42,495 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:42,499 EPOCH 9 done: loss 0.4030 - lr 0.1000\n",
            "2019-12-04 11:49:43,622 DEV : loss 0.6925612688064575 - score 0.642\n",
            "2019-12-04 11:49:43,668 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:49:43,669 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:44,435 epoch 10 - iter 0/21 - loss 0.52167434 - samples/sec: 334.55\n",
            "2019-12-04 11:49:44,694 epoch 10 - iter 2/21 - loss 0.46845737 - samples/sec: 274.32\n",
            "2019-12-04 11:49:44,990 epoch 10 - iter 4/21 - loss 0.41745588 - samples/sec: 259.42\n",
            "2019-12-04 11:49:45,276 epoch 10 - iter 6/21 - loss 0.41891018 - samples/sec: 243.58\n",
            "2019-12-04 11:49:45,615 epoch 10 - iter 8/21 - loss 0.40313431 - samples/sec: 207.96\n",
            "2019-12-04 11:49:45,991 epoch 10 - iter 10/21 - loss 0.38862116 - samples/sec: 188.28\n",
            "2019-12-04 11:49:46,280 epoch 10 - iter 12/21 - loss 0.38180190 - samples/sec: 241.45\n",
            "2019-12-04 11:49:46,699 epoch 10 - iter 14/21 - loss 0.37205991 - samples/sec: 163.83\n",
            "2019-12-04 11:49:47,137 epoch 10 - iter 16/21 - loss 0.36354267 - samples/sec: 159.18\n",
            "2019-12-04 11:49:47,435 epoch 10 - iter 18/21 - loss 0.35363683 - samples/sec: 234.20\n",
            "2019-12-04 11:49:47,657 epoch 10 - iter 20/21 - loss 0.35438348 - samples/sec: 328.40\n",
            "2019-12-04 11:49:47,968 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:47,973 EPOCH 10 done: loss 0.3544 - lr 0.1000\n",
            "2019-12-04 11:49:49,264 DEV : loss 0.6786200404167175 - score 0.679\n",
            "2019-12-04 11:49:49,313 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:49:49,315 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:50,055 epoch 11 - iter 0/21 - loss 0.63677382 - samples/sec: 348.79\n",
            "2019-12-04 11:49:50,350 epoch 11 - iter 2/21 - loss 0.46202438 - samples/sec: 240.65\n",
            "2019-12-04 11:49:50,700 epoch 11 - iter 4/21 - loss 0.43835302 - samples/sec: 196.69\n",
            "2019-12-04 11:49:51,058 epoch 11 - iter 6/21 - loss 0.46084123 - samples/sec: 209.42\n",
            "2019-12-04 11:49:51,339 epoch 11 - iter 8/21 - loss 0.46850283 - samples/sec: 255.53\n",
            "2019-12-04 11:49:51,668 epoch 11 - iter 10/21 - loss 0.43472731 - samples/sec: 210.36\n",
            "2019-12-04 11:49:51,958 epoch 11 - iter 12/21 - loss 0.41936028 - samples/sec: 244.43\n",
            "2019-12-04 11:49:52,307 epoch 11 - iter 14/21 - loss 0.45288725 - samples/sec: 201.20\n",
            "2019-12-04 11:49:52,702 epoch 11 - iter 16/21 - loss 0.45872259 - samples/sec: 171.53\n",
            "2019-12-04 11:49:53,039 epoch 11 - iter 18/21 - loss 0.44925010 - samples/sec: 204.54\n",
            "2019-12-04 11:49:53,270 epoch 11 - iter 20/21 - loss 0.43932246 - samples/sec: 319.64\n",
            "2019-12-04 11:49:53,589 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:53,590 EPOCH 11 done: loss 0.4393 - lr 0.1000\n",
            "2019-12-04 11:49:54,846 DEV : loss 0.35078322887420654 - score 0.8765\n",
            "2019-12-04 11:49:54,894 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:49:58,378 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:49:59,249 epoch 12 - iter 0/21 - loss 0.20893031 - samples/sec: 338.26\n",
            "2019-12-04 11:49:59,685 epoch 12 - iter 2/21 - loss 0.30836618 - samples/sec: 158.96\n",
            "2019-12-04 11:50:00,040 epoch 12 - iter 4/21 - loss 0.34960533 - samples/sec: 206.52\n",
            "2019-12-04 11:50:00,444 epoch 12 - iter 6/21 - loss 0.34540980 - samples/sec: 169.92\n",
            "2019-12-04 11:50:00,723 epoch 12 - iter 8/21 - loss 0.36749347 - samples/sec: 249.74\n",
            "2019-12-04 11:50:01,088 epoch 12 - iter 10/21 - loss 0.38512083 - samples/sec: 192.19\n",
            "2019-12-04 11:50:01,387 epoch 12 - iter 12/21 - loss 0.38964895 - samples/sec: 236.51\n",
            "2019-12-04 11:50:01,718 epoch 12 - iter 14/21 - loss 0.36871857 - samples/sec: 208.43\n",
            "2019-12-04 11:50:02,073 epoch 12 - iter 16/21 - loss 0.36115202 - samples/sec: 196.48\n",
            "2019-12-04 11:50:02,351 epoch 12 - iter 18/21 - loss 0.35535307 - samples/sec: 255.96\n",
            "2019-12-04 11:50:02,602 epoch 12 - iter 20/21 - loss 0.35317362 - samples/sec: 285.82\n",
            "2019-12-04 11:50:02,910 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:02,911 EPOCH 12 done: loss 0.3532 - lr 0.1000\n",
            "2019-12-04 11:50:04,153 DEV : loss 0.34620770812034607 - score 0.8272\n",
            "2019-12-04 11:50:04,200 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:50:04,202 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:04,964 epoch 13 - iter 0/21 - loss 0.18907660 - samples/sec: 312.40\n",
            "2019-12-04 11:50:05,335 epoch 13 - iter 2/21 - loss 0.28765356 - samples/sec: 192.97\n",
            "2019-12-04 11:50:05,777 epoch 13 - iter 4/21 - loss 0.30682875 - samples/sec: 157.69\n",
            "2019-12-04 11:50:06,111 epoch 13 - iter 6/21 - loss 0.32982940 - samples/sec: 218.71\n",
            "2019-12-04 11:50:06,411 epoch 13 - iter 8/21 - loss 0.35829284 - samples/sec: 229.34\n",
            "2019-12-04 11:50:06,810 epoch 13 - iter 10/21 - loss 0.36014980 - samples/sec: 173.47\n",
            "2019-12-04 11:50:07,157 epoch 13 - iter 12/21 - loss 0.35343928 - samples/sec: 202.46\n",
            "2019-12-04 11:50:07,529 epoch 13 - iter 14/21 - loss 0.36266709 - samples/sec: 187.10\n",
            "2019-12-04 11:50:07,911 epoch 13 - iter 16/21 - loss 0.35287532 - samples/sec: 184.61\n",
            "2019-12-04 11:50:08,207 epoch 13 - iter 18/21 - loss 0.34587303 - samples/sec: 236.86\n",
            "2019-12-04 11:50:08,414 epoch 13 - iter 20/21 - loss 0.34527058 - samples/sec: 345.84\n",
            "2019-12-04 11:50:08,736 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:08,741 EPOCH 13 done: loss 0.3453 - lr 0.1000\n",
            "2019-12-04 11:50:10,006 DEV : loss 0.49451273679733276 - score 0.7531\n",
            "2019-12-04 11:50:10,051 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:50:10,053 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:10,839 epoch 14 - iter 0/21 - loss 0.42325506 - samples/sec: 266.76\n",
            "2019-12-04 11:50:11,230 epoch 14 - iter 2/21 - loss 0.35068226 - samples/sec: 181.12\n",
            "2019-12-04 11:50:11,538 epoch 14 - iter 4/21 - loss 0.37682157 - samples/sec: 238.36\n",
            "2019-12-04 11:50:11,889 epoch 14 - iter 6/21 - loss 0.36503401 - samples/sec: 194.80\n",
            "2019-12-04 11:50:12,242 epoch 14 - iter 8/21 - loss 0.35817392 - samples/sec: 192.99\n",
            "2019-12-04 11:50:15,983 epoch 14 - iter 10/21 - loss 0.37227076 - samples/sec: 214.22\n",
            "2019-12-04 11:50:16,275 epoch 14 - iter 12/21 - loss 0.38134307 - samples/sec: 243.43\n",
            "2019-12-04 11:50:16,559 epoch 14 - iter 14/21 - loss 0.36629080 - samples/sec: 249.01\n",
            "2019-12-04 11:50:16,882 epoch 14 - iter 16/21 - loss 0.36636117 - samples/sec: 226.94\n",
            "2019-12-04 11:50:17,182 epoch 14 - iter 18/21 - loss 0.36382270 - samples/sec: 235.14\n",
            "2019-12-04 11:50:17,398 epoch 14 - iter 20/21 - loss 0.34946429 - samples/sec: 341.48\n",
            "2019-12-04 11:50:17,791 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:17,793 EPOCH 14 done: loss 0.3495 - lr 0.1000\n",
            "2019-12-04 11:50:19,036 DEV : loss 0.4444534182548523 - score 0.7654\n",
            "2019-12-04 11:50:19,084 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:50:19,086 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:19,877 epoch 15 - iter 0/21 - loss 0.33551449 - samples/sec: 340.88\n",
            "2019-12-04 11:50:20,208 epoch 15 - iter 2/21 - loss 0.37313475 - samples/sec: 210.89\n",
            "2019-12-04 11:50:20,554 epoch 15 - iter 4/21 - loss 0.37903066 - samples/sec: 217.66\n",
            "2019-12-04 11:50:20,868 epoch 15 - iter 6/21 - loss 0.36315031 - samples/sec: 223.74\n",
            "2019-12-04 11:50:21,167 epoch 15 - iter 8/21 - loss 0.35108614 - samples/sec: 238.58\n",
            "2019-12-04 11:50:21,495 epoch 15 - iter 10/21 - loss 0.36642369 - samples/sec: 223.81\n",
            "2019-12-04 11:50:21,804 epoch 15 - iter 12/21 - loss 0.34096860 - samples/sec: 234.97\n",
            "2019-12-04 11:50:22,099 epoch 15 - iter 14/21 - loss 0.33787392 - samples/sec: 242.05\n",
            "2019-12-04 11:50:22,376 epoch 15 - iter 16/21 - loss 0.35116741 - samples/sec: 251.93\n",
            "2019-12-04 11:50:22,721 epoch 15 - iter 18/21 - loss 0.36866765 - samples/sec: 202.81\n",
            "2019-12-04 11:50:22,909 epoch 15 - iter 20/21 - loss 0.38729645 - samples/sec: 386.77\n",
            "2019-12-04 11:50:23,219 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:23,222 EPOCH 15 done: loss 0.3873 - lr 0.1000\n",
            "2019-12-04 11:50:24,438 DEV : loss 1.075613021850586 - score 0.5926\n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-12-04 11:50:24,490 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:50:24,491 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:25,277 epoch 16 - iter 0/21 - loss 1.04391158 - samples/sec: 309.82\n",
            "2019-12-04 11:50:25,606 epoch 16 - iter 2/21 - loss 0.65840606 - samples/sec: 213.31\n",
            "2019-12-04 11:50:25,942 epoch 16 - iter 4/21 - loss 0.52307989 - samples/sec: 220.35\n",
            "2019-12-04 11:50:26,233 epoch 16 - iter 6/21 - loss 0.44153988 - samples/sec: 244.30\n",
            "2019-12-04 11:50:26,509 epoch 16 - iter 8/21 - loss 0.42868867 - samples/sec: 252.18\n",
            "2019-12-04 11:50:26,840 epoch 16 - iter 10/21 - loss 0.41514418 - samples/sec: 220.96\n",
            "2019-12-04 11:50:27,143 epoch 16 - iter 12/21 - loss 0.38558531 - samples/sec: 246.37\n",
            "2019-12-04 11:50:27,460 epoch 16 - iter 14/21 - loss 0.38591109 - samples/sec: 222.33\n",
            "2019-12-04 11:50:27,693 epoch 16 - iter 16/21 - loss 0.37481615 - samples/sec: 326.42\n",
            "2019-12-04 11:50:27,990 epoch 16 - iter 18/21 - loss 0.37579744 - samples/sec: 244.43\n",
            "2019-12-04 11:50:28,165 epoch 16 - iter 20/21 - loss 0.36847486 - samples/sec: 421.56\n",
            "2019-12-04 11:50:28,479 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:28,483 EPOCH 16 done: loss 0.3685 - lr 0.0500\n",
            "2019-12-04 11:50:29,635 DEV : loss 0.3400622606277466 - score 0.8395\n",
            "2019-12-04 11:50:29,684 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:50:29,686 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:30,433 epoch 17 - iter 0/21 - loss 0.28009129 - samples/sec: 356.74\n",
            "2019-12-04 11:50:30,704 epoch 17 - iter 2/21 - loss 0.22770075 - samples/sec: 263.52\n",
            "2019-12-04 11:50:31,028 epoch 17 - iter 4/21 - loss 0.25959747 - samples/sec: 229.26\n",
            "2019-12-04 11:50:31,331 epoch 17 - iter 6/21 - loss 0.27584414 - samples/sec: 240.16\n",
            "2019-12-04 11:50:31,595 epoch 17 - iter 8/21 - loss 0.26972878 - samples/sec: 266.48\n",
            "2019-12-04 11:50:31,880 epoch 17 - iter 10/21 - loss 0.29334716 - samples/sec: 251.86\n",
            "2019-12-04 11:50:32,200 epoch 17 - iter 12/21 - loss 0.29969070 - samples/sec: 220.84\n",
            "2019-12-04 11:50:32,541 epoch 17 - iter 14/21 - loss 0.30377098 - samples/sec: 203.52\n",
            "2019-12-04 11:50:32,837 epoch 17 - iter 16/21 - loss 0.30124629 - samples/sec: 246.62\n",
            "2019-12-04 11:50:33,170 epoch 17 - iter 18/21 - loss 0.29790310 - samples/sec: 206.70\n",
            "2019-12-04 11:50:33,320 epoch 17 - iter 20/21 - loss 0.32131591 - samples/sec: 528.84\n",
            "2019-12-04 11:50:33,635 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:33,639 EPOCH 17 done: loss 0.3213 - lr 0.0500\n",
            "2019-12-04 11:50:34,854 DEV : loss 0.44489026069641113 - score 0.8025\n",
            "2019-12-04 11:50:34,898 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:50:34,899 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:35,740 epoch 18 - iter 0/21 - loss 0.37396631 - samples/sec: 349.73\n",
            "2019-12-04 11:50:36,085 epoch 18 - iter 2/21 - loss 0.29160840 - samples/sec: 214.73\n",
            "2019-12-04 11:50:36,361 epoch 18 - iter 4/21 - loss 0.33986469 - samples/sec: 260.79\n",
            "2019-12-04 11:50:36,622 epoch 18 - iter 6/21 - loss 0.32996139 - samples/sec: 278.17\n",
            "2019-12-04 11:50:36,910 epoch 18 - iter 8/21 - loss 0.32908435 - samples/sec: 240.52\n",
            "2019-12-04 11:50:37,197 epoch 18 - iter 10/21 - loss 0.31801044 - samples/sec: 244.74\n",
            "2019-12-04 11:50:37,563 epoch 18 - iter 12/21 - loss 0.30517656 - samples/sec: 203.05\n",
            "2019-12-04 11:50:37,899 epoch 18 - iter 14/21 - loss 0.29908477 - samples/sec: 207.15\n",
            "2019-12-04 11:50:38,193 epoch 18 - iter 16/21 - loss 0.30770661 - samples/sec: 235.15\n",
            "2019-12-04 11:50:38,526 epoch 18 - iter 18/21 - loss 0.30843705 - samples/sec: 211.55\n",
            "2019-12-04 11:50:38,754 epoch 18 - iter 20/21 - loss 0.33088004 - samples/sec: 328.38\n",
            "2019-12-04 11:50:39,052 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:39,056 EPOCH 18 done: loss 0.3309 - lr 0.0500\n",
            "2019-12-04 11:50:40,285 DEV : loss 0.30967822670936584 - score 0.8765\n",
            "2019-12-04 11:50:40,338 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:50:43,849 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:44,722 epoch 19 - iter 0/21 - loss 0.29374477 - samples/sec: 323.36\n",
            "2019-12-04 11:50:45,008 epoch 19 - iter 2/21 - loss 0.38414556 - samples/sec: 248.55\n",
            "2019-12-04 11:50:45,345 epoch 19 - iter 4/21 - loss 0.38441122 - samples/sec: 221.67\n",
            "2019-12-04 11:50:45,650 epoch 19 - iter 6/21 - loss 0.31849476 - samples/sec: 235.04\n",
            "2019-12-04 11:50:45,946 epoch 19 - iter 8/21 - loss 0.31190767 - samples/sec: 239.27\n",
            "2019-12-04 11:50:46,211 epoch 19 - iter 10/21 - loss 0.29015610 - samples/sec: 282.08\n",
            "2019-12-04 11:50:46,492 epoch 19 - iter 12/21 - loss 0.29146655 - samples/sec: 261.49\n",
            "2019-12-04 11:50:46,746 epoch 19 - iter 14/21 - loss 0.28272435 - samples/sec: 275.24\n",
            "2019-12-04 11:50:47,088 epoch 19 - iter 16/21 - loss 0.29502402 - samples/sec: 206.34\n",
            "2019-12-04 11:50:47,452 epoch 19 - iter 18/21 - loss 0.30611259 - samples/sec: 194.84\n",
            "2019-12-04 11:50:47,652 epoch 19 - iter 20/21 - loss 0.29598488 - samples/sec: 376.33\n",
            "2019-12-04 11:50:47,963 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:47,965 EPOCH 19 done: loss 0.2960 - lr 0.0500\n",
            "2019-12-04 11:50:49,137 DEV : loss 0.31351572275161743 - score 0.8642\n",
            "Epoch    18: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-12-04 11:50:49,189 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:50:49,190 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:50,006 epoch 20 - iter 0/21 - loss 0.20636058 - samples/sec: 373.60\n",
            "2019-12-04 11:50:50,402 epoch 20 - iter 2/21 - loss 0.20502005 - samples/sec: 184.19\n",
            "2019-12-04 11:50:50,751 epoch 20 - iter 4/21 - loss 0.24108816 - samples/sec: 198.96\n",
            "2019-12-04 11:50:51,057 epoch 20 - iter 6/21 - loss 0.25552848 - samples/sec: 245.30\n",
            "2019-12-04 11:50:51,404 epoch 20 - iter 8/21 - loss 0.25218231 - samples/sec: 206.04\n",
            "2019-12-04 11:50:51,743 epoch 20 - iter 10/21 - loss 0.25464848 - samples/sec: 205.60\n",
            "2019-12-04 11:50:52,042 epoch 20 - iter 12/21 - loss 0.27864678 - samples/sec: 259.09\n",
            "2019-12-04 11:50:52,377 epoch 20 - iter 14/21 - loss 0.27786038 - samples/sec: 216.65\n",
            "2019-12-04 11:50:52,719 epoch 20 - iter 16/21 - loss 0.28709412 - samples/sec: 204.74\n",
            "2019-12-04 11:50:53,009 epoch 20 - iter 18/21 - loss 0.30018757 - samples/sec: 258.93\n",
            "2019-12-04 11:50:53,195 epoch 20 - iter 20/21 - loss 0.29519958 - samples/sec: 395.25\n",
            "2019-12-04 11:50:53,509 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:53,512 EPOCH 20 done: loss 0.2952 - lr 0.0250\n",
            "2019-12-04 11:50:54,773 DEV : loss 0.29795190691947937 - score 0.8765\n",
            "2019-12-04 11:50:54,823 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:50:58,196 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:50:59,033 epoch 21 - iter 0/21 - loss 0.22413316 - samples/sec: 336.30\n",
            "2019-12-04 11:50:59,342 epoch 21 - iter 2/21 - loss 0.28758531 - samples/sec: 236.25\n",
            "2019-12-04 11:50:59,678 epoch 21 - iter 4/21 - loss 0.29170712 - samples/sec: 212.65\n",
            "2019-12-04 11:50:59,991 epoch 21 - iter 6/21 - loss 0.30029310 - samples/sec: 269.34\n",
            "2019-12-04 11:51:00,278 epoch 21 - iter 8/21 - loss 0.29998332 - samples/sec: 244.67\n",
            "2019-12-04 11:51:00,573 epoch 21 - iter 10/21 - loss 0.27203537 - samples/sec: 233.46\n",
            "2019-12-04 11:51:00,911 epoch 21 - iter 12/21 - loss 0.28550610 - samples/sec: 232.61\n",
            "2019-12-04 11:51:01,211 epoch 21 - iter 14/21 - loss 0.28710848 - samples/sec: 231.29\n",
            "2019-12-04 11:51:01,490 epoch 21 - iter 16/21 - loss 0.28167742 - samples/sec: 249.57\n",
            "2019-12-04 11:51:01,855 epoch 21 - iter 18/21 - loss 0.27306153 - samples/sec: 202.15\n",
            "2019-12-04 11:51:02,035 epoch 21 - iter 20/21 - loss 0.26534212 - samples/sec: 404.55\n",
            "2019-12-04 11:51:02,381 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:02,387 EPOCH 21 done: loss 0.2653 - lr 0.0250\n",
            "2019-12-04 11:51:03,579 DEV : loss 0.3108532130718231 - score 0.8642\n",
            "2019-12-04 11:51:03,629 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:51:03,630 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:04,437 epoch 22 - iter 0/21 - loss 0.26638597 - samples/sec: 332.15\n",
            "2019-12-04 11:51:04,746 epoch 22 - iter 2/21 - loss 0.18730298 - samples/sec: 234.27\n",
            "2019-12-04 11:51:05,043 epoch 22 - iter 4/21 - loss 0.21524605 - samples/sec: 259.29\n",
            "2019-12-04 11:51:05,315 epoch 22 - iter 6/21 - loss 0.24501224 - samples/sec: 256.89\n",
            "2019-12-04 11:51:05,648 epoch 22 - iter 8/21 - loss 0.24071277 - samples/sec: 212.84\n",
            "2019-12-04 11:51:05,956 epoch 22 - iter 10/21 - loss 0.25857440 - samples/sec: 249.14\n",
            "2019-12-04 11:51:06,216 epoch 22 - iter 12/21 - loss 0.25514322 - samples/sec: 278.69\n",
            "2019-12-04 11:51:06,516 epoch 22 - iter 14/21 - loss 0.25132543 - samples/sec: 237.13\n",
            "2019-12-04 11:51:06,762 epoch 22 - iter 16/21 - loss 0.25708116 - samples/sec: 285.96\n",
            "2019-12-04 11:51:07,110 epoch 22 - iter 18/21 - loss 0.26622921 - samples/sec: 198.34\n",
            "2019-12-04 11:51:07,340 epoch 22 - iter 20/21 - loss 0.27781114 - samples/sec: 315.91\n",
            "2019-12-04 11:51:07,667 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:07,671 EPOCH 22 done: loss 0.2778 - lr 0.0250\n",
            "2019-12-04 11:51:08,800 DEV : loss 0.36679548025131226 - score 0.8272\n",
            "2019-12-04 11:51:08,850 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:51:08,851 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:09,603 epoch 23 - iter 0/21 - loss 0.47292668 - samples/sec: 343.78\n",
            "2019-12-04 11:51:09,872 epoch 23 - iter 2/21 - loss 0.31293854 - samples/sec: 274.19\n",
            "2019-12-04 11:51:10,173 epoch 23 - iter 4/21 - loss 0.32058605 - samples/sec: 236.26\n",
            "2019-12-04 11:51:10,536 epoch 23 - iter 6/21 - loss 0.30614405 - samples/sec: 197.35\n",
            "2019-12-04 11:51:10,859 epoch 23 - iter 8/21 - loss 0.30165981 - samples/sec: 238.90\n",
            "2019-12-04 11:51:11,165 epoch 23 - iter 10/21 - loss 0.29193787 - samples/sec: 227.15\n",
            "2019-12-04 11:51:11,522 epoch 23 - iter 12/21 - loss 0.28775267 - samples/sec: 194.33\n",
            "2019-12-04 11:51:11,822 epoch 23 - iter 14/21 - loss 0.28688770 - samples/sec: 236.51\n",
            "2019-12-04 11:51:12,105 epoch 23 - iter 16/21 - loss 0.28225178 - samples/sec: 246.33\n",
            "2019-12-04 11:51:12,387 epoch 23 - iter 18/21 - loss 0.28963874 - samples/sec: 252.54\n",
            "2019-12-04 11:51:12,588 epoch 23 - iter 20/21 - loss 0.27999555 - samples/sec: 366.21\n",
            "2019-12-04 11:51:12,911 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:12,913 EPOCH 23 done: loss 0.2800 - lr 0.0250\n",
            "2019-12-04 11:51:14,084 DEV : loss 0.34618860483169556 - score 0.8272\n",
            "Epoch    22: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-12-04 11:51:14,131 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:51:14,133 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:14,932 epoch 24 - iter 0/21 - loss 0.27524900 - samples/sec: 263.96\n",
            "2019-12-04 11:51:15,266 epoch 24 - iter 2/21 - loss 0.26255745 - samples/sec: 217.88\n",
            "2019-12-04 11:51:15,620 epoch 24 - iter 4/21 - loss 0.24517955 - samples/sec: 205.48\n",
            "2019-12-04 11:51:15,945 epoch 24 - iter 6/21 - loss 0.27421020 - samples/sec: 220.61\n",
            "2019-12-04 11:51:16,231 epoch 24 - iter 8/21 - loss 0.26013495 - samples/sec: 242.39\n",
            "2019-12-04 11:51:16,522 epoch 24 - iter 10/21 - loss 0.28614283 - samples/sec: 258.43\n",
            "2019-12-04 11:51:16,773 epoch 24 - iter 12/21 - loss 0.28419561 - samples/sec: 283.23\n",
            "2019-12-04 11:51:17,041 epoch 24 - iter 14/21 - loss 0.27927263 - samples/sec: 260.38\n",
            "2019-12-04 11:51:17,358 epoch 24 - iter 16/21 - loss 0.28954083 - samples/sec: 223.34\n",
            "2019-12-04 11:51:17,669 epoch 24 - iter 18/21 - loss 0.28278556 - samples/sec: 227.44\n",
            "2019-12-04 11:51:17,884 epoch 24 - iter 20/21 - loss 0.27775015 - samples/sec: 341.69\n",
            "2019-12-04 11:51:18,194 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:18,197 EPOCH 24 done: loss 0.2778 - lr 0.0125\n",
            "2019-12-04 11:51:19,406 DEV : loss 0.2949431538581848 - score 0.8889\n",
            "2019-12-04 11:51:19,454 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:51:22,937 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:23,762 epoch 25 - iter 0/21 - loss 0.37430257 - samples/sec: 292.93\n",
            "2019-12-04 11:51:24,075 epoch 25 - iter 2/21 - loss 0.26430596 - samples/sec: 243.53\n",
            "2019-12-04 11:51:24,394 epoch 25 - iter 4/21 - loss 0.28504522 - samples/sec: 225.48\n",
            "2019-12-04 11:51:24,682 epoch 25 - iter 6/21 - loss 0.27746541 - samples/sec: 242.62\n",
            "2019-12-04 11:51:24,949 epoch 25 - iter 8/21 - loss 0.27928544 - samples/sec: 284.31\n",
            "2019-12-04 11:51:25,192 epoch 25 - iter 10/21 - loss 0.28271150 - samples/sec: 299.49\n",
            "2019-12-04 11:51:25,442 epoch 25 - iter 12/21 - loss 0.27289503 - samples/sec: 291.49\n",
            "2019-12-04 11:51:25,703 epoch 25 - iter 14/21 - loss 0.26476213 - samples/sec: 272.18\n",
            "2019-12-04 11:51:25,993 epoch 25 - iter 16/21 - loss 0.26352130 - samples/sec: 246.40\n",
            "2019-12-04 11:51:26,265 epoch 25 - iter 18/21 - loss 0.27501622 - samples/sec: 259.60\n",
            "2019-12-04 11:51:26,469 epoch 25 - iter 20/21 - loss 0.27535802 - samples/sec: 352.65\n",
            "2019-12-04 11:51:26,789 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:26,794 EPOCH 25 done: loss 0.2754 - lr 0.0125\n",
            "2019-12-04 11:51:28,003 DEV : loss 0.2900146245956421 - score 0.8889\n",
            "2019-12-04 11:51:28,075 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:51:31,531 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:32,423 epoch 26 - iter 0/21 - loss 0.30775344 - samples/sec: 312.75\n",
            "2019-12-04 11:51:32,747 epoch 26 - iter 2/21 - loss 0.24798148 - samples/sec: 220.00\n",
            "2019-12-04 11:51:33,019 epoch 26 - iter 4/21 - loss 0.28443601 - samples/sec: 261.89\n",
            "2019-12-04 11:51:33,330 epoch 26 - iter 6/21 - loss 0.26957290 - samples/sec: 233.12\n",
            "2019-12-04 11:51:33,654 epoch 26 - iter 8/21 - loss 0.24871821 - samples/sec: 218.73\n",
            "2019-12-04 11:51:33,970 epoch 26 - iter 10/21 - loss 0.24472319 - samples/sec: 242.04\n",
            "2019-12-04 11:51:34,280 epoch 26 - iter 12/21 - loss 0.24657258 - samples/sec: 221.83\n",
            "2019-12-04 11:51:34,597 epoch 26 - iter 14/21 - loss 0.25681485 - samples/sec: 221.01\n",
            "2019-12-04 11:51:34,896 epoch 26 - iter 16/21 - loss 0.26982226 - samples/sec: 239.38\n",
            "2019-12-04 11:51:35,252 epoch 26 - iter 18/21 - loss 0.26234500 - samples/sec: 194.96\n",
            "2019-12-04 11:51:35,492 epoch 26 - iter 20/21 - loss 0.26689810 - samples/sec: 302.40\n",
            "2019-12-04 11:51:35,839 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:35,843 EPOCH 26 done: loss 0.2669 - lr 0.0125\n",
            "2019-12-04 11:51:37,026 DEV : loss 0.3016722798347473 - score 0.8765\n",
            "2019-12-04 11:51:37,074 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:51:37,076 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:37,872 epoch 27 - iter 0/21 - loss 0.08997017 - samples/sec: 352.40\n",
            "2019-12-04 11:51:38,164 epoch 27 - iter 2/21 - loss 0.19556554 - samples/sec: 241.83\n",
            "2019-12-04 11:51:38,473 epoch 27 - iter 4/21 - loss 0.20765713 - samples/sec: 235.94\n",
            "2019-12-04 11:51:38,826 epoch 27 - iter 6/21 - loss 0.22866866 - samples/sec: 208.54\n",
            "2019-12-04 11:51:39,186 epoch 27 - iter 8/21 - loss 0.22700535 - samples/sec: 192.72\n",
            "2019-12-04 11:51:39,455 epoch 27 - iter 10/21 - loss 0.23148300 - samples/sec: 262.16\n",
            "2019-12-04 11:51:39,766 epoch 27 - iter 12/21 - loss 0.24824978 - samples/sec: 235.94\n",
            "2019-12-04 11:51:40,037 epoch 27 - iter 14/21 - loss 0.25363074 - samples/sec: 271.24\n",
            "2019-12-04 11:51:40,255 epoch 27 - iter 16/21 - loss 0.26289774 - samples/sec: 323.22\n",
            "2019-12-04 11:51:40,552 epoch 27 - iter 18/21 - loss 0.26913412 - samples/sec: 233.70\n",
            "2019-12-04 11:51:40,742 epoch 27 - iter 20/21 - loss 0.25838537 - samples/sec: 400.35\n",
            "2019-12-04 11:51:41,074 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:41,076 EPOCH 27 done: loss 0.2584 - lr 0.0125\n",
            "2019-12-04 11:51:42,357 DEV : loss 0.29054662585258484 - score 0.8765\n",
            "2019-12-04 11:51:42,405 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:51:42,407 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:43,217 epoch 28 - iter 0/21 - loss 0.57496607 - samples/sec: 322.79\n",
            "2019-12-04 11:51:43,555 epoch 28 - iter 2/21 - loss 0.42620805 - samples/sec: 205.71\n",
            "2019-12-04 11:51:43,935 epoch 28 - iter 4/21 - loss 0.37922891 - samples/sec: 187.94\n",
            "2019-12-04 11:51:44,300 epoch 28 - iter 6/21 - loss 0.35299722 - samples/sec: 192.94\n",
            "2019-12-04 11:51:44,706 epoch 28 - iter 8/21 - loss 0.33821619 - samples/sec: 173.77\n",
            "2019-12-04 11:51:45,078 epoch 28 - iter 10/21 - loss 0.31576670 - samples/sec: 187.19\n",
            "2019-12-04 11:51:45,429 epoch 28 - iter 12/21 - loss 0.32041699 - samples/sec: 204.61\n",
            "2019-12-04 11:51:45,795 epoch 28 - iter 14/21 - loss 0.30674938 - samples/sec: 193.66\n",
            "2019-12-04 11:51:46,143 epoch 28 - iter 16/21 - loss 0.30388254 - samples/sec: 205.65\n",
            "2019-12-04 11:51:46,509 epoch 28 - iter 18/21 - loss 0.29991498 - samples/sec: 188.64\n",
            "2019-12-04 11:51:46,773 epoch 28 - iter 20/21 - loss 0.29261108 - samples/sec: 271.43\n",
            "2019-12-04 11:51:47,080 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:47,081 EPOCH 28 done: loss 0.2926 - lr 0.0125\n",
            "2019-12-04 11:51:48,419 DEV : loss 0.28233999013900757 - score 0.8889\n",
            "Epoch    27: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-12-04 11:51:48,469 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:51:51,947 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:52,750 epoch 29 - iter 0/21 - loss 0.33493176 - samples/sec: 328.87\n",
            "2019-12-04 11:51:53,091 epoch 29 - iter 2/21 - loss 0.28472542 - samples/sec: 205.03\n",
            "2019-12-04 11:51:53,531 epoch 29 - iter 4/21 - loss 0.25097672 - samples/sec: 158.17\n",
            "2019-12-04 11:51:53,929 epoch 29 - iter 6/21 - loss 0.24647904 - samples/sec: 174.54\n",
            "2019-12-04 11:51:54,251 epoch 29 - iter 8/21 - loss 0.24264470 - samples/sec: 217.44\n",
            "2019-12-04 11:51:54,587 epoch 29 - iter 10/21 - loss 0.23573858 - samples/sec: 213.99\n",
            "2019-12-04 11:51:54,998 epoch 29 - iter 12/21 - loss 0.23834315 - samples/sec: 168.62\n",
            "2019-12-04 11:51:55,337 epoch 29 - iter 14/21 - loss 0.25729905 - samples/sec: 208.35\n",
            "2019-12-04 11:51:55,715 epoch 29 - iter 16/21 - loss 0.26306480 - samples/sec: 182.29\n",
            "2019-12-04 11:51:56,062 epoch 29 - iter 18/21 - loss 0.26275479 - samples/sec: 198.20\n",
            "2019-12-04 11:51:56,280 epoch 29 - iter 20/21 - loss 0.28691491 - samples/sec: 331.53\n",
            "2019-12-04 11:51:56,608 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:51:56,611 EPOCH 29 done: loss 0.2869 - lr 0.0063\n",
            "2019-12-04 11:52:01,665 DEV : loss 0.2896624803543091 - score 0.8889\n",
            "2019-12-04 11:52:01,716 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:52:05,096 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:05,948 epoch 30 - iter 0/21 - loss 0.39939022 - samples/sec: 252.90\n",
            "2019-12-04 11:52:06,332 epoch 30 - iter 2/21 - loss 0.41478621 - samples/sec: 192.58\n",
            "2019-12-04 11:52:06,728 epoch 30 - iter 4/21 - loss 0.36682393 - samples/sec: 187.79\n",
            "2019-12-04 11:52:07,045 epoch 30 - iter 6/21 - loss 0.33755558 - samples/sec: 218.80\n",
            "2019-12-04 11:52:07,402 epoch 30 - iter 8/21 - loss 0.32790099 - samples/sec: 198.04\n",
            "2019-12-04 11:52:07,767 epoch 30 - iter 10/21 - loss 0.31709559 - samples/sec: 223.50\n",
            "2019-12-04 11:52:08,112 epoch 30 - iter 12/21 - loss 0.31398375 - samples/sec: 205.26\n",
            "2019-12-04 11:52:08,438 epoch 30 - iter 14/21 - loss 0.31607041 - samples/sec: 215.02\n",
            "2019-12-04 11:52:08,792 epoch 30 - iter 16/21 - loss 0.30415634 - samples/sec: 212.26\n",
            "2019-12-04 11:52:09,136 epoch 30 - iter 18/21 - loss 0.29033724 - samples/sec: 203.02\n",
            "2019-12-04 11:52:09,395 epoch 30 - iter 20/21 - loss 0.29055670 - samples/sec: 280.61\n",
            "2019-12-04 11:52:09,710 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:09,713 EPOCH 30 done: loss 0.2906 - lr 0.0063\n",
            "2019-12-04 11:52:11,020 DEV : loss 0.2854907214641571 - score 0.9012\n",
            "2019-12-04 11:52:11,072 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:52:14,534 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:15,447 epoch 31 - iter 0/21 - loss 0.23945308 - samples/sec: 316.44\n",
            "2019-12-04 11:52:15,825 epoch 31 - iter 2/21 - loss 0.23285576 - samples/sec: 200.71\n",
            "2019-12-04 11:52:16,119 epoch 31 - iter 4/21 - loss 0.25161374 - samples/sec: 236.34\n",
            "2019-12-04 11:52:16,405 epoch 31 - iter 6/21 - loss 0.25769853 - samples/sec: 259.43\n",
            "2019-12-04 11:52:16,744 epoch 31 - iter 8/21 - loss 0.26541453 - samples/sec: 210.22\n",
            "2019-12-04 11:52:17,070 epoch 31 - iter 10/21 - loss 0.25209647 - samples/sec: 215.49\n",
            "2019-12-04 11:52:17,415 epoch 31 - iter 12/21 - loss 0.27887747 - samples/sec: 213.97\n",
            "2019-12-04 11:52:17,766 epoch 31 - iter 14/21 - loss 0.27254093 - samples/sec: 206.21\n",
            "2019-12-04 11:52:18,062 epoch 31 - iter 16/21 - loss 0.26548926 - samples/sec: 245.61\n",
            "2019-12-04 11:52:18,353 epoch 31 - iter 18/21 - loss 0.25644613 - samples/sec: 246.58\n",
            "2019-12-04 11:52:18,546 epoch 31 - iter 20/21 - loss 0.24984769 - samples/sec: 401.42\n",
            "2019-12-04 11:52:18,887 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:18,891 EPOCH 31 done: loss 0.2498 - lr 0.0063\n",
            "2019-12-04 11:52:20,158 DEV : loss 0.2775362432003021 - score 0.9012\n",
            "2019-12-04 11:52:20,208 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:52:23,591 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:24,446 epoch 32 - iter 0/21 - loss 0.16944847 - samples/sec: 269.30\n",
            "2019-12-04 11:52:24,775 epoch 32 - iter 2/21 - loss 0.19709795 - samples/sec: 240.43\n",
            "2019-12-04 11:52:25,065 epoch 32 - iter 4/21 - loss 0.23045011 - samples/sec: 243.17\n",
            "2019-12-04 11:52:25,414 epoch 32 - iter 6/21 - loss 0.20150256 - samples/sec: 203.20\n",
            "2019-12-04 11:52:25,744 epoch 32 - iter 8/21 - loss 0.20773658 - samples/sec: 232.37\n",
            "2019-12-04 11:52:26,011 epoch 32 - iter 10/21 - loss 0.24300798 - samples/sec: 263.26\n",
            "2019-12-04 11:52:26,295 epoch 32 - iter 12/21 - loss 0.27018522 - samples/sec: 245.93\n",
            "2019-12-04 11:52:26,700 epoch 32 - iter 14/21 - loss 0.26712446 - samples/sec: 188.36\n",
            "2019-12-04 11:52:27,020 epoch 32 - iter 16/21 - loss 0.26932756 - samples/sec: 225.19\n",
            "2019-12-04 11:52:27,336 epoch 32 - iter 18/21 - loss 0.25703230 - samples/sec: 218.45\n",
            "2019-12-04 11:52:27,537 epoch 32 - iter 20/21 - loss 0.25173685 - samples/sec: 372.00\n",
            "2019-12-04 11:52:27,877 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:27,880 EPOCH 32 done: loss 0.2517 - lr 0.0063\n",
            "2019-12-04 11:52:29,180 DEV : loss 0.2765371799468994 - score 0.9012\n",
            "2019-12-04 11:52:29,230 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:52:32,592 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:33,523 epoch 33 - iter 0/21 - loss 0.31309032 - samples/sec: 333.27\n",
            "2019-12-04 11:52:33,882 epoch 33 - iter 2/21 - loss 0.26036057 - samples/sec: 197.33\n",
            "2019-12-04 11:52:34,182 epoch 33 - iter 4/21 - loss 0.27954803 - samples/sec: 234.70\n",
            "2019-12-04 11:52:34,468 epoch 33 - iter 6/21 - loss 0.29617834 - samples/sec: 259.23\n",
            "2019-12-04 11:52:34,768 epoch 33 - iter 8/21 - loss 0.26312831 - samples/sec: 230.89\n",
            "2019-12-04 11:52:35,065 epoch 33 - iter 10/21 - loss 0.26780102 - samples/sec: 240.36\n",
            "2019-12-04 11:52:35,429 epoch 33 - iter 12/21 - loss 0.27082288 - samples/sec: 212.51\n",
            "2019-12-04 11:52:35,719 epoch 33 - iter 14/21 - loss 0.26176731 - samples/sec: 244.57\n",
            "2019-12-04 11:52:36,047 epoch 33 - iter 16/21 - loss 0.27351461 - samples/sec: 215.87\n",
            "2019-12-04 11:52:36,380 epoch 33 - iter 18/21 - loss 0.28185119 - samples/sec: 214.70\n",
            "2019-12-04 11:52:36,599 epoch 33 - iter 20/21 - loss 0.26693045 - samples/sec: 333.38\n",
            "2019-12-04 11:52:36,940 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:36,941 EPOCH 33 done: loss 0.2669 - lr 0.0063\n",
            "2019-12-04 11:52:38,206 DEV : loss 0.2761792540550232 - score 0.9012\n",
            "2019-12-04 11:52:38,257 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:52:41,651 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:42,465 epoch 34 - iter 0/21 - loss 0.30300730 - samples/sec: 312.37\n",
            "2019-12-04 11:52:42,774 epoch 34 - iter 2/21 - loss 0.29819276 - samples/sec: 244.33\n",
            "2019-12-04 11:52:43,034 epoch 34 - iter 4/21 - loss 0.28653874 - samples/sec: 276.85\n",
            "2019-12-04 11:52:43,374 epoch 34 - iter 6/21 - loss 0.26733661 - samples/sec: 206.93\n",
            "2019-12-04 11:52:43,703 epoch 34 - iter 8/21 - loss 0.26959074 - samples/sec: 226.64\n",
            "2019-12-04 11:52:43,977 epoch 34 - iter 10/21 - loss 0.25620399 - samples/sec: 257.28\n",
            "2019-12-04 11:52:44,328 epoch 34 - iter 12/21 - loss 0.24417435 - samples/sec: 197.26\n",
            "2019-12-04 11:52:44,670 epoch 34 - iter 14/21 - loss 0.24643241 - samples/sec: 214.62\n",
            "2019-12-04 11:52:45,004 epoch 34 - iter 16/21 - loss 0.24575474 - samples/sec: 213.86\n",
            "2019-12-04 11:52:45,349 epoch 34 - iter 18/21 - loss 0.25022752 - samples/sec: 201.69\n",
            "2019-12-04 11:52:45,592 epoch 34 - iter 20/21 - loss 0.24004142 - samples/sec: 299.67\n",
            "2019-12-04 11:52:45,928 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:45,931 EPOCH 34 done: loss 0.2400 - lr 0.0063\n",
            "2019-12-04 11:52:47,134 DEV : loss 0.2755809724330902 - score 0.9012\n",
            "Epoch    33: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-12-04 11:52:47,183 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:52:50,612 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:51,513 epoch 35 - iter 0/21 - loss 0.20708489 - samples/sec: 329.20\n",
            "2019-12-04 11:52:51,855 epoch 35 - iter 2/21 - loss 0.19647705 - samples/sec: 223.57\n",
            "2019-12-04 11:52:52,122 epoch 35 - iter 4/21 - loss 0.27789051 - samples/sec: 261.93\n",
            "2019-12-04 11:52:52,436 epoch 35 - iter 6/21 - loss 0.28675738 - samples/sec: 219.49\n",
            "2019-12-04 11:52:52,748 epoch 35 - iter 8/21 - loss 0.27107857 - samples/sec: 235.37\n",
            "2019-12-04 11:52:53,043 epoch 35 - iter 10/21 - loss 0.26585675 - samples/sec: 242.41\n",
            "2019-12-04 11:52:53,316 epoch 35 - iter 12/21 - loss 0.26233787 - samples/sec: 273.34\n",
            "2019-12-04 11:52:53,620 epoch 35 - iter 14/21 - loss 0.24717758 - samples/sec: 226.71\n",
            "2019-12-04 11:52:53,914 epoch 35 - iter 16/21 - loss 0.25621918 - samples/sec: 240.11\n",
            "2019-12-04 11:52:54,187 epoch 35 - iter 18/21 - loss 0.25334946 - samples/sec: 257.84\n",
            "2019-12-04 11:52:54,366 epoch 35 - iter 20/21 - loss 0.24854473 - samples/sec: 424.46\n",
            "2019-12-04 11:52:54,691 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:52:54,692 EPOCH 35 done: loss 0.2485 - lr 0.0031\n",
            "2019-12-04 11:52:55,931 DEV : loss 0.2751701772212982 - score 0.9012\n",
            "2019-12-04 11:52:55,984 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:52:59,417 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:00,313 epoch 36 - iter 0/21 - loss 0.18832175 - samples/sec: 401.01\n",
            "2019-12-04 11:53:00,698 epoch 36 - iter 2/21 - loss 0.19718251 - samples/sec: 185.27\n",
            "2019-12-04 11:53:01,005 epoch 36 - iter 4/21 - loss 0.21727685 - samples/sec: 231.78\n",
            "2019-12-04 11:53:01,306 epoch 36 - iter 6/21 - loss 0.22338475 - samples/sec: 251.56\n",
            "2019-12-04 11:53:01,585 epoch 36 - iter 8/21 - loss 0.23784025 - samples/sec: 249.18\n",
            "2019-12-04 11:53:01,889 epoch 36 - iter 10/21 - loss 0.24442081 - samples/sec: 229.59\n",
            "2019-12-04 11:53:02,219 epoch 36 - iter 12/21 - loss 0.24243769 - samples/sec: 223.66\n",
            "2019-12-04 11:53:02,535 epoch 36 - iter 14/21 - loss 0.25602050 - samples/sec: 228.45\n",
            "2019-12-04 11:53:02,838 epoch 36 - iter 16/21 - loss 0.25321639 - samples/sec: 232.38\n",
            "2019-12-04 11:53:03,175 epoch 36 - iter 18/21 - loss 0.25298035 - samples/sec: 207.46\n",
            "2019-12-04 11:53:03,354 epoch 36 - iter 20/21 - loss 0.25220197 - samples/sec: 414.84\n",
            "2019-12-04 11:53:03,681 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:03,683 EPOCH 36 done: loss 0.2522 - lr 0.0031\n",
            "2019-12-04 11:53:04,916 DEV : loss 0.27596530318260193 - score 0.9136\n",
            "2019-12-04 11:53:04,965 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:53:08,421 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:09,326 epoch 37 - iter 0/21 - loss 0.36199549 - samples/sec: 260.15\n",
            "2019-12-04 11:53:09,693 epoch 37 - iter 2/21 - loss 0.31443716 - samples/sec: 205.76\n",
            "2019-12-04 11:53:09,987 epoch 37 - iter 4/21 - loss 0.27368268 - samples/sec: 241.95\n",
            "2019-12-04 11:53:10,251 epoch 37 - iter 6/21 - loss 0.27407201 - samples/sec: 269.86\n",
            "2019-12-04 11:53:10,609 epoch 37 - iter 8/21 - loss 0.25899466 - samples/sec: 199.56\n",
            "2019-12-04 11:53:10,909 epoch 37 - iter 10/21 - loss 0.25651192 - samples/sec: 248.71\n",
            "2019-12-04 11:53:11,209 epoch 37 - iter 12/21 - loss 0.25111643 - samples/sec: 234.95\n",
            "2019-12-04 11:53:11,524 epoch 37 - iter 14/21 - loss 0.25826070 - samples/sec: 219.39\n",
            "2019-12-04 11:53:11,861 epoch 37 - iter 16/21 - loss 0.24971264 - samples/sec: 211.79\n",
            "2019-12-04 11:53:12,146 epoch 37 - iter 18/21 - loss 0.25201685 - samples/sec: 243.84\n",
            "2019-12-04 11:53:12,326 epoch 37 - iter 20/21 - loss 0.25518627 - samples/sec: 421.16\n",
            "2019-12-04 11:53:12,661 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:12,666 EPOCH 37 done: loss 0.2552 - lr 0.0031\n",
            "2019-12-04 11:53:13,822 DEV : loss 0.27500319480895996 - score 0.9012\n",
            "2019-12-04 11:53:13,874 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:53:13,876 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:14,651 epoch 38 - iter 0/21 - loss 0.28242156 - samples/sec: 316.49\n",
            "2019-12-04 11:53:14,951 epoch 38 - iter 2/21 - loss 0.29813836 - samples/sec: 246.11\n",
            "2019-12-04 11:53:15,226 epoch 38 - iter 4/21 - loss 0.25376004 - samples/sec: 257.74\n",
            "2019-12-04 11:53:15,499 epoch 38 - iter 6/21 - loss 0.26276079 - samples/sec: 262.53\n",
            "2019-12-04 11:53:15,831 epoch 38 - iter 8/21 - loss 0.26147402 - samples/sec: 212.44\n",
            "2019-12-04 11:53:16,106 epoch 38 - iter 10/21 - loss 0.26346142 - samples/sec: 255.88\n",
            "2019-12-04 11:53:16,406 epoch 38 - iter 12/21 - loss 0.27329529 - samples/sec: 241.18\n",
            "2019-12-04 11:53:16,718 epoch 38 - iter 14/21 - loss 0.27019993 - samples/sec: 224.23\n",
            "2019-12-04 11:53:17,029 epoch 38 - iter 16/21 - loss 0.26360879 - samples/sec: 225.33\n",
            "2019-12-04 11:53:17,375 epoch 38 - iter 18/21 - loss 0.26185455 - samples/sec: 204.34\n",
            "2019-12-04 11:53:17,562 epoch 38 - iter 20/21 - loss 0.25642689 - samples/sec: 400.51\n",
            "2019-12-04 11:53:17,891 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:17,893 EPOCH 38 done: loss 0.2564 - lr 0.0031\n",
            "2019-12-04 11:53:19,123 DEV : loss 0.2751096189022064 - score 0.9012\n",
            "2019-12-04 11:53:19,170 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:53:19,171 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:19,936 epoch 39 - iter 0/21 - loss 0.19713433 - samples/sec: 331.75\n",
            "2019-12-04 11:53:20,262 epoch 39 - iter 2/21 - loss 0.22701711 - samples/sec: 217.67\n",
            "2019-12-04 11:53:20,628 epoch 39 - iter 4/21 - loss 0.21963677 - samples/sec: 201.34\n",
            "2019-12-04 11:53:20,891 epoch 39 - iter 6/21 - loss 0.23213987 - samples/sec: 278.60\n",
            "2019-12-04 11:53:21,239 epoch 39 - iter 8/21 - loss 0.24223364 - samples/sec: 199.44\n",
            "2019-12-04 11:53:21,594 epoch 39 - iter 10/21 - loss 0.24015146 - samples/sec: 205.61\n",
            "2019-12-04 11:53:21,923 epoch 39 - iter 12/21 - loss 0.23789989 - samples/sec: 215.09\n",
            "2019-12-04 11:53:22,232 epoch 39 - iter 14/21 - loss 0.25636413 - samples/sec: 225.57\n",
            "2019-12-04 11:53:22,547 epoch 39 - iter 16/21 - loss 0.24716793 - samples/sec: 228.87\n",
            "2019-12-04 11:53:22,864 epoch 39 - iter 18/21 - loss 0.24818087 - samples/sec: 221.68\n",
            "2019-12-04 11:53:23,075 epoch 39 - iter 20/21 - loss 0.24621600 - samples/sec: 350.81\n",
            "2019-12-04 11:53:23,400 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:23,403 EPOCH 39 done: loss 0.2462 - lr 0.0031\n",
            "2019-12-04 11:53:24,617 DEV : loss 0.27468568086624146 - score 0.9012\n",
            "2019-12-04 11:53:24,667 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:53:24,668 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:25,474 epoch 40 - iter 0/21 - loss 0.21634331 - samples/sec: 301.51\n",
            "2019-12-04 11:53:25,820 epoch 40 - iter 2/21 - loss 0.31404179 - samples/sec: 202.90\n",
            "2019-12-04 11:53:26,150 epoch 40 - iter 4/21 - loss 0.30294273 - samples/sec: 228.36\n",
            "2019-12-04 11:53:26,440 epoch 40 - iter 6/21 - loss 0.29052630 - samples/sec: 244.24\n",
            "2019-12-04 11:53:26,747 epoch 40 - iter 8/21 - loss 0.27497520 - samples/sec: 224.06\n",
            "2019-12-04 11:53:27,086 epoch 40 - iter 10/21 - loss 0.26686085 - samples/sec: 219.98\n",
            "2019-12-04 11:53:27,372 epoch 40 - iter 12/21 - loss 0.26289745 - samples/sec: 248.39\n",
            "2019-12-04 11:53:27,703 epoch 40 - iter 14/21 - loss 0.27301658 - samples/sec: 211.03\n",
            "2019-12-04 11:53:28,020 epoch 40 - iter 16/21 - loss 0.26098683 - samples/sec: 225.65\n",
            "2019-12-04 11:53:28,307 epoch 40 - iter 18/21 - loss 0.26601580 - samples/sec: 241.90\n",
            "2019-12-04 11:53:28,524 epoch 40 - iter 20/21 - loss 0.26764934 - samples/sec: 330.59\n",
            "2019-12-04 11:53:28,851 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:28,854 EPOCH 40 done: loss 0.2676 - lr 0.0031\n",
            "2019-12-04 11:53:30,068 DEV : loss 0.27483317255973816 - score 0.9012\n",
            "Epoch    39: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2019-12-04 11:53:30,123 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:53:30,126 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:30,907 epoch 41 - iter 0/21 - loss 0.53476918 - samples/sec: 423.08\n",
            "2019-12-04 11:53:31,203 epoch 41 - iter 2/21 - loss 0.33364660 - samples/sec: 236.16\n",
            "2019-12-04 11:53:31,534 epoch 41 - iter 4/21 - loss 0.31688423 - samples/sec: 215.12\n",
            "2019-12-04 11:53:31,855 epoch 41 - iter 6/21 - loss 0.29845272 - samples/sec: 224.04\n",
            "2019-12-04 11:53:32,136 epoch 41 - iter 8/21 - loss 0.27218569 - samples/sec: 247.00\n",
            "2019-12-04 11:53:32,396 epoch 41 - iter 10/21 - loss 0.25843249 - samples/sec: 272.90\n",
            "2019-12-04 11:53:32,715 epoch 41 - iter 12/21 - loss 0.25000970 - samples/sec: 227.62\n",
            "2019-12-04 11:53:33,020 epoch 41 - iter 14/21 - loss 0.25309203 - samples/sec: 225.97\n",
            "2019-12-04 11:53:33,316 epoch 41 - iter 16/21 - loss 0.25223333 - samples/sec: 239.07\n",
            "2019-12-04 11:53:33,592 epoch 41 - iter 18/21 - loss 0.24791033 - samples/sec: 255.91\n",
            "2019-12-04 11:53:33,781 epoch 41 - iter 20/21 - loss 0.23951446 - samples/sec: 383.65\n",
            "2019-12-04 11:53:34,106 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:34,112 EPOCH 41 done: loss 0.2395 - lr 0.0016\n",
            "2019-12-04 11:53:35,346 DEV : loss 0.2744297385215759 - score 0.9012\n",
            "2019-12-04 11:53:35,394 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:53:35,395 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:36,191 epoch 42 - iter 0/21 - loss 0.18728676 - samples/sec: 274.98\n",
            "2019-12-04 11:53:36,519 epoch 42 - iter 2/21 - loss 0.20647345 - samples/sec: 217.89\n",
            "2019-12-04 11:53:36,865 epoch 42 - iter 4/21 - loss 0.23635439 - samples/sec: 209.23\n",
            "2019-12-04 11:53:37,241 epoch 42 - iter 6/21 - loss 0.25754843 - samples/sec: 191.75\n",
            "2019-12-04 11:53:37,587 epoch 42 - iter 8/21 - loss 0.27924105 - samples/sec: 200.92\n",
            "2019-12-04 11:53:37,907 epoch 42 - iter 10/21 - loss 0.26778059 - samples/sec: 228.46\n",
            "2019-12-04 11:53:38,220 epoch 42 - iter 12/21 - loss 0.25950460 - samples/sec: 222.96\n",
            "2019-12-04 11:53:38,499 epoch 42 - iter 14/21 - loss 0.26835396 - samples/sec: 250.27\n",
            "2019-12-04 11:53:38,768 epoch 42 - iter 16/21 - loss 0.27030616 - samples/sec: 265.79\n",
            "2019-12-04 11:53:39,032 epoch 42 - iter 18/21 - loss 0.27481111 - samples/sec: 268.94\n",
            "2019-12-04 11:53:39,239 epoch 42 - iter 20/21 - loss 0.26794600 - samples/sec: 360.00\n",
            "2019-12-04 11:53:39,574 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:39,579 EPOCH 42 done: loss 0.2679 - lr 0.0016\n",
            "2019-12-04 11:53:40,800 DEV : loss 0.274540513753891 - score 0.9012\n",
            "2019-12-04 11:53:40,852 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:53:40,856 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:41,668 epoch 43 - iter 0/21 - loss 0.37052643 - samples/sec: 296.45\n",
            "2019-12-04 11:53:41,970 epoch 43 - iter 2/21 - loss 0.34135433 - samples/sec: 245.05\n",
            "2019-12-04 11:53:42,313 epoch 43 - iter 4/21 - loss 0.29725989 - samples/sec: 201.83\n",
            "2019-12-04 11:53:42,679 epoch 43 - iter 6/21 - loss 0.29462473 - samples/sec: 193.31\n",
            "2019-12-04 11:53:42,995 epoch 43 - iter 8/21 - loss 0.26894911 - samples/sec: 228.16\n",
            "2019-12-04 11:53:43,338 epoch 43 - iter 10/21 - loss 0.27223245 - samples/sec: 201.17\n",
            "2019-12-04 11:53:43,660 epoch 43 - iter 12/21 - loss 0.26289231 - samples/sec: 231.04\n",
            "2019-12-04 11:53:43,940 epoch 43 - iter 14/21 - loss 0.24737022 - samples/sec: 252.96\n",
            "2019-12-04 11:53:44,242 epoch 43 - iter 16/21 - loss 0.24729843 - samples/sec: 231.34\n",
            "2019-12-04 11:53:44,532 epoch 43 - iter 18/21 - loss 0.24368885 - samples/sec: 250.58\n",
            "2019-12-04 11:53:44,693 epoch 43 - iter 20/21 - loss 0.23702592 - samples/sec: 472.31\n",
            "2019-12-04 11:53:45,021 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:45,028 EPOCH 43 done: loss 0.2370 - lr 0.0016\n",
            "2019-12-04 11:53:46,224 DEV : loss 0.2740192115306854 - score 0.9012\n",
            "2019-12-04 11:53:46,273 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:53:46,275 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:47,042 epoch 44 - iter 0/21 - loss 0.22163287 - samples/sec: 344.03\n",
            "2019-12-04 11:53:47,386 epoch 44 - iter 2/21 - loss 0.21982748 - samples/sec: 212.50\n",
            "2019-12-04 11:53:47,714 epoch 44 - iter 4/21 - loss 0.22116260 - samples/sec: 229.02\n",
            "2019-12-04 11:53:47,992 epoch 44 - iter 6/21 - loss 0.25373337 - samples/sec: 253.86\n",
            "2019-12-04 11:53:48,258 epoch 44 - iter 8/21 - loss 0.25628161 - samples/sec: 262.60\n",
            "2019-12-04 11:53:48,620 epoch 44 - iter 10/21 - loss 0.24127068 - samples/sec: 193.92\n",
            "2019-12-04 11:53:48,913 epoch 44 - iter 12/21 - loss 0.23649158 - samples/sec: 241.37\n",
            "2019-12-04 11:53:49,180 epoch 44 - iter 14/21 - loss 0.23791279 - samples/sec: 261.51\n",
            "2019-12-04 11:53:49,474 epoch 44 - iter 16/21 - loss 0.24362568 - samples/sec: 248.92\n",
            "2019-12-04 11:53:49,802 epoch 44 - iter 18/21 - loss 0.24904120 - samples/sec: 214.20\n",
            "2019-12-04 11:53:49,997 epoch 44 - iter 20/21 - loss 0.23879274 - samples/sec: 392.34\n",
            "2019-12-04 11:53:50,312 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:50,313 EPOCH 44 done: loss 0.2388 - lr 0.0016\n",
            "2019-12-04 11:53:51,474 DEV : loss 0.273870050907135 - score 0.9012\n",
            "Epoch    43: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2019-12-04 11:53:51,527 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:53:51,529 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:52,322 epoch 45 - iter 0/21 - loss 0.21784469 - samples/sec: 263.45\n",
            "2019-12-04 11:53:52,630 epoch 45 - iter 2/21 - loss 0.15821483 - samples/sec: 237.21\n",
            "2019-12-04 11:53:56,809 epoch 45 - iter 4/21 - loss 0.19064373 - samples/sec: 15.46\n",
            "2019-12-04 11:53:57,071 epoch 45 - iter 6/21 - loss 0.19770137 - samples/sec: 281.78\n",
            "2019-12-04 11:53:57,322 epoch 45 - iter 8/21 - loss 0.18755657 - samples/sec: 288.32\n",
            "2019-12-04 11:53:57,603 epoch 45 - iter 10/21 - loss 0.19041372 - samples/sec: 259.31\n",
            "2019-12-04 11:53:57,851 epoch 45 - iter 12/21 - loss 0.20089596 - samples/sec: 291.51\n",
            "2019-12-04 11:53:58,130 epoch 45 - iter 14/21 - loss 0.20494540 - samples/sec: 248.52\n",
            "2019-12-04 11:53:58,405 epoch 45 - iter 16/21 - loss 0.20878015 - samples/sec: 270.86\n",
            "2019-12-04 11:53:58,633 epoch 45 - iter 18/21 - loss 0.22412811 - samples/sec: 311.58\n",
            "2019-12-04 11:53:58,853 epoch 45 - iter 20/21 - loss 0.23566427 - samples/sec: 329.08\n",
            "2019-12-04 11:53:59,230 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:53:59,232 EPOCH 45 done: loss 0.2357 - lr 0.0008\n",
            "2019-12-04 11:54:00,401 DEV : loss 0.2738293409347534 - score 0.9012\n",
            "2019-12-04 11:54:00,449 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:54:00,450 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:01,221 epoch 46 - iter 0/21 - loss 0.13987577 - samples/sec: 399.76\n",
            "2019-12-04 11:54:01,604 epoch 46 - iter 2/21 - loss 0.22370135 - samples/sec: 181.09\n",
            "2019-12-04 11:54:01,904 epoch 46 - iter 4/21 - loss 0.26347446 - samples/sec: 244.85\n",
            "2019-12-04 11:54:02,210 epoch 46 - iter 6/21 - loss 0.26615171 - samples/sec: 256.46\n",
            "2019-12-04 11:54:02,472 epoch 46 - iter 8/21 - loss 0.24992268 - samples/sec: 265.82\n",
            "2019-12-04 11:54:02,764 epoch 46 - iter 10/21 - loss 0.25077541 - samples/sec: 236.60\n",
            "2019-12-04 11:54:03,095 epoch 46 - iter 12/21 - loss 0.24144775 - samples/sec: 215.34\n",
            "2019-12-04 11:54:03,377 epoch 46 - iter 14/21 - loss 0.24093069 - samples/sec: 249.38\n",
            "2019-12-04 11:54:03,627 epoch 46 - iter 16/21 - loss 0.25523259 - samples/sec: 280.99\n",
            "2019-12-04 11:54:03,874 epoch 46 - iter 18/21 - loss 0.24962167 - samples/sec: 295.96\n",
            "2019-12-04 11:54:04,056 epoch 46 - iter 20/21 - loss 0.25195817 - samples/sec: 400.94\n",
            "2019-12-04 11:54:04,383 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:04,387 EPOCH 46 done: loss 0.2520 - lr 0.0008\n",
            "2019-12-04 11:54:05,552 DEV : loss 0.2735658288002014 - score 0.9012\n",
            "2019-12-04 11:54:05,601 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:54:05,602 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:06,366 epoch 47 - iter 0/21 - loss 0.16168761 - samples/sec: 367.19\n",
            "2019-12-04 11:54:06,647 epoch 47 - iter 2/21 - loss 0.19258846 - samples/sec: 265.59\n",
            "2019-12-04 11:54:07,003 epoch 47 - iter 4/21 - loss 0.18794797 - samples/sec: 207.47\n",
            "2019-12-04 11:54:07,345 epoch 47 - iter 6/21 - loss 0.20817112 - samples/sec: 204.52\n",
            "2019-12-04 11:54:07,682 epoch 47 - iter 8/21 - loss 0.21182922 - samples/sec: 207.95\n",
            "2019-12-04 11:54:07,974 epoch 47 - iter 10/21 - loss 0.22103157 - samples/sec: 254.50\n",
            "2019-12-04 11:54:08,229 epoch 47 - iter 12/21 - loss 0.22801040 - samples/sec: 274.82\n",
            "2019-12-04 11:54:08,481 epoch 47 - iter 14/21 - loss 0.23483789 - samples/sec: 279.13\n",
            "2019-12-04 11:54:08,764 epoch 47 - iter 16/21 - loss 0.25292898 - samples/sec: 258.52\n",
            "2019-12-04 11:54:09,064 epoch 47 - iter 18/21 - loss 0.25882766 - samples/sec: 230.09\n",
            "2019-12-04 11:54:09,278 epoch 47 - iter 20/21 - loss 0.24609242 - samples/sec: 332.83\n",
            "2019-12-04 11:54:09,602 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:09,610 EPOCH 47 done: loss 0.2461 - lr 0.0008\n",
            "2019-12-04 11:54:10,842 DEV : loss 0.27350378036499023 - score 0.9012\n",
            "2019-12-04 11:54:10,891 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:54:10,892 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:11,650 epoch 48 - iter 0/21 - loss 0.31322232 - samples/sec: 334.43\n",
            "2019-12-04 11:54:11,950 epoch 48 - iter 2/21 - loss 0.25133646 - samples/sec: 243.59\n",
            "2019-12-04 11:54:12,219 epoch 48 - iter 4/21 - loss 0.23268075 - samples/sec: 276.83\n",
            "2019-12-04 11:54:12,492 epoch 48 - iter 6/21 - loss 0.26875044 - samples/sec: 265.82\n",
            "2019-12-04 11:54:12,792 epoch 48 - iter 8/21 - loss 0.26628413 - samples/sec: 231.25\n",
            "2019-12-04 11:54:13,063 epoch 48 - iter 10/21 - loss 0.25453470 - samples/sec: 284.05\n",
            "2019-12-04 11:54:13,376 epoch 48 - iter 12/21 - loss 0.26719330 - samples/sec: 220.39\n",
            "2019-12-04 11:54:13,661 epoch 48 - iter 14/21 - loss 0.27170430 - samples/sec: 251.10\n",
            "2019-12-04 11:54:13,998 epoch 48 - iter 16/21 - loss 0.26267557 - samples/sec: 205.71\n",
            "2019-12-04 11:54:14,324 epoch 48 - iter 18/21 - loss 0.25602278 - samples/sec: 214.95\n",
            "2019-12-04 11:54:14,592 epoch 48 - iter 20/21 - loss 0.26458718 - samples/sec: 269.33\n",
            "2019-12-04 11:54:14,914 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:14,917 EPOCH 48 done: loss 0.2646 - lr 0.0008\n",
            "2019-12-04 11:54:16,151 DEV : loss 0.27343249320983887 - score 0.9012\n",
            "Epoch    47: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2019-12-04 11:54:16,199 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:54:16,201 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:16,993 epoch 49 - iter 0/21 - loss 0.20930751 - samples/sec: 421.32\n",
            "2019-12-04 11:54:17,364 epoch 49 - iter 2/21 - loss 0.30069684 - samples/sec: 185.28\n",
            "2019-12-04 11:54:17,750 epoch 49 - iter 4/21 - loss 0.30208309 - samples/sec: 191.46\n",
            "2019-12-04 11:54:18,032 epoch 49 - iter 6/21 - loss 0.30557992 - samples/sec: 250.92\n",
            "2019-12-04 11:54:18,382 epoch 49 - iter 8/21 - loss 0.29437956 - samples/sec: 220.63\n",
            "2019-12-04 11:54:18,705 epoch 49 - iter 10/21 - loss 0.29694123 - samples/sec: 212.17\n",
            "2019-12-04 11:54:19,067 epoch 49 - iter 12/21 - loss 0.28723679 - samples/sec: 205.80\n",
            "2019-12-04 11:54:19,406 epoch 49 - iter 14/21 - loss 0.27706774 - samples/sec: 208.00\n",
            "2019-12-04 11:54:19,712 epoch 49 - iter 16/21 - loss 0.26231007 - samples/sec: 230.25\n",
            "2019-12-04 11:54:19,987 epoch 49 - iter 18/21 - loss 0.25957675 - samples/sec: 256.99\n",
            "2019-12-04 11:54:20,202 epoch 49 - iter 20/21 - loss 0.24966311 - samples/sec: 338.67\n",
            "2019-12-04 11:54:20,520 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:20,523 EPOCH 49 done: loss 0.2497 - lr 0.0004\n",
            "2019-12-04 11:54:21,735 DEV : loss 0.27339839935302734 - score 0.9012\n",
            "2019-12-04 11:54:21,786 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:54:21,788 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:22,543 epoch 50 - iter 0/21 - loss 0.25597253 - samples/sec: 426.56\n",
            "2019-12-04 11:54:22,884 epoch 50 - iter 2/21 - loss 0.25447257 - samples/sec: 236.32\n",
            "2019-12-04 11:54:23,203 epoch 50 - iter 4/21 - loss 0.25881966 - samples/sec: 220.63\n",
            "2019-12-04 11:54:23,519 epoch 50 - iter 6/21 - loss 0.23642025 - samples/sec: 218.63\n",
            "2019-12-04 11:54:23,878 epoch 50 - iter 8/21 - loss 0.25138448 - samples/sec: 201.63\n",
            "2019-12-04 11:54:24,168 epoch 50 - iter 10/21 - loss 0.26052999 - samples/sec: 270.00\n",
            "2019-12-04 11:54:24,502 epoch 50 - iter 12/21 - loss 0.25008317 - samples/sec: 205.47\n",
            "2019-12-04 11:54:24,826 epoch 50 - iter 14/21 - loss 0.24275887 - samples/sec: 218.01\n",
            "2019-12-04 11:54:25,120 epoch 50 - iter 16/21 - loss 0.24429293 - samples/sec: 249.88\n",
            "2019-12-04 11:54:25,378 epoch 50 - iter 18/21 - loss 0.26393261 - samples/sec: 270.71\n",
            "2019-12-04 11:54:25,604 epoch 50 - iter 20/21 - loss 0.25536212 - samples/sec: 323.94\n",
            "2019-12-04 11:54:25,957 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:25,958 EPOCH 50 done: loss 0.2554 - lr 0.0004\n",
            "2019-12-04 11:54:27,171 DEV : loss 0.2733749747276306 - score 0.9012\n",
            "2019-12-04 11:54:27,226 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:54:30,668 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:30,669 Testing using best model ...\n",
            "2019-12-04 11:54:30,671 loading file test_csv/url50/best-model.pt\n",
            "2019-12-04 11:54:33,098 0.9625\t0.9625\t0.9625\n",
            "2019-12-04 11:54:33,101 \n",
            "MICRO_AVG: acc 0.9277 - f1-score 0.9625\n",
            "MACRO_AVG: acc 0.9237 - f1-score 0.96025\n",
            "fake       tp: 29 - fp: 1 - fn: 2 - tn: 48 - precision: 0.9667 - recall: 0.9355 - accuracy: 0.9062 - f1-score: 0.9508\n",
            "real       tp: 48 - fp: 2 - fn: 1 - tn: 29 - precision: 0.9600 - recall: 0.9796 - accuracy: 0.9412 - f1-score: 0.9697\n",
            "2019-12-04 11:54:33,102 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:33,104 loading file ./test_csv/url50/best-model.pt\n",
            "acc:  0.868421052631579\n",
            "precision:  0.8888888888888888\n",
            "recall:  0.8421052631578947\n",
            "f1:  0.8648648648648649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1gq9R8jLxXm",
        "colab_type": "code",
        "outputId": "0b20a2ca-cebf-46bb-c632-ab82ffa45c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "path = './test_csv/mix50'\n",
        "make_test(train_mix, test_mix, path, path, 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:54:37,896 Reading data from test_csv/mix50\n",
            "2019-12-04 11:54:37,897 Train: test_csv/mix50/train.csv\n",
            "2019-12-04 11:54:37,898 Dev: test_csv/mix50/dev.csv\n",
            "2019-12-04 11:54:37,900 Test: test_csv/mix50/test.csv\n",
            "2019-12-04 11:54:37,907 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 675/675 [00:00<00:00, 682.15it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:54:39,613 [b'real', b'fake']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:54:42,158 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:42,162 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            ")\"\n",
            "2019-12-04 11:54:42,165 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:42,166 Corpus: \"Corpus: 675 train + 85 dev + 84 test sentences\"\n",
            "2019-12-04 11:54:42,168 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:42,169 Parameters:\n",
            "2019-12-04 11:54:42,170  - learning_rate: \"0.1\"\n",
            "2019-12-04 11:54:42,171  - mini_batch_size: \"32\"\n",
            "2019-12-04 11:54:42,172  - patience: \"3\"\n",
            "2019-12-04 11:54:42,174  - anneal_factor: \"0.5\"\n",
            "2019-12-04 11:54:42,175  - max_epochs: \"50\"\n",
            "2019-12-04 11:54:42,176  - shuffle: \"True\"\n",
            "2019-12-04 11:54:42,177  - train_with_dev: \"False\"\n",
            "2019-12-04 11:54:42,178  - batch_growth_annealing: \"False\"\n",
            "2019-12-04 11:54:42,179 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:42,180 Model training base path: \"test_csv/mix50\"\n",
            "2019-12-04 11:54:42,182 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:42,183 Device: cuda:0\n",
            "2019-12-04 11:54:42,184 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:42,185 Embeddings storage mode: cpu\n",
            "2019-12-04 11:54:42,187 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:43,368 epoch 1 - iter 0/22 - loss 0.66017723 - samples/sec: 167.05\n",
            "2019-12-04 11:54:44,253 epoch 1 - iter 2/22 - loss 0.62411978 - samples/sec: 75.86\n",
            "2019-12-04 11:54:44,834 epoch 1 - iter 4/22 - loss 0.61171216 - samples/sec: 123.00\n",
            "2019-12-04 11:54:45,342 epoch 1 - iter 6/22 - loss 0.61826066 - samples/sec: 133.53\n",
            "2019-12-04 11:54:46,111 epoch 1 - iter 8/22 - loss 0.63349440 - samples/sec: 85.91\n",
            "2019-12-04 11:54:46,600 epoch 1 - iter 10/22 - loss 0.62994484 - samples/sec: 142.10\n",
            "2019-12-04 11:54:48,229 epoch 1 - iter 12/22 - loss 0.62920916 - samples/sec: 39.99\n",
            "2019-12-04 11:54:48,744 epoch 1 - iter 14/22 - loss 0.61878151 - samples/sec: 134.55\n",
            "2019-12-04 11:54:49,201 epoch 1 - iter 16/22 - loss 0.60922248 - samples/sec: 147.52\n",
            "2019-12-04 11:54:49,603 epoch 1 - iter 18/22 - loss 0.60139910 - samples/sec: 171.11\n",
            "2019-12-04 11:54:50,105 epoch 1 - iter 20/22 - loss 0.59867987 - samples/sec: 134.48\n",
            "2019-12-04 11:54:50,535 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:50,537 EPOCH 1 done: loss 0.5901 - lr 0.1000\n",
            "2019-12-04 11:54:52,261 DEV : loss 0.5177852511405945 - score 0.7294\n",
            "2019-12-04 11:54:52,338 BAD EPOCHS (no improvement): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type FlairEmbeddings. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LanguageModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-04 11:54:55,845 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:54:56,921 epoch 2 - iter 0/22 - loss 0.57385504 - samples/sec: 196.72\n",
            "2019-12-04 11:54:57,468 epoch 2 - iter 2/22 - loss 0.47300846 - samples/sec: 128.89\n",
            "2019-12-04 11:54:57,975 epoch 2 - iter 4/22 - loss 0.46829290 - samples/sec: 140.12\n",
            "2019-12-04 11:54:58,440 epoch 2 - iter 6/22 - loss 0.49711214 - samples/sec: 145.85\n",
            "2019-12-04 11:54:58,945 epoch 2 - iter 8/22 - loss 0.57512766 - samples/sec: 137.65\n",
            "2019-12-04 11:54:59,513 epoch 2 - iter 10/22 - loss 0.59654569 - samples/sec: 120.90\n",
            "2019-12-04 11:54:59,977 epoch 2 - iter 12/22 - loss 0.57034836 - samples/sec: 151.90\n",
            "2019-12-04 11:55:00,374 epoch 2 - iter 14/22 - loss 0.55232813 - samples/sec: 170.88\n",
            "2019-12-04 11:55:00,888 epoch 2 - iter 16/22 - loss 0.55167042 - samples/sec: 133.58\n",
            "2019-12-04 11:55:01,350 epoch 2 - iter 18/22 - loss 0.53505326 - samples/sec: 148.73\n",
            "2019-12-04 11:55:01,797 epoch 2 - iter 20/22 - loss 0.52189304 - samples/sec: 153.86\n",
            "2019-12-04 11:55:02,217 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:02,223 EPOCH 2 done: loss 0.5568 - lr 0.1000\n",
            "2019-12-04 11:55:03,741 DEV : loss 0.9889330863952637 - score 0.4353\n",
            "2019-12-04 11:55:03,826 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:55:03,828 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:04,796 epoch 3 - iter 0/22 - loss 0.86112511 - samples/sec: 216.47\n",
            "2019-12-04 11:55:05,305 epoch 3 - iter 2/22 - loss 0.62478829 - samples/sec: 149.82\n",
            "2019-12-04 11:55:05,818 epoch 3 - iter 4/22 - loss 0.52777615 - samples/sec: 130.95\n",
            "2019-12-04 11:55:06,355 epoch 3 - iter 6/22 - loss 0.50161320 - samples/sec: 124.78\n",
            "2019-12-04 11:55:06,974 epoch 3 - iter 8/22 - loss 0.50890573 - samples/sec: 113.15\n",
            "2019-12-04 11:55:07,528 epoch 3 - iter 10/22 - loss 0.52325083 - samples/sec: 122.81\n",
            "2019-12-04 11:55:07,970 epoch 3 - iter 12/22 - loss 0.50867331 - samples/sec: 155.56\n",
            "2019-12-04 11:55:08,405 epoch 3 - iter 14/22 - loss 0.49871953 - samples/sec: 158.35\n",
            "2019-12-04 11:55:08,873 epoch 3 - iter 16/22 - loss 0.50491734 - samples/sec: 151.34\n",
            "2019-12-04 11:55:09,335 epoch 3 - iter 18/22 - loss 0.51246695 - samples/sec: 148.48\n",
            "2019-12-04 11:55:09,862 epoch 3 - iter 20/22 - loss 0.49952843 - samples/sec: 128.12\n",
            "2019-12-04 11:55:10,291 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:10,293 EPOCH 3 done: loss 0.5083 - lr 0.1000\n",
            "2019-12-04 11:55:11,918 DEV : loss 0.4458070993423462 - score 0.7529\n",
            "2019-12-04 11:55:11,997 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:55:15,413 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:16,470 epoch 4 - iter 0/22 - loss 0.49329537 - samples/sec: 219.40\n",
            "2019-12-04 11:55:16,975 epoch 4 - iter 2/22 - loss 0.43133899 - samples/sec: 135.63\n",
            "2019-12-04 11:55:17,441 epoch 4 - iter 4/22 - loss 0.45051754 - samples/sec: 152.77\n",
            "2019-12-04 11:55:17,921 epoch 4 - iter 6/22 - loss 0.42878203 - samples/sec: 145.97\n",
            "2019-12-04 11:55:18,395 epoch 4 - iter 8/22 - loss 0.43675756 - samples/sec: 141.99\n",
            "2019-12-04 11:55:18,950 epoch 4 - iter 10/22 - loss 0.43337251 - samples/sec: 127.47\n",
            "2019-12-04 11:55:19,516 epoch 4 - iter 12/22 - loss 0.42395341 - samples/sec: 121.60\n",
            "2019-12-04 11:55:20,059 epoch 4 - iter 14/22 - loss 0.41112824 - samples/sec: 133.13\n",
            "2019-12-04 11:55:20,532 epoch 4 - iter 16/22 - loss 0.41755737 - samples/sec: 145.35\n",
            "2019-12-04 11:55:21,015 epoch 4 - iter 18/22 - loss 0.41661331 - samples/sec: 140.72\n",
            "2019-12-04 11:55:21,495 epoch 4 - iter 20/22 - loss 0.41618760 - samples/sec: 140.59\n",
            "2019-12-04 11:55:21,921 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:21,923 EPOCH 4 done: loss 0.4096 - lr 0.1000\n",
            "2019-12-04 11:55:23,483 DEV : loss 1.9156497716903687 - score 0.4118\n",
            "2019-12-04 11:55:23,557 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:55:23,559 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:24,576 epoch 5 - iter 0/22 - loss 1.97068381 - samples/sec: 221.36\n",
            "2019-12-04 11:55:25,071 epoch 5 - iter 2/22 - loss 1.01080432 - samples/sec: 138.85\n",
            "2019-12-04 11:55:25,529 epoch 5 - iter 4/22 - loss 0.75505913 - samples/sec: 153.93\n",
            "2019-12-04 11:55:26,009 epoch 5 - iter 6/22 - loss 0.63795596 - samples/sec: 151.73\n",
            "2019-12-04 11:55:26,440 epoch 5 - iter 8/22 - loss 0.59536869 - samples/sec: 156.56\n",
            "2019-12-04 11:55:26,975 epoch 5 - iter 10/22 - loss 0.53924988 - samples/sec: 127.44\n",
            "2019-12-04 11:55:27,537 epoch 5 - iter 12/22 - loss 0.51425717 - samples/sec: 131.37\n",
            "2019-12-04 11:55:27,977 epoch 5 - iter 14/22 - loss 0.48702392 - samples/sec: 153.99\n",
            "2019-12-04 11:55:28,372 epoch 5 - iter 16/22 - loss 0.47684960 - samples/sec: 171.64\n",
            "2019-12-04 11:55:28,820 epoch 5 - iter 18/22 - loss 0.46809467 - samples/sec: 154.19\n",
            "2019-12-04 11:55:29,395 epoch 5 - iter 20/22 - loss 0.45895116 - samples/sec: 117.14\n",
            "2019-12-04 11:55:29,806 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:29,808 EPOCH 5 done: loss 0.4629 - lr 0.1000\n",
            "2019-12-04 11:55:31,407 DEV : loss 0.8453598022460938 - score 0.5647\n",
            "2019-12-04 11:55:31,482 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:55:31,484 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:32,573 epoch 6 - iter 0/22 - loss 1.24452913 - samples/sec: 226.48\n",
            "2019-12-04 11:55:33,144 epoch 6 - iter 2/22 - loss 0.68158840 - samples/sec: 119.34\n",
            "2019-12-04 11:55:33,711 epoch 6 - iter 4/22 - loss 0.53517949 - samples/sec: 120.78\n",
            "2019-12-04 11:55:34,263 epoch 6 - iter 6/22 - loss 0.46942346 - samples/sec: 132.82\n",
            "2019-12-04 11:55:34,781 epoch 6 - iter 8/22 - loss 0.43885062 - samples/sec: 131.00\n",
            "2019-12-04 11:55:35,291 epoch 6 - iter 10/22 - loss 0.46953821 - samples/sec: 133.70\n",
            "2019-12-04 11:55:35,837 epoch 6 - iter 12/22 - loss 0.46358799 - samples/sec: 127.55\n",
            "2019-12-04 11:55:36,338 epoch 6 - iter 14/22 - loss 0.48411041 - samples/sec: 133.58\n",
            "2019-12-04 11:55:36,755 epoch 6 - iter 16/22 - loss 0.45868251 - samples/sec: 163.22\n",
            "2019-12-04 11:55:37,324 epoch 6 - iter 18/22 - loss 0.44618900 - samples/sec: 121.80\n",
            "2019-12-04 11:55:37,823 epoch 6 - iter 20/22 - loss 0.43062341 - samples/sec: 136.56\n",
            "2019-12-04 11:55:38,231 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:38,232 EPOCH 6 done: loss 0.4579 - lr 0.1000\n",
            "2019-12-04 11:55:39,829 DEV : loss 0.4329385757446289 - score 0.8\n",
            "2019-12-04 11:55:39,900 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:55:43,330 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:44,379 epoch 7 - iter 0/22 - loss 0.53493798 - samples/sec: 201.32\n",
            "2019-12-04 11:55:44,959 epoch 7 - iter 2/22 - loss 0.35519973 - samples/sec: 126.73\n",
            "2019-12-04 11:55:45,548 epoch 7 - iter 4/22 - loss 0.33043385 - samples/sec: 117.56\n",
            "2019-12-04 11:55:46,056 epoch 7 - iter 6/22 - loss 0.32338812 - samples/sec: 137.78\n",
            "2019-12-04 11:55:46,513 epoch 7 - iter 8/22 - loss 0.33381366 - samples/sec: 155.35\n",
            "2019-12-04 11:55:47,016 epoch 7 - iter 10/22 - loss 0.35809460 - samples/sec: 135.16\n",
            "2019-12-04 11:55:47,515 epoch 7 - iter 12/22 - loss 0.36329055 - samples/sec: 136.08\n",
            "2019-12-04 11:55:48,064 epoch 7 - iter 14/22 - loss 0.37944113 - samples/sec: 130.44\n",
            "2019-12-04 11:55:48,467 epoch 7 - iter 16/22 - loss 0.36758456 - samples/sec: 170.34\n",
            "2019-12-04 11:55:48,948 epoch 7 - iter 18/22 - loss 0.37225005 - samples/sec: 142.96\n",
            "2019-12-04 11:55:49,402 epoch 7 - iter 20/22 - loss 0.37134114 - samples/sec: 149.58\n",
            "2019-12-04 11:55:49,834 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:49,835 EPOCH 7 done: loss 0.3668 - lr 0.1000\n",
            "2019-12-04 11:55:51,440 DEV : loss 1.0347652435302734 - score 0.6588\n",
            "2019-12-04 11:55:51,526 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:55:51,530 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:55:52,557 epoch 8 - iter 0/22 - loss 0.64700717 - samples/sec: 197.59\n",
            "2019-12-04 11:55:53,126 epoch 8 - iter 2/22 - loss 0.40338381 - samples/sec: 119.62\n",
            "2019-12-04 11:55:57,360 epoch 8 - iter 4/22 - loss 0.38647368 - samples/sec: 149.00\n",
            "2019-12-04 11:55:57,861 epoch 8 - iter 6/22 - loss 0.37432180 - samples/sec: 136.16\n",
            "2019-12-04 11:55:58,265 epoch 8 - iter 8/22 - loss 0.38431337 - samples/sec: 167.71\n",
            "2019-12-04 11:55:58,739 epoch 8 - iter 10/22 - loss 0.36214102 - samples/sec: 148.23\n",
            "2019-12-04 11:55:59,191 epoch 8 - iter 12/22 - loss 0.35243779 - samples/sec: 154.31\n",
            "2019-12-04 11:55:59,611 epoch 8 - iter 14/22 - loss 0.33507848 - samples/sec: 160.38\n",
            "2019-12-04 11:56:00,078 epoch 8 - iter 16/22 - loss 0.33289892 - samples/sec: 145.15\n",
            "2019-12-04 11:56:00,539 epoch 8 - iter 18/22 - loss 0.35888756 - samples/sec: 150.49\n",
            "2019-12-04 11:56:01,018 epoch 8 - iter 20/22 - loss 0.35120466 - samples/sec: 141.70\n",
            "2019-12-04 11:56:01,482 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:01,487 EPOCH 8 done: loss 0.3412 - lr 0.1000\n",
            "2019-12-04 11:56:02,945 DEV : loss 0.5437732338905334 - score 0.7529\n",
            "2019-12-04 11:56:03,026 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:56:03,028 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:04,033 epoch 9 - iter 0/22 - loss 0.33439589 - samples/sec: 218.64\n",
            "2019-12-04 11:56:04,571 epoch 9 - iter 2/22 - loss 0.30572137 - samples/sec: 128.08\n",
            "2019-12-04 11:56:05,039 epoch 9 - iter 4/22 - loss 0.31956986 - samples/sec: 146.51\n",
            "2019-12-04 11:56:05,648 epoch 9 - iter 6/22 - loss 0.32281669 - samples/sec: 116.96\n",
            "2019-12-04 11:56:06,180 epoch 9 - iter 8/22 - loss 0.32244235 - samples/sec: 128.06\n",
            "2019-12-04 11:56:06,726 epoch 9 - iter 10/22 - loss 0.32782740 - samples/sec: 124.17\n",
            "2019-12-04 11:56:07,298 epoch 9 - iter 12/22 - loss 0.31791855 - samples/sec: 125.63\n",
            "2019-12-04 11:56:07,831 epoch 9 - iter 14/22 - loss 0.32889128 - samples/sec: 127.76\n",
            "2019-12-04 11:56:08,252 epoch 9 - iter 16/22 - loss 0.32411005 - samples/sec: 163.28\n",
            "2019-12-04 11:56:08,688 epoch 9 - iter 18/22 - loss 0.33166070 - samples/sec: 160.98\n",
            "2019-12-04 11:56:09,119 epoch 9 - iter 20/22 - loss 0.32425306 - samples/sec: 156.68\n",
            "2019-12-04 11:56:09,519 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:09,521 EPOCH 9 done: loss 0.3260 - lr 0.1000\n",
            "2019-12-04 11:56:11,054 DEV : loss 0.5378828048706055 - score 0.7529\n",
            "2019-12-04 11:56:11,132 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:56:11,133 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:12,125 epoch 10 - iter 0/22 - loss 0.32712737 - samples/sec: 195.97\n",
            "2019-12-04 11:56:12,656 epoch 10 - iter 2/22 - loss 0.35293858 - samples/sec: 128.81\n",
            "2019-12-04 11:56:13,179 epoch 10 - iter 4/22 - loss 0.31040373 - samples/sec: 137.69\n",
            "2019-12-04 11:56:13,676 epoch 10 - iter 6/22 - loss 0.30547027 - samples/sec: 137.19\n",
            "2019-12-04 11:56:14,133 epoch 10 - iter 8/22 - loss 0.34159075 - samples/sec: 149.30\n",
            "2019-12-04 11:56:14,685 epoch 10 - iter 10/22 - loss 0.43051204 - samples/sec: 131.13\n",
            "2019-12-04 11:56:15,114 epoch 10 - iter 12/22 - loss 0.41160560 - samples/sec: 157.92\n",
            "2019-12-04 11:56:15,534 epoch 10 - iter 14/22 - loss 0.39088677 - samples/sec: 160.44\n",
            "2019-12-04 11:56:16,092 epoch 10 - iter 16/22 - loss 0.37228632 - samples/sec: 131.94\n",
            "2019-12-04 11:56:16,634 epoch 10 - iter 18/22 - loss 0.36647227 - samples/sec: 124.31\n",
            "2019-12-04 11:56:17,177 epoch 10 - iter 20/22 - loss 0.37484723 - samples/sec: 124.33\n",
            "2019-12-04 11:56:17,606 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:17,617 EPOCH 10 done: loss 0.3805 - lr 0.1000\n",
            "2019-12-04 11:56:19,214 DEV : loss 1.2100260257720947 - score 0.6235\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2019-12-04 11:56:19,287 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:56:19,289 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:20,260 epoch 11 - iter 0/22 - loss 1.10255814 - samples/sec: 218.76\n",
            "2019-12-04 11:56:20,799 epoch 11 - iter 2/22 - loss 0.57953278 - samples/sec: 136.00\n",
            "2019-12-04 11:56:21,224 epoch 11 - iter 4/22 - loss 0.45700896 - samples/sec: 161.10\n",
            "2019-12-04 11:56:21,693 epoch 11 - iter 6/22 - loss 0.40423877 - samples/sec: 143.65\n",
            "2019-12-04 11:56:22,228 epoch 11 - iter 8/22 - loss 0.37431817 - samples/sec: 142.26\n",
            "2019-12-04 11:56:22,622 epoch 11 - iter 10/22 - loss 0.34983250 - samples/sec: 171.47\n",
            "2019-12-04 11:56:23,179 epoch 11 - iter 12/22 - loss 0.33684005 - samples/sec: 119.25\n",
            "2019-12-04 11:56:23,619 epoch 11 - iter 14/22 - loss 0.34523780 - samples/sec: 156.51\n",
            "2019-12-04 11:56:24,092 epoch 11 - iter 16/22 - loss 0.34519371 - samples/sec: 141.42\n",
            "2019-12-04 11:56:24,633 epoch 11 - iter 18/22 - loss 0.33796836 - samples/sec: 124.64\n",
            "2019-12-04 11:56:25,168 epoch 11 - iter 20/22 - loss 0.32778922 - samples/sec: 128.47\n",
            "2019-12-04 11:56:25,564 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:25,568 EPOCH 11 done: loss 0.3246 - lr 0.0500\n",
            "2019-12-04 11:56:27,173 DEV : loss 0.6029195785522461 - score 0.7647\n",
            "2019-12-04 11:56:27,250 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:56:27,252 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:28,216 epoch 12 - iter 0/22 - loss 0.45102584 - samples/sec: 281.44\n",
            "2019-12-04 11:56:28,729 epoch 12 - iter 2/22 - loss 0.34451674 - samples/sec: 134.88\n",
            "2019-12-04 11:56:29,260 epoch 12 - iter 4/22 - loss 0.28505257 - samples/sec: 132.23\n",
            "2019-12-04 11:56:29,692 epoch 12 - iter 6/22 - loss 0.30131468 - samples/sec: 156.79\n",
            "2019-12-04 11:56:30,196 epoch 12 - iter 8/22 - loss 0.30436253 - samples/sec: 138.66\n",
            "2019-12-04 11:56:30,641 epoch 12 - iter 10/22 - loss 0.28827868 - samples/sec: 157.46\n",
            "2019-12-04 11:56:31,050 epoch 12 - iter 12/22 - loss 0.29007496 - samples/sec: 167.48\n",
            "2019-12-04 11:56:31,549 epoch 12 - iter 14/22 - loss 0.28211817 - samples/sec: 137.72\n",
            "2019-12-04 11:56:32,006 epoch 12 - iter 16/22 - loss 0.27793910 - samples/sec: 152.83\n",
            "2019-12-04 11:56:32,512 epoch 12 - iter 18/22 - loss 0.26895614 - samples/sec: 134.28\n",
            "2019-12-04 11:56:32,947 epoch 12 - iter 20/22 - loss 0.26653476 - samples/sec: 157.93\n",
            "2019-12-04 11:56:33,374 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:33,380 EPOCH 12 done: loss 0.3035 - lr 0.0500\n",
            "2019-12-04 11:56:34,944 DEV : loss 0.3349177837371826 - score 0.8471\n",
            "2019-12-04 11:56:35,019 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:56:38,481 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:39,563 epoch 13 - iter 0/22 - loss 0.31032935 - samples/sec: 167.27\n",
            "2019-12-04 11:56:40,027 epoch 13 - iter 2/22 - loss 0.31921131 - samples/sec: 154.68\n",
            "2019-12-04 11:56:40,531 epoch 13 - iter 4/22 - loss 0.29883941 - samples/sec: 144.51\n",
            "2019-12-04 11:56:40,978 epoch 13 - iter 6/22 - loss 0.28367853 - samples/sec: 150.29\n",
            "2019-12-04 11:56:41,538 epoch 13 - iter 8/22 - loss 0.28227175 - samples/sec: 123.95\n",
            "2019-12-04 11:56:42,073 epoch 13 - iter 10/22 - loss 0.28798005 - samples/sec: 126.20\n",
            "2019-12-04 11:56:42,666 epoch 13 - iter 12/22 - loss 0.27709888 - samples/sec: 113.35\n",
            "2019-12-04 11:56:43,168 epoch 13 - iter 14/22 - loss 0.26226639 - samples/sec: 144.64\n",
            "2019-12-04 11:56:43,612 epoch 13 - iter 16/22 - loss 0.27700117 - samples/sec: 151.45\n",
            "2019-12-04 11:56:44,082 epoch 13 - iter 18/22 - loss 0.28154615 - samples/sec: 142.42\n",
            "2019-12-04 11:56:44,519 epoch 13 - iter 20/22 - loss 0.28325896 - samples/sec: 157.89\n",
            "2019-12-04 11:56:44,937 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:44,942 EPOCH 13 done: loss 0.2745 - lr 0.0500\n",
            "2019-12-04 11:56:46,541 DEV : loss 0.3069116175174713 - score 0.8471\n",
            "2019-12-04 11:56:46,626 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:56:50,005 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:51,009 epoch 14 - iter 0/22 - loss 0.24292672 - samples/sec: 228.02\n",
            "2019-12-04 11:56:51,542 epoch 14 - iter 2/22 - loss 0.23197969 - samples/sec: 129.34\n",
            "2019-12-04 11:56:52,031 epoch 14 - iter 4/22 - loss 0.25162161 - samples/sec: 146.01\n",
            "2019-12-04 11:56:52,553 epoch 14 - iter 6/22 - loss 0.25636555 - samples/sec: 131.60\n",
            "2019-12-04 11:56:53,014 epoch 14 - iter 8/22 - loss 0.26705828 - samples/sec: 154.82\n",
            "2019-12-04 11:56:53,513 epoch 14 - iter 10/22 - loss 0.26130149 - samples/sec: 148.11\n",
            "2019-12-04 11:56:53,928 epoch 14 - iter 12/22 - loss 0.25442622 - samples/sec: 165.33\n",
            "2019-12-04 11:56:54,355 epoch 14 - iter 14/22 - loss 0.25506145 - samples/sec: 158.54\n",
            "2019-12-04 11:56:54,830 epoch 14 - iter 16/22 - loss 0.26223940 - samples/sec: 142.30\n",
            "2019-12-04 11:56:55,338 epoch 14 - iter 18/22 - loss 0.26086385 - samples/sec: 136.18\n",
            "2019-12-04 11:56:55,886 epoch 14 - iter 20/22 - loss 0.25913779 - samples/sec: 123.98\n",
            "2019-12-04 11:56:56,273 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:56:56,276 EPOCH 14 done: loss 0.2488 - lr 0.0500\n",
            "2019-12-04 11:56:57,769 DEV : loss 0.31522586941719055 - score 0.8824\n",
            "2019-12-04 11:56:57,848 BAD EPOCHS (no improvement): 0\n",
            "2019-12-04 11:57:01,222 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:02,188 epoch 15 - iter 0/22 - loss 0.27689165 - samples/sec: 239.14\n",
            "2019-12-04 11:57:02,613 epoch 15 - iter 2/22 - loss 0.30295935 - samples/sec: 170.14\n",
            "2019-12-04 11:57:06,915 epoch 15 - iter 4/22 - loss 0.26242074 - samples/sec: 14.96\n",
            "2019-12-04 11:57:07,464 epoch 15 - iter 6/22 - loss 0.25900902 - samples/sec: 125.76\n",
            "2019-12-04 11:57:07,940 epoch 15 - iter 8/22 - loss 0.25392185 - samples/sec: 147.70\n",
            "2019-12-04 11:57:08,433 epoch 15 - iter 10/22 - loss 0.25557758 - samples/sec: 143.62\n",
            "2019-12-04 11:57:08,871 epoch 15 - iter 12/22 - loss 0.25375129 - samples/sec: 156.29\n",
            "2019-12-04 11:57:09,348 epoch 15 - iter 14/22 - loss 0.25004644 - samples/sec: 146.12\n",
            "2019-12-04 11:57:09,790 epoch 15 - iter 16/22 - loss 0.24975658 - samples/sec: 155.65\n",
            "2019-12-04 11:57:10,167 epoch 15 - iter 18/22 - loss 0.24306181 - samples/sec: 181.45\n",
            "2019-12-04 11:57:10,680 epoch 15 - iter 20/22 - loss 0.24171873 - samples/sec: 131.88\n",
            "2019-12-04 11:57:11,132 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:11,134 EPOCH 15 done: loss 0.2659 - lr 0.0500\n",
            "2019-12-04 11:57:12,602 DEV : loss 0.3882778286933899 - score 0.8118\n",
            "2019-12-04 11:57:12,683 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:57:12,688 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:13,635 epoch 16 - iter 0/22 - loss 0.25548694 - samples/sec: 201.06\n",
            "2019-12-04 11:57:14,108 epoch 16 - iter 2/22 - loss 0.29351959 - samples/sec: 150.63\n",
            "2019-12-04 11:57:14,602 epoch 16 - iter 4/22 - loss 0.29173191 - samples/sec: 138.73\n",
            "2019-12-04 11:57:15,133 epoch 16 - iter 6/22 - loss 0.29599070 - samples/sec: 131.45\n",
            "2019-12-04 11:57:15,720 epoch 16 - iter 8/22 - loss 0.33334150 - samples/sec: 124.31\n",
            "2019-12-04 11:57:16,141 epoch 16 - iter 10/22 - loss 0.31373509 - samples/sec: 162.60\n",
            "2019-12-04 11:57:16,673 epoch 16 - iter 12/22 - loss 0.30102271 - samples/sec: 129.46\n",
            "2019-12-04 11:57:17,130 epoch 16 - iter 14/22 - loss 0.28301811 - samples/sec: 149.08\n",
            "2019-12-04 11:57:17,586 epoch 16 - iter 16/22 - loss 0.27320055 - samples/sec: 150.40\n",
            "2019-12-04 11:57:18,099 epoch 16 - iter 18/22 - loss 0.28120592 - samples/sec: 131.13\n",
            "2019-12-04 11:57:18,561 epoch 16 - iter 20/22 - loss 0.28039931 - samples/sec: 147.34\n",
            "2019-12-04 11:57:18,962 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:18,964 EPOCH 16 done: loss 0.2744 - lr 0.0500\n",
            "2019-12-04 11:57:20,497 DEV : loss 0.30605071783065796 - score 0.8824\n",
            "2019-12-04 11:57:20,572 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:57:24,130 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:25,197 epoch 17 - iter 0/22 - loss 0.14123055 - samples/sec: 243.23\n",
            "2019-12-04 11:57:25,737 epoch 17 - iter 2/22 - loss 0.18139192 - samples/sec: 126.35\n",
            "2019-12-04 11:57:26,190 epoch 17 - iter 4/22 - loss 0.17908582 - samples/sec: 161.14\n",
            "2019-12-04 11:57:26,702 epoch 17 - iter 6/22 - loss 0.18679899 - samples/sec: 131.02\n",
            "2019-12-04 11:57:27,223 epoch 17 - iter 8/22 - loss 0.20717642 - samples/sec: 128.82\n",
            "2019-12-04 11:57:27,854 epoch 17 - iter 10/22 - loss 0.23518212 - samples/sec: 116.39\n",
            "2019-12-04 11:57:28,318 epoch 17 - iter 12/22 - loss 0.24558478 - samples/sec: 145.01\n",
            "2019-12-04 11:57:28,826 epoch 17 - iter 14/22 - loss 0.23945817 - samples/sec: 132.95\n",
            "2019-12-04 11:57:29,247 epoch 17 - iter 16/22 - loss 0.23206891 - samples/sec: 164.83\n",
            "2019-12-04 11:57:29,729 epoch 17 - iter 18/22 - loss 0.23208435 - samples/sec: 139.51\n",
            "2019-12-04 11:57:30,327 epoch 17 - iter 20/22 - loss 0.22355878 - samples/sec: 114.18\n",
            "2019-12-04 11:57:30,735 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:30,738 EPOCH 17 done: loss 0.2137 - lr 0.0500\n",
            "2019-12-04 11:57:32,279 DEV : loss 0.3546169698238373 - score 0.8471\n",
            "2019-12-04 11:57:32,357 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:57:32,358 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:33,359 epoch 18 - iter 0/22 - loss 0.24908344 - samples/sec: 213.20\n",
            "2019-12-04 11:57:33,847 epoch 18 - iter 2/22 - loss 0.20669309 - samples/sec: 142.96\n",
            "2019-12-04 11:57:34,318 epoch 18 - iter 4/22 - loss 0.23377635 - samples/sec: 152.43\n",
            "2019-12-04 11:57:34,884 epoch 18 - iter 6/22 - loss 0.22793103 - samples/sec: 126.58\n",
            "2019-12-04 11:57:35,425 epoch 18 - iter 8/22 - loss 0.22562493 - samples/sec: 124.39\n",
            "2019-12-04 11:57:35,943 epoch 18 - iter 10/22 - loss 0.21555946 - samples/sec: 130.85\n",
            "2019-12-04 11:57:36,460 epoch 18 - iter 12/22 - loss 0.20753770 - samples/sec: 139.31\n",
            "2019-12-04 11:57:36,873 epoch 18 - iter 14/22 - loss 0.21239821 - samples/sec: 165.84\n",
            "2019-12-04 11:57:37,485 epoch 18 - iter 16/22 - loss 0.22000911 - samples/sec: 109.95\n",
            "2019-12-04 11:57:38,048 epoch 18 - iter 18/22 - loss 0.21902809 - samples/sec: 125.52\n",
            "2019-12-04 11:57:38,521 epoch 18 - iter 20/22 - loss 0.22927277 - samples/sec: 144.82\n",
            "2019-12-04 11:57:38,912 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:38,916 EPOCH 18 done: loss 0.2373 - lr 0.0500\n",
            "2019-12-04 11:57:40,491 DEV : loss 0.34631186723709106 - score 0.8353\n",
            "Epoch    17: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2019-12-04 11:57:40,566 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:57:40,567 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:41,586 epoch 19 - iter 0/22 - loss 0.42591885 - samples/sec: 212.29\n",
            "2019-12-04 11:57:42,132 epoch 19 - iter 2/22 - loss 0.22320517 - samples/sec: 128.29\n",
            "2019-12-04 11:57:42,595 epoch 19 - iter 4/22 - loss 0.21564959 - samples/sec: 156.64\n",
            "2019-12-04 11:57:43,163 epoch 19 - iter 6/22 - loss 0.23383467 - samples/sec: 120.68\n",
            "2019-12-04 11:57:43,708 epoch 19 - iter 8/22 - loss 0.23506010 - samples/sec: 128.47\n",
            "2019-12-04 11:57:44,199 epoch 19 - iter 10/22 - loss 0.22664338 - samples/sec: 143.49\n",
            "2019-12-04 11:57:44,743 epoch 19 - iter 12/22 - loss 0.22245372 - samples/sec: 127.13\n",
            "2019-12-04 11:57:45,188 epoch 19 - iter 14/22 - loss 0.20985892 - samples/sec: 158.01\n",
            "2019-12-04 11:57:45,656 epoch 19 - iter 16/22 - loss 0.20571624 - samples/sec: 150.19\n",
            "2019-12-04 11:57:46,114 epoch 19 - iter 18/22 - loss 0.20247500 - samples/sec: 150.31\n",
            "2019-12-04 11:57:46,652 epoch 19 - iter 20/22 - loss 0.20406968 - samples/sec: 125.28\n",
            "2019-12-04 11:57:47,092 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:47,094 EPOCH 19 done: loss 0.1955 - lr 0.0250\n",
            "2019-12-04 11:57:48,578 DEV : loss 0.3828026056289673 - score 0.8471\n",
            "2019-12-04 11:57:48,670 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:57:48,672 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:49,680 epoch 20 - iter 0/22 - loss 0.40230644 - samples/sec: 195.43\n",
            "2019-12-04 11:57:50,127 epoch 20 - iter 2/22 - loss 0.27159967 - samples/sec: 158.39\n",
            "2019-12-04 11:57:50,691 epoch 20 - iter 4/22 - loss 0.29207620 - samples/sec: 122.88\n",
            "2019-12-04 11:57:51,193 epoch 20 - iter 6/22 - loss 0.25050017 - samples/sec: 136.45\n",
            "2019-12-04 11:57:51,707 epoch 20 - iter 8/22 - loss 0.24317415 - samples/sec: 133.57\n",
            "2019-12-04 11:57:52,256 epoch 20 - iter 10/22 - loss 0.22845435 - samples/sec: 128.81\n",
            "2019-12-04 11:57:52,783 epoch 20 - iter 12/22 - loss 0.23036189 - samples/sec: 131.97\n",
            "2019-12-04 11:57:53,252 epoch 20 - iter 14/22 - loss 0.24053091 - samples/sec: 146.85\n",
            "2019-12-04 11:57:53,738 epoch 20 - iter 16/22 - loss 0.23396303 - samples/sec: 142.46\n",
            "2019-12-04 11:57:54,191 epoch 20 - iter 18/22 - loss 0.23744816 - samples/sec: 153.36\n",
            "2019-12-04 11:57:54,620 epoch 20 - iter 20/22 - loss 0.23227413 - samples/sec: 160.03\n",
            "2019-12-04 11:57:55,037 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:57:55,038 EPOCH 20 done: loss 0.2250 - lr 0.0250\n",
            "2019-12-04 11:57:56,604 DEV : loss 0.28898125886917114 - score 0.8824\n",
            "2019-12-04 11:57:56,679 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:58:00,176 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:01,206 epoch 21 - iter 0/22 - loss 0.25839382 - samples/sec: 198.09\n",
            "2019-12-04 11:58:01,751 epoch 21 - iter 2/22 - loss 0.27818688 - samples/sec: 125.19\n",
            "2019-12-04 11:58:02,300 epoch 21 - iter 4/22 - loss 0.23537804 - samples/sec: 130.33\n",
            "2019-12-04 11:58:02,801 epoch 21 - iter 6/22 - loss 0.23670973 - samples/sec: 135.74\n",
            "2019-12-04 11:58:03,280 epoch 21 - iter 8/22 - loss 0.21676456 - samples/sec: 148.78\n",
            "2019-12-04 11:58:03,854 epoch 21 - iter 10/22 - loss 0.22178572 - samples/sec: 124.47\n",
            "2019-12-04 11:58:04,299 epoch 21 - iter 12/22 - loss 0.20649143 - samples/sec: 151.38\n",
            "2019-12-04 11:58:04,842 epoch 21 - iter 14/22 - loss 0.21177971 - samples/sec: 127.17\n",
            "2019-12-04 11:58:05,356 epoch 21 - iter 16/22 - loss 0.21398811 - samples/sec: 132.03\n",
            "2019-12-04 11:58:05,879 epoch 21 - iter 18/22 - loss 0.21710589 - samples/sec: 131.84\n",
            "2019-12-04 11:58:06,379 epoch 21 - iter 20/22 - loss 0.21292852 - samples/sec: 136.21\n",
            "2019-12-04 11:58:06,761 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:06,765 EPOCH 21 done: loss 0.2055 - lr 0.0250\n",
            "2019-12-04 11:58:08,361 DEV : loss 0.34137505292892456 - score 0.8588\n",
            "2019-12-04 11:58:08,435 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:58:08,436 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:09,487 epoch 22 - iter 0/22 - loss 0.10192220 - samples/sec: 156.90\n",
            "2019-12-04 11:58:13,914 epoch 22 - iter 2/22 - loss 0.18030587 - samples/sec: 14.61\n",
            "2019-12-04 11:58:14,301 epoch 22 - iter 4/22 - loss 0.18327977 - samples/sec: 184.20\n",
            "2019-12-04 11:58:14,715 epoch 22 - iter 6/22 - loss 0.16925109 - samples/sec: 176.67\n",
            "2019-12-04 11:58:15,178 epoch 22 - iter 8/22 - loss 0.16764510 - samples/sec: 145.88\n",
            "2019-12-04 11:58:15,676 epoch 22 - iter 10/22 - loss 0.18810518 - samples/sec: 137.18\n",
            "2019-12-04 11:58:16,162 epoch 22 - iter 12/22 - loss 0.22917830 - samples/sec: 144.03\n",
            "2019-12-04 11:58:16,650 epoch 22 - iter 14/22 - loss 0.22779851 - samples/sec: 142.79\n",
            "2019-12-04 11:58:17,077 epoch 22 - iter 16/22 - loss 0.22095364 - samples/sec: 160.73\n",
            "2019-12-04 11:58:17,577 epoch 22 - iter 18/22 - loss 0.22571693 - samples/sec: 135.53\n",
            "2019-12-04 11:58:17,992 epoch 22 - iter 20/22 - loss 0.22305037 - samples/sec: 166.72\n",
            "2019-12-04 11:58:18,450 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:18,453 EPOCH 22 done: loss 0.2150 - lr 0.0250\n",
            "2019-12-04 11:58:20,036 DEV : loss 0.30671483278274536 - score 0.8706\n",
            "Epoch    21: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2019-12-04 11:58:20,108 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:58:20,109 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:21,052 epoch 23 - iter 0/22 - loss 0.34774241 - samples/sec: 221.97\n",
            "2019-12-04 11:58:21,589 epoch 23 - iter 2/22 - loss 0.24060252 - samples/sec: 128.10\n",
            "2019-12-04 11:58:22,049 epoch 23 - iter 4/22 - loss 0.21657406 - samples/sec: 164.63\n",
            "2019-12-04 11:58:22,590 epoch 23 - iter 6/22 - loss 0.18929819 - samples/sec: 123.34\n",
            "2019-12-04 11:58:23,070 epoch 23 - iter 8/22 - loss 0.20419336 - samples/sec: 141.91\n",
            "2019-12-04 11:58:23,498 epoch 23 - iter 10/22 - loss 0.19418123 - samples/sec: 167.37\n",
            "2019-12-04 11:58:23,996 epoch 23 - iter 12/22 - loss 0.19484191 - samples/sec: 141.76\n",
            "2019-12-04 11:58:24,470 epoch 23 - iter 14/22 - loss 0.19894730 - samples/sec: 141.26\n",
            "2019-12-04 11:58:24,944 epoch 23 - iter 16/22 - loss 0.20096235 - samples/sec: 144.67\n",
            "2019-12-04 11:58:25,369 epoch 23 - iter 18/22 - loss 0.19575849 - samples/sec: 158.87\n",
            "2019-12-04 11:58:25,916 epoch 23 - iter 20/22 - loss 0.19191837 - samples/sec: 122.90\n",
            "2019-12-04 11:58:26,292 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:26,295 EPOCH 23 done: loss 0.1857 - lr 0.0125\n",
            "2019-12-04 11:58:27,903 DEV : loss 0.3249114155769348 - score 0.8588\n",
            "2019-12-04 11:58:27,973 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:58:27,974 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:28,939 epoch 24 - iter 0/22 - loss 0.20680845 - samples/sec: 216.46\n",
            "2019-12-04 11:58:29,401 epoch 24 - iter 2/22 - loss 0.21242053 - samples/sec: 150.59\n",
            "2019-12-04 11:58:29,943 epoch 24 - iter 4/22 - loss 0.17897108 - samples/sec: 130.78\n",
            "2019-12-04 11:58:30,390 epoch 24 - iter 6/22 - loss 0.18122979 - samples/sec: 151.23\n",
            "2019-12-04 11:58:30,898 epoch 24 - iter 8/22 - loss 0.19160244 - samples/sec: 135.04\n",
            "2019-12-04 11:58:31,365 epoch 24 - iter 10/22 - loss 0.19519857 - samples/sec: 152.74\n",
            "2019-12-04 11:58:31,786 epoch 24 - iter 12/22 - loss 0.19776379 - samples/sec: 160.81\n",
            "2019-12-04 11:58:32,238 epoch 24 - iter 14/22 - loss 0.19349435 - samples/sec: 154.50\n",
            "2019-12-04 11:58:32,704 epoch 24 - iter 16/22 - loss 0.19230979 - samples/sec: 154.13\n",
            "2019-12-04 11:58:33,233 epoch 24 - iter 18/22 - loss 0.18664067 - samples/sec: 126.27\n",
            "2019-12-04 11:58:33,662 epoch 24 - iter 20/22 - loss 0.17850281 - samples/sec: 161.83\n",
            "2019-12-04 11:58:34,036 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:34,046 EPOCH 24 done: loss 0.1750 - lr 0.0125\n",
            "2019-12-04 11:58:35,638 DEV : loss 0.3417322039604187 - score 0.8588\n",
            "2019-12-04 11:58:35,714 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:58:35,715 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:36,760 epoch 25 - iter 0/22 - loss 0.17739595 - samples/sec: 205.92\n",
            "2019-12-04 11:58:37,315 epoch 25 - iter 2/22 - loss 0.16487984 - samples/sec: 121.05\n",
            "2019-12-04 11:58:37,894 epoch 25 - iter 4/22 - loss 0.21163288 - samples/sec: 127.45\n",
            "2019-12-04 11:58:38,361 epoch 25 - iter 6/22 - loss 0.20871969 - samples/sec: 146.28\n",
            "2019-12-04 11:58:38,781 epoch 25 - iter 8/22 - loss 0.19983060 - samples/sec: 161.52\n",
            "2019-12-04 11:58:39,234 epoch 25 - iter 10/22 - loss 0.19743796 - samples/sec: 156.05\n",
            "2019-12-04 11:58:39,772 epoch 25 - iter 12/22 - loss 0.20213212 - samples/sec: 132.27\n",
            "2019-12-04 11:58:40,278 epoch 25 - iter 14/22 - loss 0.19239593 - samples/sec: 133.74\n",
            "2019-12-04 11:58:40,814 epoch 25 - iter 16/22 - loss 0.17803859 - samples/sec: 130.60\n",
            "2019-12-04 11:58:41,338 epoch 25 - iter 18/22 - loss 0.17281183 - samples/sec: 129.50\n",
            "2019-12-04 11:58:41,835 epoch 25 - iter 20/22 - loss 0.17170926 - samples/sec: 136.75\n",
            "2019-12-04 11:58:42,225 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:42,230 EPOCH 25 done: loss 0.2140 - lr 0.0125\n",
            "2019-12-04 11:58:43,780 DEV : loss 0.33997541666030884 - score 0.8588\n",
            "2019-12-04 11:58:43,860 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:58:43,862 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:44,843 epoch 26 - iter 0/22 - loss 0.11154082 - samples/sec: 267.75\n",
            "2019-12-04 11:58:45,357 epoch 26 - iter 2/22 - loss 0.21201577 - samples/sec: 132.52\n",
            "2019-12-04 11:58:45,830 epoch 26 - iter 4/22 - loss 0.21121389 - samples/sec: 145.77\n",
            "2019-12-04 11:58:46,325 epoch 26 - iter 6/22 - loss 0.20641408 - samples/sec: 143.15\n",
            "2019-12-04 11:58:46,805 epoch 26 - iter 8/22 - loss 0.19895977 - samples/sec: 145.48\n",
            "2019-12-04 11:58:47,277 epoch 26 - iter 10/22 - loss 0.18926660 - samples/sec: 142.66\n",
            "2019-12-04 11:58:47,833 epoch 26 - iter 12/22 - loss 0.18912604 - samples/sec: 124.59\n",
            "2019-12-04 11:58:48,301 epoch 26 - iter 14/22 - loss 0.20083879 - samples/sec: 148.95\n",
            "2019-12-04 11:58:48,739 epoch 26 - iter 16/22 - loss 0.20302115 - samples/sec: 158.86\n",
            "2019-12-04 11:58:49,184 epoch 26 - iter 18/22 - loss 0.19579931 - samples/sec: 152.56\n",
            "2019-12-04 11:58:49,665 epoch 26 - iter 20/22 - loss 0.18542355 - samples/sec: 141.73\n",
            "2019-12-04 11:58:50,034 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:50,038 EPOCH 26 done: loss 0.1794 - lr 0.0125\n",
            "2019-12-04 11:58:51,465 DEV : loss 0.3018922209739685 - score 0.8706\n",
            "Epoch    25: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2019-12-04 11:58:51,552 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:58:51,553 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:52,588 epoch 27 - iter 0/22 - loss 0.30959284 - samples/sec: 186.11\n",
            "2019-12-04 11:58:53,122 epoch 27 - iter 2/22 - loss 0.21223014 - samples/sec: 132.21\n",
            "2019-12-04 11:58:53,549 epoch 27 - iter 4/22 - loss 0.25840319 - samples/sec: 162.53\n",
            "2019-12-04 11:58:53,979 epoch 27 - iter 6/22 - loss 0.25685617 - samples/sec: 162.01\n",
            "2019-12-04 11:58:54,419 epoch 27 - iter 8/22 - loss 0.23624263 - samples/sec: 160.02\n",
            "2019-12-04 11:58:54,917 epoch 27 - iter 10/22 - loss 0.22846828 - samples/sec: 137.13\n",
            "2019-12-04 11:58:55,499 epoch 27 - iter 12/22 - loss 0.22082566 - samples/sec: 121.78\n",
            "2019-12-04 11:58:55,987 epoch 27 - iter 14/22 - loss 0.22099401 - samples/sec: 138.99\n",
            "2019-12-04 11:58:56,490 epoch 27 - iter 16/22 - loss 0.20554422 - samples/sec: 133.05\n",
            "2019-12-04 11:58:56,972 epoch 27 - iter 18/22 - loss 0.20069436 - samples/sec: 145.02\n",
            "2019-12-04 11:58:57,512 epoch 27 - iter 20/22 - loss 0.19477043 - samples/sec: 123.41\n",
            "2019-12-04 11:58:57,917 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:58:57,920 EPOCH 27 done: loss 0.1883 - lr 0.0063\n",
            "2019-12-04 11:58:59,486 DEV : loss 0.2998858094215393 - score 0.8706\n",
            "2019-12-04 11:58:59,560 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:58:59,562 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:00,515 epoch 28 - iter 0/22 - loss 0.20146382 - samples/sec: 236.13\n",
            "2019-12-04 11:59:01,023 epoch 28 - iter 2/22 - loss 0.14554458 - samples/sec: 138.85\n",
            "2019-12-04 11:59:01,636 epoch 28 - iter 4/22 - loss 0.17280077 - samples/sec: 117.75\n",
            "2019-12-04 11:59:02,144 epoch 28 - iter 6/22 - loss 0.15488821 - samples/sec: 133.76\n",
            "2019-12-04 11:59:02,668 epoch 28 - iter 8/22 - loss 0.15817006 - samples/sec: 128.57\n",
            "2019-12-04 11:59:03,211 epoch 28 - iter 10/22 - loss 0.16600688 - samples/sec: 128.06\n",
            "2019-12-04 11:59:03,724 epoch 28 - iter 12/22 - loss 0.17790044 - samples/sec: 131.79\n",
            "2019-12-04 11:59:04,219 epoch 28 - iter 14/22 - loss 0.18589888 - samples/sec: 138.97\n",
            "2019-12-04 11:59:04,702 epoch 28 - iter 16/22 - loss 0.18151428 - samples/sec: 146.18\n",
            "2019-12-04 11:59:05,216 epoch 28 - iter 18/22 - loss 0.18749300 - samples/sec: 130.55\n",
            "2019-12-04 11:59:05,722 epoch 28 - iter 20/22 - loss 0.18011018 - samples/sec: 135.69\n",
            "2019-12-04 11:59:06,126 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:06,127 EPOCH 28 done: loss 0.1721 - lr 0.0063\n",
            "2019-12-04 11:59:07,614 DEV : loss 0.28979164361953735 - score 0.8706\n",
            "2019-12-04 11:59:07,691 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:59:07,692 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:12,451 epoch 29 - iter 0/22 - loss 0.26767150 - samples/sec: 280.52\n",
            "2019-12-04 11:59:12,957 epoch 29 - iter 2/22 - loss 0.18306455 - samples/sec: 134.92\n",
            "2019-12-04 11:59:13,429 epoch 29 - iter 4/22 - loss 0.20240715 - samples/sec: 143.51\n",
            "2019-12-04 11:59:13,904 epoch 29 - iter 6/22 - loss 0.21565274 - samples/sec: 155.81\n",
            "2019-12-04 11:59:14,424 epoch 29 - iter 8/22 - loss 0.22808288 - samples/sec: 130.08\n",
            "2019-12-04 11:59:14,869 epoch 29 - iter 10/22 - loss 0.20472122 - samples/sec: 153.68\n",
            "2019-12-04 11:59:15,392 epoch 29 - iter 12/22 - loss 0.20984788 - samples/sec: 129.54\n",
            "2019-12-04 11:59:15,862 epoch 29 - iter 14/22 - loss 0.21136464 - samples/sec: 144.35\n",
            "2019-12-04 11:59:16,251 epoch 29 - iter 16/22 - loss 0.20887029 - samples/sec: 175.59\n",
            "2019-12-04 11:59:16,653 epoch 29 - iter 18/22 - loss 0.19974162 - samples/sec: 172.11\n",
            "2019-12-04 11:59:17,016 epoch 29 - iter 20/22 - loss 0.19702437 - samples/sec: 188.42\n",
            "2019-12-04 11:59:17,409 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:17,412 EPOCH 29 done: loss 0.2056 - lr 0.0063\n",
            "2019-12-04 11:59:18,960 DEV : loss 0.3347778916358948 - score 0.8588\n",
            "2019-12-04 11:59:19,037 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:59:19,038 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:19,981 epoch 30 - iter 0/22 - loss 0.09850593 - samples/sec: 224.53\n",
            "2019-12-04 11:59:20,510 epoch 30 - iter 2/22 - loss 0.18658381 - samples/sec: 128.85\n",
            "2019-12-04 11:59:21,061 epoch 30 - iter 4/22 - loss 0.20468384 - samples/sec: 130.95\n",
            "2019-12-04 11:59:21,551 epoch 30 - iter 6/22 - loss 0.20741640 - samples/sec: 140.46\n",
            "2019-12-04 11:59:21,960 epoch 30 - iter 8/22 - loss 0.23105568 - samples/sec: 166.73\n",
            "2019-12-04 11:59:22,340 epoch 30 - iter 10/22 - loss 0.22384353 - samples/sec: 187.09\n",
            "2019-12-04 11:59:22,818 epoch 30 - iter 12/22 - loss 0.22209816 - samples/sec: 140.56\n",
            "2019-12-04 11:59:23,316 epoch 30 - iter 14/22 - loss 0.21539336 - samples/sec: 135.71\n",
            "2019-12-04 11:59:23,872 epoch 30 - iter 16/22 - loss 0.19972089 - samples/sec: 128.11\n",
            "2019-12-04 11:59:24,299 epoch 30 - iter 18/22 - loss 0.18983725 - samples/sec: 158.16\n",
            "2019-12-04 11:59:24,776 epoch 30 - iter 20/22 - loss 0.19128568 - samples/sec: 140.59\n",
            "2019-12-04 11:59:25,148 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:25,150 EPOCH 30 done: loss 0.2002 - lr 0.0063\n",
            "2019-12-04 11:59:26,603 DEV : loss 0.27898967266082764 - score 0.8824\n",
            "Epoch    29: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2019-12-04 11:59:26,680 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 11:59:30,154 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:31,199 epoch 31 - iter 0/22 - loss 0.31362197 - samples/sec: 187.83\n",
            "2019-12-04 11:59:31,782 epoch 31 - iter 2/22 - loss 0.31148178 - samples/sec: 121.76\n",
            "2019-12-04 11:59:32,329 epoch 31 - iter 4/22 - loss 0.24044003 - samples/sec: 127.03\n",
            "2019-12-04 11:59:32,901 epoch 31 - iter 6/22 - loss 0.20842602 - samples/sec: 120.77\n",
            "2019-12-04 11:59:33,352 epoch 31 - iter 8/22 - loss 0.19584716 - samples/sec: 151.13\n",
            "2019-12-04 11:59:33,809 epoch 31 - iter 10/22 - loss 0.19875051 - samples/sec: 153.39\n",
            "2019-12-04 11:59:34,277 epoch 31 - iter 12/22 - loss 0.20750288 - samples/sec: 148.66\n",
            "2019-12-04 11:59:34,796 epoch 31 - iter 14/22 - loss 0.20467313 - samples/sec: 130.64\n",
            "2019-12-04 11:59:35,285 epoch 31 - iter 16/22 - loss 0.19274576 - samples/sec: 146.58\n",
            "2019-12-04 11:59:35,786 epoch 31 - iter 18/22 - loss 0.19043120 - samples/sec: 135.83\n",
            "2019-12-04 11:59:36,318 epoch 31 - iter 20/22 - loss 0.18920327 - samples/sec: 126.78\n",
            "2019-12-04 11:59:36,702 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:36,703 EPOCH 31 done: loss 0.1928 - lr 0.0031\n",
            "2019-12-04 11:59:38,282 DEV : loss 0.2830203175544739 - score 0.8824\n",
            "2019-12-04 11:59:38,361 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 11:59:41,790 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:42,870 epoch 32 - iter 0/22 - loss 0.10648767 - samples/sec: 205.19\n",
            "2019-12-04 11:59:43,382 epoch 32 - iter 2/22 - loss 0.09831095 - samples/sec: 136.43\n",
            "2019-12-04 11:59:43,933 epoch 32 - iter 4/22 - loss 0.14176556 - samples/sec: 128.12\n",
            "2019-12-04 11:59:44,356 epoch 32 - iter 6/22 - loss 0.16583347 - samples/sec: 160.03\n",
            "2019-12-04 11:59:44,809 epoch 32 - iter 8/22 - loss 0.15184058 - samples/sec: 151.97\n",
            "2019-12-04 11:59:45,268 epoch 32 - iter 10/22 - loss 0.17613697 - samples/sec: 156.56\n",
            "2019-12-04 11:59:45,669 epoch 32 - iter 12/22 - loss 0.17088644 - samples/sec: 173.10\n",
            "2019-12-04 11:59:46,111 epoch 32 - iter 14/22 - loss 0.18321106 - samples/sec: 158.10\n",
            "2019-12-04 11:59:46,635 epoch 32 - iter 16/22 - loss 0.18587435 - samples/sec: 134.61\n",
            "2019-12-04 11:59:47,054 epoch 32 - iter 18/22 - loss 0.18609177 - samples/sec: 162.01\n",
            "2019-12-04 11:59:47,481 epoch 32 - iter 20/22 - loss 0.18379622 - samples/sec: 159.00\n",
            "2019-12-04 11:59:47,884 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:47,885 EPOCH 32 done: loss 0.1812 - lr 0.0031\n",
            "2019-12-04 11:59:49,419 DEV : loss 0.29333922266960144 - score 0.8706\n",
            "2019-12-04 11:59:49,504 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 11:59:49,508 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:50,513 epoch 33 - iter 0/22 - loss 0.11410195 - samples/sec: 215.18\n",
            "2019-12-04 11:59:51,071 epoch 33 - iter 2/22 - loss 0.15865104 - samples/sec: 126.39\n",
            "2019-12-04 11:59:51,609 epoch 33 - iter 4/22 - loss 0.18484180 - samples/sec: 137.00\n",
            "2019-12-04 11:59:52,160 epoch 33 - iter 6/22 - loss 0.17305175 - samples/sec: 122.76\n",
            "2019-12-04 11:59:52,729 epoch 33 - iter 8/22 - loss 0.17549731 - samples/sec: 118.24\n",
            "2019-12-04 11:59:53,234 epoch 33 - iter 10/22 - loss 0.17535935 - samples/sec: 134.90\n",
            "2019-12-04 11:59:53,698 epoch 33 - iter 12/22 - loss 0.19190139 - samples/sec: 155.36\n",
            "2019-12-04 11:59:54,139 epoch 33 - iter 14/22 - loss 0.20401213 - samples/sec: 153.26\n",
            "2019-12-04 11:59:54,734 epoch 33 - iter 16/22 - loss 0.19629421 - samples/sec: 114.75\n",
            "2019-12-04 11:59:55,263 epoch 33 - iter 18/22 - loss 0.20225546 - samples/sec: 131.50\n",
            "2019-12-04 11:59:55,832 epoch 33 - iter 20/22 - loss 0.20272582 - samples/sec: 118.35\n",
            "2019-12-04 11:59:56,198 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:56,203 EPOCH 33 done: loss 0.1939 - lr 0.0031\n",
            "2019-12-04 11:59:57,702 DEV : loss 0.2868848443031311 - score 0.8706\n",
            "2019-12-04 11:59:57,775 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 11:59:57,777 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 11:59:58,809 epoch 34 - iter 0/22 - loss 0.06503675 - samples/sec: 226.58\n",
            "2019-12-04 11:59:59,235 epoch 34 - iter 2/22 - loss 0.11722072 - samples/sec: 162.11\n",
            "2019-12-04 11:59:59,749 epoch 34 - iter 4/22 - loss 0.15259429 - samples/sec: 134.15\n",
            "2019-12-04 12:00:00,216 epoch 34 - iter 6/22 - loss 0.16590988 - samples/sec: 162.97\n",
            "2019-12-04 12:00:00,704 epoch 34 - iter 8/22 - loss 0.17955948 - samples/sec: 137.59\n",
            "2019-12-04 12:00:01,236 epoch 34 - iter 10/22 - loss 0.17114659 - samples/sec: 125.80\n",
            "2019-12-04 12:00:01,738 epoch 34 - iter 12/22 - loss 0.16873948 - samples/sec: 138.85\n",
            "2019-12-04 12:00:02,182 epoch 34 - iter 14/22 - loss 0.15481344 - samples/sec: 157.46\n",
            "2019-12-04 12:00:02,690 epoch 34 - iter 16/22 - loss 0.16095745 - samples/sec: 131.85\n",
            "2019-12-04 12:00:03,143 epoch 34 - iter 18/22 - loss 0.16395965 - samples/sec: 154.18\n",
            "2019-12-04 12:00:03,543 epoch 34 - iter 20/22 - loss 0.18015756 - samples/sec: 172.32\n",
            "2019-12-04 12:00:03,928 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:03,929 EPOCH 34 done: loss 0.1746 - lr 0.0031\n",
            "2019-12-04 12:00:05,441 DEV : loss 0.29841944575309753 - score 0.8706\n",
            "Epoch    33: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2019-12-04 12:00:05,518 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 12:00:05,520 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:06,504 epoch 35 - iter 0/22 - loss 0.25249624 - samples/sec: 215.43\n",
            "2019-12-04 12:00:07,022 epoch 35 - iter 2/22 - loss 0.27720977 - samples/sec: 139.13\n",
            "2019-12-04 12:00:07,600 epoch 35 - iter 4/22 - loss 0.21919864 - samples/sec: 116.74\n",
            "2019-12-04 12:00:08,156 epoch 35 - iter 6/22 - loss 0.19752405 - samples/sec: 122.68\n",
            "2019-12-04 12:00:08,654 epoch 35 - iter 8/22 - loss 0.17409321 - samples/sec: 151.70\n",
            "2019-12-04 12:00:09,145 epoch 35 - iter 10/22 - loss 0.17846729 - samples/sec: 136.89\n",
            "2019-12-04 12:00:09,641 epoch 35 - iter 12/22 - loss 0.18313086 - samples/sec: 136.42\n",
            "2019-12-04 12:00:10,165 epoch 35 - iter 14/22 - loss 0.17472462 - samples/sec: 130.61\n",
            "2019-12-04 12:00:10,718 epoch 35 - iter 16/22 - loss 0.17634486 - samples/sec: 122.04\n",
            "2019-12-04 12:00:11,200 epoch 35 - iter 18/22 - loss 0.17631647 - samples/sec: 139.50\n",
            "2019-12-04 12:00:11,717 epoch 35 - iter 20/22 - loss 0.17530721 - samples/sec: 133.92\n",
            "2019-12-04 12:00:12,096 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:12,100 EPOCH 35 done: loss 0.1733 - lr 0.0016\n",
            "2019-12-04 12:00:13,603 DEV : loss 0.2995484173297882 - score 0.8706\n",
            "2019-12-04 12:00:13,682 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 12:00:13,684 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:14,689 epoch 36 - iter 0/22 - loss 0.20688930 - samples/sec: 163.62\n",
            "2019-12-04 12:00:15,257 epoch 36 - iter 2/22 - loss 0.19160264 - samples/sec: 122.52\n",
            "2019-12-04 12:00:15,770 epoch 36 - iter 4/22 - loss 0.19633854 - samples/sec: 136.54\n",
            "2019-12-04 12:00:19,950 epoch 36 - iter 6/22 - loss 0.19185705 - samples/sec: 15.48\n",
            "2019-12-04 12:00:20,338 epoch 36 - iter 8/22 - loss 0.17906017 - samples/sec: 184.57\n",
            "2019-12-04 12:00:20,798 epoch 36 - iter 10/22 - loss 0.19381878 - samples/sec: 146.12\n",
            "2019-12-04 12:00:21,204 epoch 36 - iter 12/22 - loss 0.18496566 - samples/sec: 170.39\n",
            "2019-12-04 12:00:21,659 epoch 36 - iter 14/22 - loss 0.18574650 - samples/sec: 151.92\n",
            "2019-12-04 12:00:22,058 epoch 36 - iter 16/22 - loss 0.19653086 - samples/sec: 174.21\n",
            "2019-12-04 12:00:22,429 epoch 36 - iter 18/22 - loss 0.19908008 - samples/sec: 183.79\n",
            "2019-12-04 12:00:22,827 epoch 36 - iter 20/22 - loss 0.19476847 - samples/sec: 171.61\n",
            "2019-12-04 12:00:23,254 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:23,259 EPOCH 36 done: loss 0.1874 - lr 0.0016\n",
            "2019-12-04 12:00:24,880 DEV : loss 0.29539403319358826 - score 0.8706\n",
            "2019-12-04 12:00:24,959 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 12:00:24,960 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:25,933 epoch 37 - iter 0/22 - loss 0.29452905 - samples/sec: 158.08\n",
            "2019-12-04 12:00:26,563 epoch 37 - iter 2/22 - loss 0.30462675 - samples/sec: 112.39\n",
            "2019-12-04 12:00:27,047 epoch 37 - iter 4/22 - loss 0.23329811 - samples/sec: 141.15\n",
            "2019-12-04 12:00:27,612 epoch 37 - iter 6/22 - loss 0.20272161 - samples/sec: 121.89\n",
            "2019-12-04 12:00:28,141 epoch 37 - iter 8/22 - loss 0.18052772 - samples/sec: 141.91\n",
            "2019-12-04 12:00:28,589 epoch 37 - iter 10/22 - loss 0.20437237 - samples/sec: 153.90\n",
            "2019-12-04 12:00:29,055 epoch 37 - iter 12/22 - loss 0.19743818 - samples/sec: 154.37\n",
            "2019-12-04 12:00:29,639 epoch 37 - iter 14/22 - loss 0.19247274 - samples/sec: 114.30\n",
            "2019-12-04 12:00:30,100 epoch 37 - iter 16/22 - loss 0.19274307 - samples/sec: 148.15\n",
            "2019-12-04 12:00:30,612 epoch 37 - iter 18/22 - loss 0.18949654 - samples/sec: 134.99\n",
            "2019-12-04 12:00:31,041 epoch 37 - iter 20/22 - loss 0.18530027 - samples/sec: 159.40\n",
            "2019-12-04 12:00:31,435 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:31,437 EPOCH 37 done: loss 0.2087 - lr 0.0016\n",
            "2019-12-04 12:00:32,961 DEV : loss 0.2970990836620331 - score 0.8706\n",
            "2019-12-04 12:00:33,035 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 12:00:33,037 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:33,996 epoch 38 - iter 0/22 - loss 0.16830030 - samples/sec: 262.10\n",
            "2019-12-04 12:00:34,523 epoch 38 - iter 2/22 - loss 0.22643666 - samples/sec: 127.76\n",
            "2019-12-04 12:00:35,020 epoch 38 - iter 4/22 - loss 0.19659185 - samples/sec: 146.61\n",
            "2019-12-04 12:00:35,511 epoch 38 - iter 6/22 - loss 0.19364444 - samples/sec: 147.53\n",
            "2019-12-04 12:00:36,003 epoch 38 - iter 8/22 - loss 0.18666920 - samples/sec: 138.36\n",
            "2019-12-04 12:00:36,580 epoch 38 - iter 10/22 - loss 0.19026418 - samples/sec: 115.36\n",
            "2019-12-04 12:00:37,174 epoch 38 - iter 12/22 - loss 0.19859102 - samples/sec: 116.22\n",
            "2019-12-04 12:00:37,698 epoch 38 - iter 14/22 - loss 0.19548026 - samples/sec: 129.28\n",
            "2019-12-04 12:00:38,171 epoch 38 - iter 16/22 - loss 0.19354915 - samples/sec: 143.71\n",
            "2019-12-04 12:00:38,655 epoch 38 - iter 18/22 - loss 0.18894697 - samples/sec: 148.01\n",
            "2019-12-04 12:00:39,071 epoch 38 - iter 20/22 - loss 0.19010134 - samples/sec: 165.86\n",
            "2019-12-04 12:00:39,465 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:39,470 EPOCH 38 done: loss 0.2077 - lr 0.0016\n",
            "2019-12-04 12:00:40,920 DEV : loss 0.293722927570343 - score 0.8706\n",
            "Epoch    37: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2019-12-04 12:00:40,996 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 12:00:40,998 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:42,057 epoch 39 - iter 0/22 - loss 0.07228940 - samples/sec: 177.68\n",
            "2019-12-04 12:00:42,625 epoch 39 - iter 2/22 - loss 0.11421837 - samples/sec: 121.82\n",
            "2019-12-04 12:00:43,145 epoch 39 - iter 4/22 - loss 0.12011861 - samples/sec: 137.17\n",
            "2019-12-04 12:00:43,648 epoch 39 - iter 6/22 - loss 0.15448142 - samples/sec: 145.70\n",
            "2019-12-04 12:00:44,110 epoch 39 - iter 8/22 - loss 0.17846892 - samples/sec: 145.52\n",
            "2019-12-04 12:00:44,618 epoch 39 - iter 10/22 - loss 0.17644020 - samples/sec: 135.62\n",
            "2019-12-04 12:00:45,109 epoch 39 - iter 12/22 - loss 0.18122205 - samples/sec: 143.76\n",
            "2019-12-04 12:00:45,553 epoch 39 - iter 14/22 - loss 0.17273147 - samples/sec: 160.51\n",
            "2019-12-04 12:00:46,041 epoch 39 - iter 16/22 - loss 0.18602584 - samples/sec: 138.26\n",
            "2019-12-04 12:00:46,573 epoch 39 - iter 18/22 - loss 0.18580801 - samples/sec: 130.34\n",
            "2019-12-04 12:00:47,048 epoch 39 - iter 20/22 - loss 0.18044559 - samples/sec: 144.89\n",
            "2019-12-04 12:00:47,454 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:47,457 EPOCH 39 done: loss 0.1730 - lr 0.0008\n",
            "2019-12-04 12:00:48,948 DEV : loss 0.29246237874031067 - score 0.8706\n",
            "2019-12-04 12:00:49,024 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 12:00:49,025 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:50,000 epoch 40 - iter 0/22 - loss 0.16627938 - samples/sec: 244.43\n",
            "2019-12-04 12:00:50,618 epoch 40 - iter 2/22 - loss 0.19699576 - samples/sec: 112.16\n",
            "2019-12-04 12:00:51,080 epoch 40 - iter 4/22 - loss 0.16964729 - samples/sec: 148.34\n",
            "2019-12-04 12:00:51,666 epoch 40 - iter 6/22 - loss 0.16251668 - samples/sec: 126.88\n",
            "2019-12-04 12:00:52,135 epoch 40 - iter 8/22 - loss 0.16967331 - samples/sec: 145.26\n",
            "2019-12-04 12:00:52,639 epoch 40 - iter 10/22 - loss 0.16998827 - samples/sec: 132.82\n",
            "2019-12-04 12:00:53,124 epoch 40 - iter 12/22 - loss 0.15850148 - samples/sec: 142.94\n",
            "2019-12-04 12:00:53,658 epoch 40 - iter 14/22 - loss 0.15941476 - samples/sec: 125.48\n",
            "2019-12-04 12:00:54,109 epoch 40 - iter 16/22 - loss 0.16701774 - samples/sec: 152.64\n",
            "2019-12-04 12:00:54,598 epoch 40 - iter 18/22 - loss 0.16265327 - samples/sec: 144.66\n",
            "2019-12-04 12:00:55,019 epoch 40 - iter 20/22 - loss 0.17920750 - samples/sec: 162.56\n",
            "2019-12-04 12:00:55,402 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:55,404 EPOCH 40 done: loss 0.1787 - lr 0.0008\n",
            "2019-12-04 12:00:56,901 DEV : loss 0.2936899960041046 - score 0.8706\n",
            "2019-12-04 12:00:56,975 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 12:00:56,977 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:00:57,973 epoch 41 - iter 0/22 - loss 0.15325704 - samples/sec: 200.80\n",
            "2019-12-04 12:00:58,399 epoch 41 - iter 2/22 - loss 0.13701776 - samples/sec: 168.74\n",
            "2019-12-04 12:00:58,897 epoch 41 - iter 4/22 - loss 0.19144312 - samples/sec: 145.15\n",
            "2019-12-04 12:00:59,350 epoch 41 - iter 6/22 - loss 0.18898706 - samples/sec: 148.91\n",
            "2019-12-04 12:00:59,830 epoch 41 - iter 8/22 - loss 0.19374681 - samples/sec: 139.73\n",
            "2019-12-04 12:01:00,382 epoch 41 - iter 10/22 - loss 0.19038758 - samples/sec: 128.60\n",
            "2019-12-04 12:01:00,879 epoch 41 - iter 12/22 - loss 0.17669597 - samples/sec: 136.45\n",
            "2019-12-04 12:01:01,382 epoch 41 - iter 14/22 - loss 0.17549667 - samples/sec: 134.27\n",
            "2019-12-04 12:01:01,925 epoch 41 - iter 16/22 - loss 0.17184704 - samples/sec: 131.53\n",
            "2019-12-04 12:01:02,456 epoch 41 - iter 18/22 - loss 0.16137531 - samples/sec: 125.57\n",
            "2019-12-04 12:01:02,984 epoch 41 - iter 20/22 - loss 0.16053633 - samples/sec: 130.31\n",
            "2019-12-04 12:01:03,397 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:03,398 EPOCH 41 done: loss 0.1748 - lr 0.0008\n",
            "2019-12-04 12:01:04,982 DEV : loss 0.2926572561264038 - score 0.8706\n",
            "2019-12-04 12:01:05,068 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 12:01:05,071 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:06,014 epoch 42 - iter 0/22 - loss 0.06809048 - samples/sec: 221.90\n",
            "2019-12-04 12:01:06,594 epoch 42 - iter 2/22 - loss 0.08823588 - samples/sec: 119.80\n",
            "2019-12-04 12:01:07,157 epoch 42 - iter 4/22 - loss 0.12390229 - samples/sec: 129.23\n",
            "2019-12-04 12:01:07,669 epoch 42 - iter 6/22 - loss 0.11674521 - samples/sec: 130.63\n",
            "2019-12-04 12:01:08,175 epoch 42 - iter 8/22 - loss 0.15754015 - samples/sec: 134.06\n",
            "2019-12-04 12:01:08,709 epoch 42 - iter 10/22 - loss 0.15852457 - samples/sec: 133.22\n",
            "2019-12-04 12:01:09,183 epoch 42 - iter 12/22 - loss 0.17676486 - samples/sec: 142.75\n",
            "2019-12-04 12:01:09,788 epoch 42 - iter 14/22 - loss 0.17481342 - samples/sec: 113.86\n",
            "2019-12-04 12:01:10,281 epoch 42 - iter 16/22 - loss 0.18671980 - samples/sec: 140.60\n",
            "2019-12-04 12:01:10,754 epoch 42 - iter 18/22 - loss 0.18191191 - samples/sec: 142.28\n",
            "2019-12-04 12:01:11,269 epoch 42 - iter 20/22 - loss 0.17199116 - samples/sec: 132.52\n",
            "2019-12-04 12:01:11,653 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:11,658 EPOCH 42 done: loss 0.1646 - lr 0.0008\n",
            "2019-12-04 12:01:13,214 DEV : loss 0.2932460904121399 - score 0.8706\n",
            "Epoch    41: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2019-12-04 12:01:13,289 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 12:01:13,290 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:14,268 epoch 43 - iter 0/22 - loss 0.16552058 - samples/sec: 202.36\n",
            "2019-12-04 12:01:14,773 epoch 43 - iter 2/22 - loss 0.15786038 - samples/sec: 139.26\n",
            "2019-12-04 12:01:15,354 epoch 43 - iter 4/22 - loss 0.16658028 - samples/sec: 118.33\n",
            "2019-12-04 12:01:15,879 epoch 43 - iter 6/22 - loss 0.15482177 - samples/sec: 129.88\n",
            "2019-12-04 12:01:20,118 epoch 43 - iter 8/22 - loss 0.14080213 - samples/sec: 138.18\n",
            "2019-12-04 12:01:20,623 epoch 43 - iter 10/22 - loss 0.13484892 - samples/sec: 136.63\n",
            "2019-12-04 12:01:21,141 epoch 43 - iter 12/22 - loss 0.13758647 - samples/sec: 135.86\n",
            "2019-12-04 12:01:21,654 epoch 43 - iter 14/22 - loss 0.14348725 - samples/sec: 133.89\n",
            "2019-12-04 12:01:22,055 epoch 43 - iter 16/22 - loss 0.15581913 - samples/sec: 175.22\n",
            "2019-12-04 12:01:22,587 epoch 43 - iter 18/22 - loss 0.16042226 - samples/sec: 130.30\n",
            "2019-12-04 12:01:23,003 epoch 43 - iter 20/22 - loss 0.15478374 - samples/sec: 165.24\n",
            "2019-12-04 12:01:23,468 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:23,472 EPOCH 43 done: loss 0.1737 - lr 0.0004\n",
            "2019-12-04 12:01:25,050 DEV : loss 0.2918514609336853 - score 0.8824\n",
            "2019-12-04 12:01:25,129 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 12:01:28,644 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:29,710 epoch 44 - iter 0/22 - loss 0.11983432 - samples/sec: 202.72\n",
            "2019-12-04 12:01:30,197 epoch 44 - iter 2/22 - loss 0.12565371 - samples/sec: 143.49\n",
            "2019-12-04 12:01:30,775 epoch 44 - iter 4/22 - loss 0.14218130 - samples/sec: 125.96\n",
            "2019-12-04 12:01:31,240 epoch 44 - iter 6/22 - loss 0.14332381 - samples/sec: 146.00\n",
            "2019-12-04 12:01:31,700 epoch 44 - iter 8/22 - loss 0.17135004 - samples/sec: 146.18\n",
            "2019-12-04 12:01:32,161 epoch 44 - iter 10/22 - loss 0.17194214 - samples/sec: 153.12\n",
            "2019-12-04 12:01:32,598 epoch 44 - iter 12/22 - loss 0.17130533 - samples/sec: 155.17\n",
            "2019-12-04 12:01:33,052 epoch 44 - iter 14/22 - loss 0.17719258 - samples/sec: 155.59\n",
            "2019-12-04 12:01:33,483 epoch 44 - iter 16/22 - loss 0.16431371 - samples/sec: 156.26\n",
            "2019-12-04 12:01:33,987 epoch 44 - iter 18/22 - loss 0.16925447 - samples/sec: 136.42\n",
            "2019-12-04 12:01:34,510 epoch 44 - iter 20/22 - loss 0.18070562 - samples/sec: 128.72\n",
            "2019-12-04 12:01:34,938 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:34,939 EPOCH 44 done: loss 0.1871 - lr 0.0004\n",
            "2019-12-04 12:01:36,456 DEV : loss 0.29039719700813293 - score 0.8706\n",
            "2019-12-04 12:01:36,534 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 12:01:36,536 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:37,599 epoch 45 - iter 0/22 - loss 0.13209638 - samples/sec: 196.28\n",
            "2019-12-04 12:01:38,048 epoch 45 - iter 2/22 - loss 0.18034266 - samples/sec: 154.49\n",
            "2019-12-04 12:01:38,565 epoch 45 - iter 4/22 - loss 0.18949599 - samples/sec: 140.67\n",
            "2019-12-04 12:01:38,997 epoch 45 - iter 6/22 - loss 0.21131088 - samples/sec: 156.27\n",
            "2019-12-04 12:01:39,537 epoch 45 - iter 8/22 - loss 0.20376451 - samples/sec: 124.42\n",
            "2019-12-04 12:01:40,052 epoch 45 - iter 10/22 - loss 0.19589444 - samples/sec: 142.49\n",
            "2019-12-04 12:01:40,581 epoch 45 - iter 12/22 - loss 0.18450439 - samples/sec: 127.78\n",
            "2019-12-04 12:01:41,033 epoch 45 - iter 14/22 - loss 0.17977873 - samples/sec: 150.78\n",
            "2019-12-04 12:01:41,493 epoch 45 - iter 16/22 - loss 0.17663386 - samples/sec: 150.09\n",
            "2019-12-04 12:01:41,903 epoch 45 - iter 18/22 - loss 0.17974243 - samples/sec: 165.60\n",
            "2019-12-04 12:01:42,368 epoch 45 - iter 20/22 - loss 0.17760765 - samples/sec: 146.76\n",
            "2019-12-04 12:01:42,744 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:42,745 EPOCH 45 done: loss 0.1892 - lr 0.0004\n",
            "2019-12-04 12:01:44,261 DEV : loss 0.29088371992111206 - score 0.8706\n",
            "2019-12-04 12:01:44,335 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 12:01:44,336 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:45,378 epoch 46 - iter 0/22 - loss 0.16223651 - samples/sec: 198.91\n",
            "2019-12-04 12:01:45,902 epoch 46 - iter 2/22 - loss 0.20135944 - samples/sec: 133.29\n",
            "2019-12-04 12:01:46,525 epoch 46 - iter 4/22 - loss 0.20125555 - samples/sec: 113.39\n",
            "2019-12-04 12:01:46,983 epoch 46 - iter 6/22 - loss 0.21702997 - samples/sec: 149.35\n",
            "2019-12-04 12:01:47,463 epoch 46 - iter 8/22 - loss 0.22521281 - samples/sec: 139.78\n",
            "2019-12-04 12:01:47,928 epoch 46 - iter 10/22 - loss 0.21354975 - samples/sec: 151.14\n",
            "2019-12-04 12:01:48,397 epoch 46 - iter 12/22 - loss 0.19717721 - samples/sec: 143.39\n",
            "2019-12-04 12:01:48,981 epoch 46 - iter 14/22 - loss 0.19000232 - samples/sec: 115.17\n",
            "2019-12-04 12:01:49,551 epoch 46 - iter 16/22 - loss 0.18769427 - samples/sec: 125.11\n",
            "2019-12-04 12:01:50,044 epoch 46 - iter 18/22 - loss 0.18608530 - samples/sec: 137.52\n",
            "2019-12-04 12:01:50,495 epoch 46 - iter 20/22 - loss 0.18915041 - samples/sec: 149.46\n",
            "2019-12-04 12:01:50,891 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:50,893 EPOCH 46 done: loss 0.1814 - lr 0.0004\n",
            "2019-12-04 12:01:52,405 DEV : loss 0.2914659380912781 - score 0.8706\n",
            "Epoch    45: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2019-12-04 12:01:52,484 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 12:01:52,487 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:53,462 epoch 47 - iter 0/22 - loss 0.10719150 - samples/sec: 224.88\n",
            "2019-12-04 12:01:53,967 epoch 47 - iter 2/22 - loss 0.09689408 - samples/sec: 139.09\n",
            "2019-12-04 12:01:54,472 epoch 47 - iter 4/22 - loss 0.11933955 - samples/sec: 134.08\n",
            "2019-12-04 12:01:54,968 epoch 47 - iter 6/22 - loss 0.13277724 - samples/sec: 141.43\n",
            "2019-12-04 12:01:55,471 epoch 47 - iter 8/22 - loss 0.12861680 - samples/sec: 140.71\n",
            "2019-12-04 12:01:55,950 epoch 47 - iter 10/22 - loss 0.12874664 - samples/sec: 141.91\n",
            "2019-12-04 12:01:56,443 epoch 47 - iter 12/22 - loss 0.13922246 - samples/sec: 146.79\n",
            "2019-12-04 12:01:56,886 epoch 47 - iter 14/22 - loss 0.14464513 - samples/sec: 157.60\n",
            "2019-12-04 12:01:57,358 epoch 47 - iter 16/22 - loss 0.14590233 - samples/sec: 144.24\n",
            "2019-12-04 12:01:57,874 epoch 47 - iter 18/22 - loss 0.14407976 - samples/sec: 136.06\n",
            "2019-12-04 12:01:58,307 epoch 47 - iter 20/22 - loss 0.14719491 - samples/sec: 158.35\n",
            "2019-12-04 12:01:58,734 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:01:58,735 EPOCH 47 done: loss 0.1780 - lr 0.0002\n",
            "2019-12-04 12:02:00,374 DEV : loss 0.29226669669151306 - score 0.8824\n",
            "2019-12-04 12:02:00,452 BAD EPOCHS (no improvement): 1\n",
            "2019-12-04 12:02:03,935 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:04,973 epoch 48 - iter 0/22 - loss 0.13151205 - samples/sec: 205.29\n",
            "2019-12-04 12:02:05,531 epoch 48 - iter 2/22 - loss 0.14233197 - samples/sec: 124.70\n",
            "2019-12-04 12:02:06,094 epoch 48 - iter 4/22 - loss 0.17031367 - samples/sec: 131.50\n",
            "2019-12-04 12:02:06,549 epoch 48 - iter 6/22 - loss 0.17578058 - samples/sec: 148.46\n",
            "2019-12-04 12:02:07,042 epoch 48 - iter 8/22 - loss 0.17603692 - samples/sec: 135.86\n",
            "2019-12-04 12:02:07,553 epoch 48 - iter 10/22 - loss 0.17089461 - samples/sec: 141.95\n",
            "2019-12-04 12:02:08,023 epoch 48 - iter 12/22 - loss 0.16994611 - samples/sec: 144.70\n",
            "2019-12-04 12:02:08,435 epoch 48 - iter 14/22 - loss 0.17245615 - samples/sec: 163.64\n",
            "2019-12-04 12:02:08,950 epoch 48 - iter 16/22 - loss 0.17016636 - samples/sec: 135.56\n",
            "2019-12-04 12:02:09,528 epoch 48 - iter 18/22 - loss 0.17381363 - samples/sec: 116.62\n",
            "2019-12-04 12:02:10,002 epoch 48 - iter 20/22 - loss 0.16706915 - samples/sec: 143.52\n",
            "2019-12-04 12:02:10,400 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:10,402 EPOCH 48 done: loss 0.1710 - lr 0.0002\n",
            "2019-12-04 12:02:12,025 DEV : loss 0.2919183671474457 - score 0.8824\n",
            "2019-12-04 12:02:12,099 BAD EPOCHS (no improvement): 2\n",
            "2019-12-04 12:02:15,526 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:16,511 epoch 49 - iter 0/22 - loss 0.14352089 - samples/sec: 279.06\n",
            "2019-12-04 12:02:16,998 epoch 49 - iter 2/22 - loss 0.17604248 - samples/sec: 141.60\n",
            "2019-12-04 12:02:17,478 epoch 49 - iter 4/22 - loss 0.14177079 - samples/sec: 141.68\n",
            "2019-12-04 12:02:18,049 epoch 49 - iter 6/22 - loss 0.14701946 - samples/sec: 127.19\n",
            "2019-12-04 12:02:18,509 epoch 49 - iter 8/22 - loss 0.14429546 - samples/sec: 147.18\n",
            "2019-12-04 12:02:19,012 epoch 49 - iter 10/22 - loss 0.19159323 - samples/sec: 134.82\n",
            "2019-12-04 12:02:19,512 epoch 49 - iter 12/22 - loss 0.18620018 - samples/sec: 141.56\n",
            "2019-12-04 12:02:19,940 epoch 49 - iter 14/22 - loss 0.18611957 - samples/sec: 159.85\n",
            "2019-12-04 12:02:20,497 epoch 49 - iter 16/22 - loss 0.19078517 - samples/sec: 120.21\n",
            "2019-12-04 12:02:21,103 epoch 49 - iter 18/22 - loss 0.19537574 - samples/sec: 116.13\n",
            "2019-12-04 12:02:21,640 epoch 49 - iter 20/22 - loss 0.19126327 - samples/sec: 126.41\n",
            "2019-12-04 12:02:22,043 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:22,045 EPOCH 49 done: loss 0.1890 - lr 0.0002\n",
            "2019-12-04 12:02:23,557 DEV : loss 0.2933278977870941 - score 0.8706\n",
            "2019-12-04 12:02:23,631 BAD EPOCHS (no improvement): 3\n",
            "2019-12-04 12:02:23,632 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:24,648 epoch 50 - iter 0/22 - loss 0.17276807 - samples/sec: 207.92\n",
            "2019-12-04 12:02:25,104 epoch 50 - iter 2/22 - loss 0.17999582 - samples/sec: 151.23\n",
            "2019-12-04 12:02:25,743 epoch 50 - iter 4/22 - loss 0.19360286 - samples/sec: 108.27\n",
            "2019-12-04 12:02:29,938 epoch 50 - iter 6/22 - loss 0.17531516 - samples/sec: 154.24\n",
            "2019-12-04 12:02:30,338 epoch 50 - iter 8/22 - loss 0.15464442 - samples/sec: 170.82\n",
            "2019-12-04 12:02:30,802 epoch 50 - iter 10/22 - loss 0.15605731 - samples/sec: 158.13\n",
            "2019-12-04 12:02:31,172 epoch 50 - iter 12/22 - loss 0.16889085 - samples/sec: 187.63\n",
            "2019-12-04 12:02:31,574 epoch 50 - iter 14/22 - loss 0.17371684 - samples/sec: 168.87\n",
            "2019-12-04 12:02:32,018 epoch 50 - iter 16/22 - loss 0.17697349 - samples/sec: 160.43\n",
            "2019-12-04 12:02:32,399 epoch 50 - iter 18/22 - loss 0.18350108 - samples/sec: 181.18\n",
            "2019-12-04 12:02:32,805 epoch 50 - iter 20/22 - loss 0.17856495 - samples/sec: 166.46\n",
            "2019-12-04 12:02:33,224 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:33,227 EPOCH 50 done: loss 0.1764 - lr 0.0002\n",
            "2019-12-04 12:02:34,864 DEV : loss 0.29293292760849 - score 0.8706\n",
            "Epoch    49: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2019-12-04 12:02:34,942 BAD EPOCHS (no improvement): 4\n",
            "2019-12-04 12:02:38,396 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:38,401 Testing using best model ...\n",
            "2019-12-04 12:02:38,405 loading file test_csv/mix50/best-model.pt\n",
            "2019-12-04 12:02:41,351 0.8929\t0.8929\t0.8929\n",
            "2019-12-04 12:02:41,352 \n",
            "MICRO_AVG: acc 0.8065 - f1-score 0.8929\n",
            "MACRO_AVG: acc 0.7938 - f1-score 0.8842000000000001\n",
            "fake       tp: 26 - fp: 4 - fn: 5 - tn: 49 - precision: 0.8667 - recall: 0.8387 - accuracy: 0.7429 - f1-score: 0.8525\n",
            "real       tp: 49 - fp: 5 - fn: 4 - tn: 26 - precision: 0.9074 - recall: 0.9245 - accuracy: 0.8448 - f1-score: 0.9159\n",
            "2019-12-04 12:02:41,354 ----------------------------------------------------------------------------------------------------\n",
            "2019-12-04 12:02:41,361 loading file ./test_csv/mix50/best-model.pt\n",
            "acc:  0.7924528301886793\n",
            "precision:  0.7327586206896551\n",
            "recall:  0.8673469387755102\n",
            "f1:  0.7943925233644858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6SOqZJ9L0An",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
